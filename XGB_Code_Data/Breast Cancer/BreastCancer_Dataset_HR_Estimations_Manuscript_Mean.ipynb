{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Breast Cancer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All packages, hyperparameter evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import Counter\n",
    "import time\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import pandas_profiling\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt.pyll.base import scope\n",
    "import pyspark\n",
    "\n",
    "import xgboost\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "# Hyperparameters tuning\n",
    "\n",
    "from hyperopt import STATUS_OK, fmin, hp, tpe, SparkTrials\n",
    "\n",
    "# Some constants\n",
    "\n",
    "SEED = 314159265\n",
    "VALID_SIZE = 0.2\n",
    "TARGET = 'outcome'\n",
    "\n",
    "def c_statistic_harrell(pred, labels):\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if int(labels[j]) > 0 and abs(int(labels[i])) > int(labels[j]):\n",
    "                total += 1\n",
    "                if pred[j] > pred[i]:\n",
    "                    matches += 1\n",
    "    return matches/total\n",
    "\n",
    "#-----------------------XGBoost--------------------------#\n",
    "\n",
    "def score_xgb(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    \n",
    "    n_folds = 5\n",
    "    val_scores = []\n",
    "    skf = KFold(n_splits = n_folds, shuffle = False)\n",
    "    num_boost_round=1000\n",
    "    #k-fold CV\n",
    "    for train_index, val_index in skf.split(X_train): \n",
    "        X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        dtrain = xgboost.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgboost.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "        gbm_model = xgboost.train(params, dtrain, num_boost_round,\n",
    "                              evals=watchlist,\n",
    "                              verbose_eval=250)\n",
    "        \n",
    "        predictions = gbm_model.predict(dval,\n",
    "                                    ntree_limit=gbm_model.best_iteration + 1)\n",
    "        val_scores.append(c_statistic_harrell(predictions, list(y_val)))\n",
    "    \n",
    "    score = np.mean(val_scores) #Objective: maximize mean 5-fold CV C-index \n",
    "    \n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    # The score function should return the loss (1-score)\n",
    "    # since the optimize function looks for the minimum\n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def optimize_xgb(score, \n",
    "             random_state=SEED):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space (space here) of \n",
    "    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "    # XGB param ranges obtained from Barnwal A, Cho H, Hocking T (2020). Survival regression with accelerated failure time model in XGBoost: \n",
    "    # https://arxiv.org/pdf/2006.04920.pdf\n",
    "    # exception: min_child_weight, reg_alpha and reg_lambda capped at 10 rather than 100\n",
    "    space = {\n",
    "        'eta':                         hp.loguniform('eta', np.log(0.001), np.log(1)),\n",
    "        'max_depth':                   scope.int(hp.quniform('max_depth', 2,10,1)),\n",
    "        'min_child_weight':            hp.loguniform('min_child_weight', np.log(0.001), np.log(10)),\n",
    "        'reg_alpha':                   hp.loguniform('reg_alpha', np.log(0.001), np.log(10)),\n",
    "        'reg_lambda':                  hp.loguniform('reg_lambda', np.log(0.001), np.log(10)),\n",
    "        'subsample':                   hp.uniform('subsample', 0.75, 1),\n",
    "        \"objective\": \"survival:cox\"\n",
    "    }\n",
    "    \n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                max_evals=100)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directory to Save Files (Assumed that Files needed for reading are in current working directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory to save all figures (create directory beforehand)\n",
    "save_to = save_to = os.getcwd() + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -2282\n",
       "1   -2006\n",
       "2    1456\n",
       "3    -148\n",
       "4   -1863\n",
       "Name: SURV_DAY_XGB, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_bcd = pd.read_csv(\"XGB_BCDS_normalized.csv\")\n",
    "X_bcd_id = All_bcd['id']\n",
    "X_bcd = All_bcd.drop(columns = ['id','survtime','censdead','SURV_DAY_XGB'])\n",
    "y_bcd = All_bcd['SURV_DAY_XGB']\n",
    "y_bcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>menopause</th>\n",
       "      <th>hormone</th>\n",
       "      <th>size</th>\n",
       "      <th>grade</th>\n",
       "      <th>nodes</th>\n",
       "      <th>prog_recp</th>\n",
       "      <th>estrg_recp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059244</td>\n",
       "      <td>0.091783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032773</td>\n",
       "      <td>0.012238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.440678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177311</td>\n",
       "      <td>0.077797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.322034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.009615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728814</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.007867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  menopause  hormone      size  grade  nodes  prog_recp  estrg_recp\n",
       "0  0.288136          0        0  0.128205      3      5   0.059244    0.091783\n",
       "1  0.525424          0        0  0.145299      1      1   0.032773    0.012238\n",
       "2  0.440678          0        0  0.230769      2      1   0.177311    0.077797\n",
       "3  0.322034          0        0  0.179487      1      3   0.010504    0.009615\n",
       "4  0.728814          1        1  0.136752      2      1   0.007983    0.007867"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_bcd.shape)\n",
    "X_bcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -2282\n",
       "1   -2006\n",
       "2    1456\n",
       "3    -148\n",
       "4   -1863\n",
       "Name: SURV_DAY_XGB, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_bcd.shape)\n",
    "y_bcd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning, 100 evaluation rounds to find best hyperparameters to run our XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bcd, y_bcd, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Running XGBoost ----\n",
      "Training with params:                                  \n",
      "{'eta': 0.578826344617033, 'max_depth': 5, 'min_child_weight': 0.005213123272652775, 'objective': 'survival:cox', 'reg_alpha': 0.2792524457272663, 'reg_lambda': 0.03244599053133823, 'subsample': 0.8435049296826771}\n",
      "[0]\teval-cox-nloglik:12.71057\ttrain-cox-nloglik:5.59205\n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[0]\teval-cox-nloglik:11.13401\ttrain-cox-nloglik:5.69107\n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[0]\teval-cox-nloglik:3.98827\ttrain-cox-nloglik:6.54573 \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[0]\teval-cox-nloglik:10.77925\ttrain-cox-nloglik:5.86764\n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[0]\teval-cox-nloglik:11.48371\ttrain-cox-nloglik:11.37569\n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan       \n",
      "\n",
      "\tScore 0.0                                             \n",
      "\n",
      "\n",
      "Training with params:                                             \n",
      "{'eta': 0.4070143560445401, 'max_depth': 3, 'min_child_weight': 0.013532958651116473, 'objective': 'survival:cox', 'reg_alpha': 0.6317206416259817, 'reg_lambda': 0.05794769506514157, 'subsample': 0.8936661093301386}\n",
      "[0]\teval-cox-nloglik:4.18754\ttrain-cox-nloglik:5.21450            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.43878\ttrain-cox-nloglik:2.55335          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.48039\ttrain-cox-nloglik:2.23717          \n",
      "\n",
      "[750]\teval-cox-nloglik:8.69964\ttrain-cox-nloglik:2.05902          \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                  \n",
      "\n",
      "[0]\teval-cox-nloglik:4.29361\ttrain-cox-nloglik:5.10505            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.62038\ttrain-cox-nloglik:2.46034          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.99586\ttrain-cox-nloglik:2.15321          \n",
      "\n",
      "[750]\teval-cox-nloglik:9.44528\ttrain-cox-nloglik:2.00933          \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                  \n",
      "\n",
      "[0]\teval-cox-nloglik:3.97651\ttrain-cox-nloglik:5.20998            \n",
      "\n",
      "[250]\teval-cox-nloglik:8.06538\ttrain-cox-nloglik:2.58861          \n",
      "\n",
      "[500]\teval-cox-nloglik:9.79475\ttrain-cox-nloglik:2.25922          \n",
      "\n",
      "[750]\teval-cox-nloglik:11.00670\ttrain-cox-nloglik:2.08011         \n",
      "\n",
      "[999]\teval-cox-nloglik:11.94936\ttrain-cox-nloglik:2.03450         \n",
      "\n",
      "[0]\teval-cox-nloglik:3.89224\ttrain-cox-nloglik:5.38526            \n",
      "\n",
      "[250]\teval-cox-nloglik:7.54515\ttrain-cox-nloglik:2.49589          \n",
      "\n",
      "[500]\teval-cox-nloglik:8.93472\ttrain-cox-nloglik:2.18950          \n",
      "\n",
      "[750]\teval-cox-nloglik:10.43891\ttrain-cox-nloglik:2.02839         \n",
      "\n",
      "[999]\teval-cox-nloglik:11.54590\ttrain-cox-nloglik:1.98880         \n",
      "\n",
      "[0]\teval-cox-nloglik:3.96694\ttrain-cox-nloglik:5.16706            \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                  \n",
      "\n",
      "\tScore 0.25848185145468106                                        \n",
      "\n",
      "\n",
      "Training with params:                                                           \n",
      "{'eta': 0.06665906026354577, 'max_depth': 6, 'min_child_weight': 0.021539038678890485, 'objective': 'survival:cox', 'reg_alpha': 0.3757009660207343, 'reg_lambda': 0.19632611806004568, 'subsample': 0.9642732502448353}\n",
      "[0]\teval-cox-nloglik:4.01695\ttrain-cox-nloglik:5.41389                          \n",
      "\n",
      "[250]\teval-cox-nloglik:6.14835\ttrain-cox-nloglik:2.50098                        \n",
      "\n",
      "[500]\teval-cox-nloglik:7.37062\ttrain-cox-nloglik:2.16992                        \n",
      "\n",
      "[750]\teval-cox-nloglik:8.04433\ttrain-cox-nloglik:2.01898                        \n",
      "\n",
      "[999]\teval-cox-nloglik:8.19286\ttrain-cox-nloglik:1.99843                        \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25374\ttrain-cox-nloglik:5.31782                          \n",
      "\n",
      "[250]\teval-cox-nloglik:7.13927\ttrain-cox-nloglik:2.41771                        \n",
      "\n",
      "[500]\teval-cox-nloglik:8.66461\ttrain-cox-nloglik:2.10237                        \n",
      "\n",
      "[750]\teval-cox-nloglik:9.65120\ttrain-cox-nloglik:1.99787                        \n",
      "\n",
      "[999]\teval-cox-nloglik:10.36580\ttrain-cox-nloglik:1.99274                       \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06905\ttrain-cox-nloglik:5.39084                          \n",
      "\n",
      "[250]\teval-cox-nloglik:5.95747\ttrain-cox-nloglik:2.52374                        \n",
      "\n",
      "[500]\teval-cox-nloglik:7.00785\ttrain-cox-nloglik:2.19337                        \n",
      "\n",
      "[750]\teval-cox-nloglik:7.65381\ttrain-cox-nloglik:2.04474                        \n",
      "\n",
      "[999]\teval-cox-nloglik:8.14667\ttrain-cox-nloglik:1.97062                        \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09581\ttrain-cox-nloglik:5.41550                          \n",
      "\n",
      "[250]\teval-cox-nloglik:7.18454\ttrain-cox-nloglik:2.48250                        \n",
      "\n",
      "[500]\teval-cox-nloglik:8.74121\ttrain-cox-nloglik:2.15840                        \n",
      "\n",
      "[750]\teval-cox-nloglik:9.64017\ttrain-cox-nloglik:2.00865                        \n",
      "\n",
      "[999]\teval-cox-nloglik:10.50325\ttrain-cox-nloglik:1.92620                       \n",
      "\n",
      "[0]\teval-cox-nloglik:4.20026\ttrain-cox-nloglik:5.35395                          \n",
      "\n",
      "[250]\teval-cox-nloglik:5.53302\ttrain-cox-nloglik:2.57015                        \n",
      "\n",
      "[500]\teval-cox-nloglik:6.75879\ttrain-cox-nloglik:2.23417                        \n",
      "\n",
      "[750]\teval-cox-nloglik:7.70865\ttrain-cox-nloglik:2.06097                        \n",
      "\n",
      "[999]\teval-cox-nloglik:8.15166\ttrain-cox-nloglik:1.98338                        \n",
      "\n",
      "\tScore 0.6915819744666619                                                       \n",
      "\n",
      "\n",
      "Training with params:                                                            \n",
      "{'eta': 0.016444847308068746, 'max_depth': 8, 'min_child_weight': 0.0016186106954980892, 'objective': 'survival:cox', 'reg_alpha': 1.9783812262432277, 'reg_lambda': 0.022067476537119077, 'subsample': 0.8382114081922212}\n",
      "[0]\teval-cox-nloglik:4.11193\ttrain-cox-nloglik:5.52911                           \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97114\ttrain-cox-nloglik:3.87807                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.20399\ttrain-cox-nloglik:3.51193                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.38242\ttrain-cox-nloglik:3.32785                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.50738\ttrain-cox-nloglik:3.21557                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25750\ttrain-cox-nloglik:5.48184                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.67621\ttrain-cox-nloglik:3.79546                         \n",
      "\n",
      "[500]\teval-cox-nloglik:5.00629\ttrain-cox-nloglik:3.41040                         \n",
      "\n",
      "[750]\teval-cox-nloglik:5.22714\ttrain-cox-nloglik:3.22683                         \n",
      "\n",
      "[999]\teval-cox-nloglik:5.37925\ttrain-cox-nloglik:3.11234                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07254\ttrain-cox-nloglik:5.52278                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.07002\ttrain-cox-nloglik:3.88717                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.28499\ttrain-cox-nloglik:3.51822                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.41052\ttrain-cox-nloglik:3.33563                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.51083\ttrain-cox-nloglik:3.22066                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09355\ttrain-cox-nloglik:5.53939                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.33641\ttrain-cox-nloglik:3.88780                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.63278\ttrain-cox-nloglik:3.51123                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.81490\ttrain-cox-nloglik:3.32300                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.94888\ttrain-cox-nloglik:3.20413                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23196\ttrain-cox-nloglik:5.48803                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.02247\ttrain-cox-nloglik:3.92917                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12283\ttrain-cox-nloglik:3.56524                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.23886\ttrain-cox-nloglik:3.38462                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.33569\ttrain-cox-nloglik:3.26925                         \n",
      "\n",
      "\tScore 0.695524003842994                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.6713638993599288, 'max_depth': 6, 'min_child_weight': 0.013852814233354384, 'objective': 'survival:cox', 'reg_alpha': 0.041795956680287065, 'reg_lambda': 0.061874159919434395, 'subsample': 0.934358569103573}\n",
      "[0]\teval-cox-nloglik:11.02763\ttrain-cox-nloglik:5.50591                           \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:10.67603\ttrain-cox-nloglik:5.50679                           \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:15.28112\ttrain-cox-nloglik:5.53798                           \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:9.53035\ttrain-cox-nloglik:5.93813                            \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:5.35544\ttrain-cox-nloglik:5.53467                            \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "\tScore 0.0                                                                        \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.4980479426731639, 'max_depth': 2, 'min_child_weight': 9.286982872280506, 'objective': 'survival:cox', 'reg_alpha': 0.0017571806689328253, 'reg_lambda': 0.00385795268687028, 'subsample': 0.7651844824776286}\n",
      "[0]\teval-cox-nloglik:3.78228\ttrain-cox-nloglik:5.26267                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.14793\ttrain-cox-nloglik:3.82800                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.35508\ttrain-cox-nloglik:3.36425                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.16703\ttrain-cox-nloglik:3.06903                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.84478\ttrain-cox-nloglik:2.86150                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09655\ttrain-cox-nloglik:5.16884                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.54467\ttrain-cox-nloglik:3.67440                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.25369\ttrain-cox-nloglik:3.23013                          \n",
      "\n",
      "[750]\teval-cox-nloglik:6.50977\ttrain-cox-nloglik:2.96238                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.12528\ttrain-cox-nloglik:2.75795                          \n",
      "\n",
      "[0]\teval-cox-nloglik:3.87158\ttrain-cox-nloglik:5.26450                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.36297\ttrain-cox-nloglik:3.78870                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.78509\ttrain-cox-nloglik:3.30726                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.63451\ttrain-cox-nloglik:2.99743                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.34503\ttrain-cox-nloglik:2.79107                          \n",
      "\n",
      "[0]\teval-cox-nloglik:3.91771\ttrain-cox-nloglik:5.25812                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.57995\ttrain-cox-nloglik:3.72128                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.13471\ttrain-cox-nloglik:3.28834                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.03091\ttrain-cox-nloglik:2.98235                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.82497\ttrain-cox-nloglik:2.78496                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.01731\ttrain-cox-nloglik:5.22896                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.76194\ttrain-cox-nloglik:3.84856                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.46205\ttrain-cox-nloglik:3.39473                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.66823\ttrain-cox-nloglik:3.09091                          \n",
      "\n",
      "[999]\teval-cox-nloglik:6.01126\ttrain-cox-nloglik:2.87350                          \n",
      "\n",
      "\tScore 0.6367154932550938                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0011154299894610877, 'max_depth': 10, 'min_child_weight': 3.39374690129223, 'objective': 'survival:cox', 'reg_alpha': 0.1210298424626744, 'reg_lambda': 0.021155472854546047, 'subsample': 0.8526844900579423}\n",
      "[0]\teval-cox-nloglik:4.12717\ttrain-cox-nloglik:5.55943                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91577\ttrain-cox-nloglik:5.26951                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83913\ttrain-cox-nloglik:5.07436                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81236\ttrain-cox-nloglik:4.92450                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80483\ttrain-cox-nloglik:4.80358                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26626\ttrain-cox-nloglik:5.51870                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.13273\ttrain-cox-nloglik:5.19186                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12196\ttrain-cox-nloglik:4.98128                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14353\ttrain-cox-nloglik:4.81907                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.18275\ttrain-cox-nloglik:4.68808                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09102\ttrain-cox-nloglik:5.56179                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96198\ttrain-cox-nloglik:5.26746                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91597\ttrain-cox-nloglik:5.06600                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.90462\ttrain-cox-nloglik:4.91252                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90716\ttrain-cox-nloglik:4.78992                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10274\ttrain-cox-nloglik:5.56282                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97407\ttrain-cox-nloglik:5.26415                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92506\ttrain-cox-nloglik:5.06539                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91409\ttrain-cox-nloglik:4.91416                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.93100\ttrain-cox-nloglik:4.78772                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23965\ttrain-cox-nloglik:5.52583                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05890\ttrain-cox-nloglik:5.24064                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.98433\ttrain-cox-nloglik:5.05233                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95605\ttrain-cox-nloglik:4.90894                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.94844\ttrain-cox-nloglik:4.78725                          \n",
      "\n",
      "\tScore 0.7187097242153332                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.07872787981187905, 'max_depth': 2, 'min_child_weight': 0.006608127491472944, 'objective': 'survival:cox', 'reg_alpha': 0.6540536723882797, 'reg_lambda': 0.002575960250085398, 'subsample': 0.7621745334797208}\n",
      "[0]\teval-cox-nloglik:4.99136\ttrain-cox-nloglik:5.72293                           \n",
      "\n",
      "[250]\teval-cox-nloglik:5.07317\ttrain-cox-nloglik:4.36453                         \n",
      "\n",
      "[500]\teval-cox-nloglik:5.12817\ttrain-cox-nloglik:4.04219                         \n",
      "\n",
      "[750]\teval-cox-nloglik:5.16552\ttrain-cox-nloglik:3.81867                         \n",
      "\n",
      "[999]\teval-cox-nloglik:5.78093\ttrain-cox-nloglik:3.64576                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23722\ttrain-cox-nloglik:5.43422                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.47329\ttrain-cox-nloglik:4.22138                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.67881\ttrain-cox-nloglik:3.87586                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.87678\ttrain-cox-nloglik:3.62981                         \n",
      "\n",
      "[999]\teval-cox-nloglik:5.13269\ttrain-cox-nloglik:3.46254                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.03934\ttrain-cox-nloglik:5.49989                           \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97063\ttrain-cox-nloglik:4.41060                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.21663\ttrain-cox-nloglik:4.04013                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.45951\ttrain-cox-nloglik:3.81046                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.76259\ttrain-cox-nloglik:3.64913                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06242\ttrain-cox-nloglik:5.49921                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.30251\ttrain-cox-nloglik:4.31030                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.58809\ttrain-cox-nloglik:3.94378                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.62230\ttrain-cox-nloglik:3.70661                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.79287\ttrain-cox-nloglik:3.52497                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.18313\ttrain-cox-nloglik:5.46274                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.01406\ttrain-cox-nloglik:4.37186                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.26787\ttrain-cox-nloglik:4.06826                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.34753\ttrain-cox-nloglik:3.83881                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.50325\ttrain-cox-nloglik:3.67645                         \n",
      "\n",
      "\tScore 0.6897815899100692                                                        \n",
      "\n",
      "\n",
      "Training with params:                                                            \n",
      "{'eta': 0.10504981112902699, 'max_depth': 9, 'min_child_weight': 0.9040288769374237, 'objective': 'survival:cox', 'reg_alpha': 0.22487534616119, 'reg_lambda': 0.009330205844116405, 'subsample': 0.9553683401131333}\n",
      "[0]\teval-cox-nloglik:4.00326\ttrain-cox-nloglik:5.29995                           \n",
      "\n",
      "[250]\teval-cox-nloglik:7.70382\ttrain-cox-nloglik:2.04238                         \n",
      "\n",
      "[500]\teval-cox-nloglik:8.04347\ttrain-cox-nloglik:2.08955                         \n",
      "\n",
      "[750]\teval-cox-nloglik:7.91424\ttrain-cox-nloglik:2.20519                         \n",
      "\n",
      "[999]\teval-cox-nloglik:7.68185\ttrain-cox-nloglik:2.31348                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.19368\ttrain-cox-nloglik:5.23757                           \n",
      "\n",
      "[250]\teval-cox-nloglik:10.68886\ttrain-cox-nloglik:1.99092                        \n",
      "\n",
      "[500]\teval-cox-nloglik:10.69098\ttrain-cox-nloglik:2.11811                        \n",
      "\n",
      "[750]\teval-cox-nloglik:11.36643\ttrain-cox-nloglik:2.19738                        \n",
      "\n",
      "[999]\teval-cox-nloglik:11.90319\ttrain-cox-nloglik:2.25943                        \n",
      "\n",
      "[0]\teval-cox-nloglik:3.96499\ttrain-cox-nloglik:5.26419                           \n",
      "\n",
      "[250]\teval-cox-nloglik:7.47747\ttrain-cox-nloglik:2.04884                         \n",
      "\n",
      "[500]\teval-cox-nloglik:7.97750\ttrain-cox-nloglik:2.09176                         \n",
      "\n",
      "[750]\teval-cox-nloglik:7.66747\ttrain-cox-nloglik:2.25075                         \n",
      "\n",
      "[999]\teval-cox-nloglik:7.59115\ttrain-cox-nloglik:2.30921                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08198\ttrain-cox-nloglik:5.30537                           \n",
      "\n",
      "[250]\teval-cox-nloglik:10.06656\ttrain-cox-nloglik:1.99318                        \n",
      "\n",
      "[500]\teval-cox-nloglik:11.61867\ttrain-cox-nloglik:1.95644                        \n",
      "\n",
      "[750]\teval-cox-nloglik:12.50960\ttrain-cox-nloglik:2.03704                        \n",
      "\n",
      "[999]\teval-cox-nloglik:13.45161\ttrain-cox-nloglik:2.14209                        \n",
      "\n",
      "[0]\teval-cox-nloglik:4.12816\ttrain-cox-nloglik:5.23879                           \n",
      "\n",
      "[250]\teval-cox-nloglik:7.83319\ttrain-cox-nloglik:2.05788                         \n",
      "\n",
      "[500]\teval-cox-nloglik:9.02776\ttrain-cox-nloglik:1.99293                         \n",
      "\n",
      "[750]\teval-cox-nloglik:9.66897\ttrain-cox-nloglik:2.18351                         \n",
      "\n",
      "[999]\teval-cox-nloglik:10.21998\ttrain-cox-nloglik:2.22286                        \n",
      "\n",
      "\tScore 0.6965569294765876                                                        \n",
      "\n",
      "\n",
      "Training with params:                                                            \n",
      "{'eta': 0.0026761371818664254, 'max_depth': 3, 'min_child_weight': 0.21803737067973478, 'objective': 'survival:cox', 'reg_alpha': 0.001415443680207328, 'reg_lambda': 4.861825142165391, 'subsample': 0.8992914657134297}\n",
      "[0]\teval-cox-nloglik:4.12656\ttrain-cox-nloglik:5.55878                           \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86353\ttrain-cox-nloglik:5.23376                         \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79465\ttrain-cox-nloglik:5.08174                         \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76717\ttrain-cox-nloglik:4.98525                         \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76464\ttrain-cox-nloglik:4.91183                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26570\ttrain-cox-nloglik:5.51811                           \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11052\ttrain-cox-nloglik:5.14789                         \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12442\ttrain-cox-nloglik:4.98475                         \n",
      "\n",
      "[750]\teval-cox-nloglik:4.15907\ttrain-cox-nloglik:4.88563                         \n",
      "\n",
      "[999]\teval-cox-nloglik:4.18965\ttrain-cox-nloglik:4.81386                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09053\ttrain-cox-nloglik:5.56116                           \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90605\ttrain-cox-nloglik:5.24392                         \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85195\ttrain-cox-nloglik:5.09391                         \n",
      "\n",
      "[750]\teval-cox-nloglik:3.83748\ttrain-cox-nloglik:4.99837                         \n",
      "\n",
      "[999]\teval-cox-nloglik:3.83072\ttrain-cox-nloglik:4.92778                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10192\ttrain-cox-nloglik:5.56200                           \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94008\ttrain-cox-nloglik:5.21552                         \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91716\ttrain-cox-nloglik:5.05525                         \n",
      "\n",
      "[750]\teval-cox-nloglik:3.92842\ttrain-cox-nloglik:4.95435                         \n",
      "\n",
      "[999]\teval-cox-nloglik:3.94302\ttrain-cox-nloglik:4.88253                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23882\ttrain-cox-nloglik:5.52517                           \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98930\ttrain-cox-nloglik:5.21971                         \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90975\ttrain-cox-nloglik:5.08420                         \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87979\ttrain-cox-nloglik:4.99695                         \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86041\ttrain-cox-nloglik:4.92860                         \n",
      "\n",
      "\tScore 0.7274802716778429                                                        \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.10553806625241664, 'max_depth': 8, 'min_child_weight': 0.001511219279774833, 'objective': 'survival:cox', 'reg_alpha': 0.6010139510158184, 'reg_lambda': 0.026328052502110965, 'subsample': 0.9342288324360352}\n",
      "[0]\teval-cox-nloglik:4.36789\ttrain-cox-nloglik:5.21671                            \n",
      "\n",
      "[250]\teval-cox-nloglik:8.15478\ttrain-cox-nloglik:2.27958                          \n",
      "\n",
      "[500]\teval-cox-nloglik:9.25055\ttrain-cox-nloglik:2.04137                          \n",
      "\n",
      "[750]\teval-cox-nloglik:9.45627\ttrain-cox-nloglik:2.00770                          \n",
      "\n",
      "[999]\teval-cox-nloglik:9.54176\ttrain-cox-nloglik:2.11037                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.32022\ttrain-cox-nloglik:4.98559                            \n",
      "\n",
      "[250]\teval-cox-nloglik:8.11484\ttrain-cox-nloglik:2.21276                          \n",
      "\n",
      "[500]\teval-cox-nloglik:9.71660\ttrain-cox-nloglik:2.00054                          \n",
      "\n",
      "[750]\teval-cox-nloglik:10.81133\ttrain-cox-nloglik:2.00533                         \n",
      "\n",
      "[999]\teval-cox-nloglik:11.47207\ttrain-cox-nloglik:2.09860                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.36628\ttrain-cox-nloglik:5.10675                            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.99230\ttrain-cox-nloglik:2.28776                          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.79123\ttrain-cox-nloglik:2.05401                          \n",
      "\n",
      "[750]\teval-cox-nloglik:8.68515\ttrain-cox-nloglik:1.96929                          \n",
      "\n",
      "[999]\teval-cox-nloglik:9.02908\ttrain-cox-nloglik:2.08011                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.12846\ttrain-cox-nloglik:5.05079                            \n",
      "\n",
      "[250]\teval-cox-nloglik:8.74542\ttrain-cox-nloglik:2.24424                          \n",
      "\n",
      "[500]\teval-cox-nloglik:10.04487\ttrain-cox-nloglik:2.01432                         \n",
      "\n",
      "[750]\teval-cox-nloglik:10.78703\ttrain-cox-nloglik:1.90238                         \n",
      "\n",
      "[999]\teval-cox-nloglik:11.81547\ttrain-cox-nloglik:1.90947                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10953\ttrain-cox-nloglik:5.14569                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.31776\ttrain-cox-nloglik:2.31347                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.23960\ttrain-cox-nloglik:2.07103                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.02039\ttrain-cox-nloglik:1.97415                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.71239\ttrain-cox-nloglik:1.97784                          \n",
      "\n",
      "\tScore 0.6929379563982787                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0069767901296192165, 'max_depth': 7, 'min_child_weight': 0.0024576570703992878, 'objective': 'survival:cox', 'reg_alpha': 0.001400119098280053, 'reg_lambda': 0.003238268996744419, 'subsample': 0.9882241602472785}\n",
      "[0]\teval-cox-nloglik:4.06078\ttrain-cox-nloglik:5.51057                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.54162\ttrain-cox-nloglik:3.49158                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.26826\ttrain-cox-nloglik:3.00729                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.98378\ttrain-cox-nloglik:2.73400                          \n",
      "\n",
      "[999]\teval-cox-nloglik:6.93745\ttrain-cox-nloglik:2.53498                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24363\ttrain-cox-nloglik:5.48024                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.50902\ttrain-cox-nloglik:3.50137                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.12270\ttrain-cox-nloglik:3.00717                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.69733\ttrain-cox-nloglik:2.73365                          \n",
      "\n",
      "[999]\teval-cox-nloglik:6.35123\ttrain-cox-nloglik:2.53707                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10492\ttrain-cox-nloglik:5.51211                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.38458\ttrain-cox-nloglik:3.48609                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.23303\ttrain-cox-nloglik:3.00544                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.12747\ttrain-cox-nloglik:2.74735                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.38308\ttrain-cox-nloglik:2.56431                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08317\ttrain-cox-nloglik:5.52484                            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.34463\ttrain-cox-nloglik:3.47050                          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.73600\ttrain-cox-nloglik:3.00361                          \n",
      "\n",
      "[750]\teval-cox-nloglik:8.91789\ttrain-cox-nloglik:2.73822                          \n",
      "\n",
      "[999]\teval-cox-nloglik:9.86070\ttrain-cox-nloglik:2.53967                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.19466\ttrain-cox-nloglik:5.47525                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.73520\ttrain-cox-nloglik:3.62376                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.18710\ttrain-cox-nloglik:3.10683                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.53372\ttrain-cox-nloglik:2.80951                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.71184\ttrain-cox-nloglik:2.61240                          \n",
      "\n",
      "\tScore 0.6949180554616324                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0013612850748960883, 'max_depth': 4, 'min_child_weight': 0.047106948034189654, 'objective': 'survival:cox', 'reg_alpha': 0.018701140699677557, 'reg_lambda': 0.001780042781443355, 'subsample': 0.9336394001808818}\n",
      "[0]\teval-cox-nloglik:4.12678\ttrain-cox-nloglik:5.55845                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86731\ttrain-cox-nloglik:5.09489                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95938\ttrain-cox-nloglik:4.86240                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.03337\ttrain-cox-nloglik:4.70245                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.08596\ttrain-cox-nloglik:4.57663                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26326\ttrain-cox-nloglik:5.51700                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.15134\ttrain-cox-nloglik:5.02997                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.18441\ttrain-cox-nloglik:4.78591                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.24202\ttrain-cox-nloglik:4.62070                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.31078\ttrain-cox-nloglik:4.48837                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09162\ttrain-cox-nloglik:5.56088                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.03091\ttrain-cox-nloglik:5.11122                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12342\ttrain-cox-nloglik:4.88282                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.16420\ttrain-cox-nloglik:4.72179                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.18753\ttrain-cox-nloglik:4.60369                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10236\ttrain-cox-nloglik:5.56093                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.02013\ttrain-cox-nloglik:5.09929                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.15139\ttrain-cox-nloglik:4.86681                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.48117\ttrain-cox-nloglik:4.70684                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.64590\ttrain-cox-nloglik:4.57416                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23926\ttrain-cox-nloglik:5.52446                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.02285\ttrain-cox-nloglik:5.10712                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.94136\ttrain-cox-nloglik:4.90339                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.90699\ttrain-cox-nloglik:4.75996                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90178\ttrain-cox-nloglik:4.63825                          \n",
      "\n",
      "\tScore 0.7111321590162583                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0096528325416615, 'max_depth': 7, 'min_child_weight': 0.026767032481409166, 'objective': 'survival:cox', 'reg_alpha': 0.1818821706842526, 'reg_lambda': 2.199658760674382, 'subsample': 0.9621047232924224}\n",
      "[0]\teval-cox-nloglik:4.11952\ttrain-cox-nloglik:5.54750                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90380\ttrain-cox-nloglik:4.09393                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.11680\ttrain-cox-nloglik:3.59021                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.41035\ttrain-cox-nloglik:3.25327                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.64660\ttrain-cox-nloglik:3.02220                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26186\ttrain-cox-nloglik:5.50563                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.43715\ttrain-cox-nloglik:4.01685                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.86996\ttrain-cox-nloglik:3.49178                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.31911\ttrain-cox-nloglik:3.15094                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.78611\ttrain-cox-nloglik:2.92915                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08788\ttrain-cox-nloglik:5.54912                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05441\ttrain-cox-nloglik:4.07308                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.33232\ttrain-cox-nloglik:3.56024                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.61314\ttrain-cox-nloglik:3.25585                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.83724\ttrain-cox-nloglik:3.04450                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09937\ttrain-cox-nloglik:5.55003                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16789\ttrain-cox-nloglik:4.04382                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.65330\ttrain-cox-nloglik:3.52719                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.98275\ttrain-cox-nloglik:3.20374                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.29892\ttrain-cox-nloglik:2.98880                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23145\ttrain-cox-nloglik:5.51332                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.13859\ttrain-cox-nloglik:4.16385                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.30262\ttrain-cox-nloglik:3.67149                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.49757\ttrain-cox-nloglik:3.34703                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.70405\ttrain-cox-nloglik:3.12148                          \n",
      "\n",
      "\tScore 0.6959104968440224                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.9070199930005723, 'max_depth': 2, 'min_child_weight': 0.0011980218180841, 'objective': 'survival:cox', 'reg_alpha': 0.15205720881835827, 'reg_lambda': 0.10009355615819535, 'subsample': 0.824909488839375}\n",
      "[0]\teval-cox-nloglik:5.19971\ttrain-cox-nloglik:6.00689                            \n",
      "\n",
      "[250]\teval-cox-nloglik:7.44359\ttrain-cox-nloglik:2.75820                          \n",
      "\n",
      "[500]\teval-cox-nloglik:9.50734\ttrain-cox-nloglik:2.28939                          \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:5.45993\ttrain-cox-nloglik:5.77050                            \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:3.96101\ttrain-cox-nloglik:5.33080                            \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:3.90942\ttrain-cox-nloglik:5.22469                            \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:3.89417\ttrain-cox-nloglik:5.26626                            \n",
      "\n",
      "[250]\teval-cox-nloglik:8.84000\ttrain-cox-nloglik:2.72473                          \n",
      "\n",
      "[500]\teval-cox-nloglik:9.62088\ttrain-cox-nloglik:2.29241                          \n",
      "\n",
      "[750]\teval-cox-nloglik:11.35752\ttrain-cox-nloglik:2.19463                         \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "\tScore 0.0                                                                        \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.001263904087940109, 'max_depth': 9, 'min_child_weight': 0.024370705046106472, 'objective': 'survival:cox', 'reg_alpha': 0.008874984429987779, 'reg_lambda': 0.005964500285814523, 'subsample': 0.8128491369498538}\n",
      "[0]\teval-cox-nloglik:4.11740\ttrain-cox-nloglik:5.55227                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87023\ttrain-cox-nloglik:4.56413                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.02384\ttrain-cox-nloglik:4.10887                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.22721\ttrain-cox-nloglik:3.81929                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.42643\ttrain-cox-nloglik:3.60698                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26317\ttrain-cox-nloglik:5.51185                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11651\ttrain-cox-nloglik:4.45693                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.19076\ttrain-cox-nloglik:4.00682                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.29058\ttrain-cox-nloglik:3.71904                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.39958\ttrain-cox-nloglik:3.51362                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09030\ttrain-cox-nloglik:5.55412                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94865\ttrain-cox-nloglik:4.55462                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.98466\ttrain-cox-nloglik:4.10334                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.04536\ttrain-cox-nloglik:3.79692                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.11700\ttrain-cox-nloglik:3.58493                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10173\ttrain-cox-nloglik:5.55645                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16597\ttrain-cox-nloglik:4.50546                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.62590\ttrain-cox-nloglik:4.04202                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.08820\ttrain-cox-nloglik:3.74886                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.54530\ttrain-cox-nloglik:3.53923                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24048\ttrain-cox-nloglik:5.51949                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.08871\ttrain-cox-nloglik:4.54829                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10826\ttrain-cox-nloglik:4.10459                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14665\ttrain-cox-nloglik:3.81760                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.20550\ttrain-cox-nloglik:3.60836                          \n",
      "\n",
      "\tScore 0.6979554805730211                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.004399337605234798, 'max_depth': 5, 'min_child_weight': 0.07606561154963155, 'objective': 'survival:cox', 'reg_alpha': 0.04478333528228481, 'reg_lambda': 0.015685094987491485, 'subsample': 0.8238705803656661}\n",
      "[0]\teval-cox-nloglik:4.12059\ttrain-cox-nloglik:5.54865                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.99945\ttrain-cox-nloglik:4.40282                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.16161\ttrain-cox-nloglik:3.99384                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.32892\ttrain-cox-nloglik:3.72821                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.43438\ttrain-cox-nloglik:3.53544                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25694\ttrain-cox-nloglik:5.50821                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.32452\ttrain-cox-nloglik:4.30098                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.56639\ttrain-cox-nloglik:3.86972                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.77362\ttrain-cox-nloglik:3.60137                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.92931\ttrain-cox-nloglik:3.39790                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09254\ttrain-cox-nloglik:5.54959                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.04491\ttrain-cox-nloglik:4.40667                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.22964\ttrain-cox-nloglik:3.98957                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.37199\ttrain-cox-nloglik:3.72944                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.49620\ttrain-cox-nloglik:3.52978                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10063\ttrain-cox-nloglik:5.55333                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.18732\ttrain-cox-nloglik:4.37156                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.68761\ttrain-cox-nloglik:3.96097                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.01467\ttrain-cox-nloglik:3.69483                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.23815\ttrain-cox-nloglik:3.50323                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24032\ttrain-cox-nloglik:5.51423                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91511\ttrain-cox-nloglik:4.48027                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.94434\ttrain-cox-nloglik:4.05502                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.00806\ttrain-cox-nloglik:3.79338                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.05057\ttrain-cox-nloglik:3.60645                          \n",
      "\n",
      "\tScore 0.7103245601213961                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.008614522776129148, 'max_depth': 7, 'min_child_weight': 0.015251059789288897, 'objective': 'survival:cox', 'reg_alpha': 0.002370164156225856, 'reg_lambda': 0.7280792993028645, 'subsample': 0.8560058456294557}\n",
      "[0]\teval-cox-nloglik:4.11980\ttrain-cox-nloglik:5.54365                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.03832\ttrain-cox-nloglik:3.84827                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.38130\ttrain-cox-nloglik:3.30176                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.73170\ttrain-cox-nloglik:2.97865                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.07247\ttrain-cox-nloglik:2.76889                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26384\ttrain-cox-nloglik:5.49834                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.59521\ttrain-cox-nloglik:3.70605                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.15955\ttrain-cox-nloglik:3.15469                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.69126\ttrain-cox-nloglik:2.84771                          \n",
      "\n",
      "[999]\teval-cox-nloglik:6.20383\ttrain-cox-nloglik:2.64479                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08957\ttrain-cox-nloglik:5.54421                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.14072\ttrain-cox-nloglik:3.80798                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.52989\ttrain-cox-nloglik:3.27713                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.85969\ttrain-cox-nloglik:2.97770                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.17864\ttrain-cox-nloglik:2.77616                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09866\ttrain-cox-nloglik:5.54741                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.43530\ttrain-cox-nloglik:3.78568                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.97375\ttrain-cox-nloglik:3.27140                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.47934\ttrain-cox-nloglik:2.98061                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.94560\ttrain-cox-nloglik:2.77788                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23330\ttrain-cox-nloglik:5.50953                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16939\ttrain-cox-nloglik:3.88507                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.37588\ttrain-cox-nloglik:3.36622                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.54238\ttrain-cox-nloglik:3.07162                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.72163\ttrain-cox-nloglik:2.85884                          \n",
      "\n",
      "\tScore 0.6966832017113561                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.001369020940630009, 'max_depth': 7, 'min_child_weight': 2.8595403834037354, 'objective': 'survival:cox', 'reg_alpha': 1.467669863210172, 'reg_lambda': 0.0036995363217453693, 'subsample': 0.8044568279787734}\n",
      "[0]\teval-cox-nloglik:4.12700\ttrain-cox-nloglik:5.55923                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90733\ttrain-cox-nloglik:5.26290                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84024\ttrain-cox-nloglik:5.08113                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81744\ttrain-cox-nloglik:4.94810                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80928\ttrain-cox-nloglik:4.84382                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26623\ttrain-cox-nloglik:5.51846                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.13577\ttrain-cox-nloglik:5.17686                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12771\ttrain-cox-nloglik:4.97532                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.16032\ttrain-cox-nloglik:4.82956                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.19185\ttrain-cox-nloglik:4.71349                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09131\ttrain-cox-nloglik:5.56175                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95655\ttrain-cox-nloglik:5.26377                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90320\ttrain-cox-nloglik:5.07826                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88447\ttrain-cox-nloglik:4.93924                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.87547\ttrain-cox-nloglik:4.83253                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10253\ttrain-cox-nloglik:5.56279                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96882\ttrain-cox-nloglik:5.25732                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92748\ttrain-cox-nloglik:5.06641                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.92506\ttrain-cox-nloglik:4.92692                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.93646\ttrain-cox-nloglik:4.81639                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23959\ttrain-cox-nloglik:5.52574                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.04664\ttrain-cox-nloglik:5.23960                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.96351\ttrain-cox-nloglik:5.06221                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93075\ttrain-cox-nloglik:4.93394                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.91619\ttrain-cox-nloglik:4.83160                          \n",
      "\n",
      "\tScore 0.7208989499301139                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.21621190462382386, 'max_depth': 8, 'min_child_weight': 0.48147293260020146, 'objective': 'survival:cox', 'reg_alpha': 1.090767378838391, 'reg_lambda': 0.0029151866476359286, 'subsample': 0.8974249641190937}\n",
      "[0]\teval-cox-nloglik:4.01347\ttrain-cox-nloglik:5.15911                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.85289\ttrain-cox-nloglik:2.40202                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.59785\ttrain-cox-nloglik:2.23018                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.70072\ttrain-cox-nloglik:2.03772                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.31011\ttrain-cox-nloglik:1.97119                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.38905\ttrain-cox-nloglik:4.93362                            \n",
      "\n",
      "[250]\teval-cox-nloglik:7.33040\ttrain-cox-nloglik:2.29996                          \n",
      "\n",
      "[500]\teval-cox-nloglik:8.20388\ttrain-cox-nloglik:2.10532                          \n",
      "\n",
      "[750]\teval-cox-nloglik:9.60737\ttrain-cox-nloglik:1.99616                          \n",
      "\n",
      "[999]\teval-cox-nloglik:10.49301\ttrain-cox-nloglik:2.02257                         \n",
      "\n",
      "[0]\teval-cox-nloglik:3.96842\ttrain-cox-nloglik:5.07278                            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.26724\ttrain-cox-nloglik:2.39426                          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.04012\ttrain-cox-nloglik:2.21032                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.77019\ttrain-cox-nloglik:2.06983                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.69650\ttrain-cox-nloglik:1.97398                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24235\ttrain-cox-nloglik:4.96550                            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.52199\ttrain-cox-nloglik:2.37190                          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.25951\ttrain-cox-nloglik:2.20232                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.76739\ttrain-cox-nloglik:2.09476                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.55184\ttrain-cox-nloglik:1.96629                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06384\ttrain-cox-nloglik:5.01165                            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.51606\ttrain-cox-nloglik:2.43268                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.95590\ttrain-cox-nloglik:2.26898                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.35260\ttrain-cox-nloglik:2.14026                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.15059\ttrain-cox-nloglik:2.00896                          \n",
      "\n",
      "\tScore 0.6843673257534698                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0026240258205369716, 'max_depth': 4, 'min_child_weight': 0.34247849804676334, 'objective': 'survival:cox', 'reg_alpha': 4.725452642374182, 'reg_lambda': 5.207054401848208, 'subsample': 0.7936829384710472}\n",
      "[0]\teval-cox-nloglik:4.12682\ttrain-cox-nloglik:5.55937                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90954\ttrain-cox-nloglik:5.30224                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83592\ttrain-cox-nloglik:5.16733                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.80452\ttrain-cox-nloglik:5.08360                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79268\ttrain-cox-nloglik:5.02290                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26611\ttrain-cox-nloglik:5.51876                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.13605\ttrain-cox-nloglik:5.22033                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.11827\ttrain-cox-nloglik:5.07991                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.13334\ttrain-cox-nloglik:4.99402                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.15613\ttrain-cox-nloglik:4.93532                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09056\ttrain-cox-nloglik:5.56179                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91480\ttrain-cox-nloglik:5.30990                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85160\ttrain-cox-nloglik:5.18110                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82026\ttrain-cox-nloglik:5.09649                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80637\ttrain-cox-nloglik:5.03618                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10235\ttrain-cox-nloglik:5.56256                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93719\ttrain-cox-nloglik:5.28521                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89488\ttrain-cox-nloglik:5.14841                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89272\ttrain-cox-nloglik:5.06039                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90101\ttrain-cox-nloglik:4.99536                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23926\ttrain-cox-nloglik:5.52570                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.01836\ttrain-cox-nloglik:5.28042                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.93134\ttrain-cox-nloglik:5.16551                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88432\ttrain-cox-nloglik:5.09258                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.85384\ttrain-cox-nloglik:5.03704                          \n",
      "\n",
      "\tScore 0.7312863034059083                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0030040130367618764, 'max_depth': 3, 'min_child_weight': 0.3013112773484995, 'objective': 'survival:cox', 'reg_alpha': 5.776291306258856, 'reg_lambda': 7.451850401587287, 'subsample': 0.8816552265654074}\n",
      "[0]\teval-cox-nloglik:4.12666\ttrain-cox-nloglik:5.55929                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89294\ttrain-cox-nloglik:5.31482                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.81494\ttrain-cox-nloglik:5.19775                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.77560\ttrain-cox-nloglik:5.12817                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.75775\ttrain-cox-nloglik:5.07916                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26591\ttrain-cox-nloglik:5.51855                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.13162\ttrain-cox-nloglik:5.23060                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10608\ttrain-cox-nloglik:5.10388                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11195\ttrain-cox-nloglik:5.03108                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.12735\ttrain-cox-nloglik:4.98503                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09055\ttrain-cox-nloglik:5.56171                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91179\ttrain-cox-nloglik:5.31934                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84788\ttrain-cox-nloglik:5.20635                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81747\ttrain-cox-nloglik:5.13695                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80083\ttrain-cox-nloglik:5.09086                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10214\ttrain-cox-nloglik:5.56247                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93666\ttrain-cox-nloglik:5.28883                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89730\ttrain-cox-nloglik:5.16958                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89758\ttrain-cox-nloglik:5.09443                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90757\ttrain-cox-nloglik:5.04315                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23918\ttrain-cox-nloglik:5.52572                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.01992\ttrain-cox-nloglik:5.28210                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.94093\ttrain-cox-nloglik:5.18321                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89843\ttrain-cox-nloglik:5.12586                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.87142\ttrain-cox-nloglik:5.08516                          \n",
      "\n",
      "\tScore 0.7353389618353481                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.026230724425767026, 'max_depth': 4, 'min_child_weight': 0.18074246720348333, 'objective': 'survival:cox', 'reg_alpha': 6.200168884414787, 'reg_lambda': 9.698023375911198, 'subsample': 0.7979151753655576}\n",
      "[0]\teval-cox-nloglik:4.11510\ttrain-cox-nloglik:5.54848                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.77874\ttrain-cox-nloglik:4.92365                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.80977\ttrain-cox-nloglik:4.79638                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.83922\ttrain-cox-nloglik:4.72864                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.85114\ttrain-cox-nloglik:4.66888                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25910\ttrain-cox-nloglik:5.50604                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.18930\ttrain-cox-nloglik:4.84686                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.22407\ttrain-cox-nloglik:4.70905                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.24417\ttrain-cox-nloglik:4.63066                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.25644\ttrain-cox-nloglik:4.57306                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08023\ttrain-cox-nloglik:5.55115                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.79770\ttrain-cox-nloglik:4.94956                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.81477\ttrain-cox-nloglik:4.82482                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.83379\ttrain-cox-nloglik:4.75329                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.83869\ttrain-cox-nloglik:4.70150                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09532\ttrain-cox-nloglik:5.55185                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96664\ttrain-cox-nloglik:4.89167                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.00165\ttrain-cox-nloglik:4.77171                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.03599\ttrain-cox-nloglik:4.69754                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.06201\ttrain-cox-nloglik:4.64400                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22961\ttrain-cox-nloglik:5.51493                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.79942\ttrain-cox-nloglik:4.95193                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78788\ttrain-cox-nloglik:4.82983                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79762\ttrain-cox-nloglik:4.75819                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80366\ttrain-cox-nloglik:4.70586                          \n",
      "\n",
      "\tScore 0.7302276950175584                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.002636033608450952, 'max_depth': 3, 'min_child_weight': 0.9555338607139514, 'objective': 'survival:cox', 'reg_alpha': 7.630752621923583, 'reg_lambda': 1.0701144250501626, 'subsample': 0.8724496622431234}\n",
      "[0]\teval-cox-nloglik:4.12684\ttrain-cox-nloglik:5.55900                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89716\ttrain-cox-nloglik:5.31028                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82611\ttrain-cox-nloglik:5.20042                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79328\ttrain-cox-nloglik:5.13809                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.77761\ttrain-cox-nloglik:5.09484                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26564\ttrain-cox-nloglik:5.51843                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12601\ttrain-cox-nloglik:5.22041                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10749\ttrain-cox-nloglik:5.10295                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11667\ttrain-cox-nloglik:5.03587                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.12997\ttrain-cox-nloglik:4.99500                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09066\ttrain-cox-nloglik:5.56154                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91445\ttrain-cox-nloglik:5.31938                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85437\ttrain-cox-nloglik:5.21271                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82222\ttrain-cox-nloglik:5.14808                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80502\ttrain-cox-nloglik:5.10717                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10216\ttrain-cox-nloglik:5.56251                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94034\ttrain-cox-nloglik:5.28977                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90116\ttrain-cox-nloglik:5.17691                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89751\ttrain-cox-nloglik:5.10890                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90201\ttrain-cox-nloglik:5.06306                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23910\ttrain-cox-nloglik:5.52562                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.02066\ttrain-cox-nloglik:5.28556                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.94646\ttrain-cox-nloglik:5.19234                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.90640\ttrain-cox-nloglik:5.13890                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88093\ttrain-cox-nloglik:5.10228                          \n",
      "\n",
      "\tScore 0.7326616267286796                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.004007724633806583, 'max_depth': 3, 'min_child_weight': 1.2949717289566898, 'objective': 'survival:cox', 'reg_alpha': 8.393248876569746, 'reg_lambda': 0.7097812462111738, 'subsample': 0.8683657248920278}\n",
      "[0]\teval-cox-nloglik:4.12589\ttrain-cox-nloglik:5.55793                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85037\ttrain-cox-nloglik:5.25104                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79243\ttrain-cox-nloglik:5.14471                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.77164\ttrain-cox-nloglik:5.08860                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76683\ttrain-cox-nloglik:5.04993                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26498\ttrain-cox-nloglik:5.51740                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10956\ttrain-cox-nloglik:5.15554                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.11032\ttrain-cox-nloglik:5.04697                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.13125\ttrain-cox-nloglik:4.98938                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.14882\ttrain-cox-nloglik:4.95500                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09001\ttrain-cox-nloglik:5.56071                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87614\ttrain-cox-nloglik:5.26335                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82171\ttrain-cox-nloglik:5.16012                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79775\ttrain-cox-nloglik:5.10409                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78586\ttrain-cox-nloglik:5.07097                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10169\ttrain-cox-nloglik:5.56172                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91568\ttrain-cox-nloglik:5.22926                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89711\ttrain-cox-nloglik:5.11813                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.90977\ttrain-cox-nloglik:5.05606                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92114\ttrain-cox-nloglik:5.01916                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23844\ttrain-cox-nloglik:5.52483                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97670\ttrain-cox-nloglik:5.23366                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90961\ttrain-cox-nloglik:5.14501                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87369\ttrain-cox-nloglik:5.09796                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.85144\ttrain-cox-nloglik:5.06696                          \n",
      "\n",
      "\tScore 0.7347868619392198                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.018454188404372632, 'max_depth': 5, 'min_child_weight': 3.292024696028164, 'objective': 'survival:cox', 'reg_alpha': 2.8914013814952866, 'reg_lambda': 0.3240517711392779, 'subsample': 0.8750466881870403}\n",
      "[0]\teval-cox-nloglik:4.10870\ttrain-cox-nloglik:5.54118                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89202\ttrain-cox-nloglik:4.61764                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.04978\ttrain-cox-nloglik:4.35536                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14166\ttrain-cox-nloglik:4.18883                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.23202\ttrain-cox-nloglik:4.06855                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25333\ttrain-cox-nloglik:5.49883                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.29889\ttrain-cox-nloglik:4.49472                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.41600\ttrain-cox-nloglik:4.20509                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.49658\ttrain-cox-nloglik:4.02853                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.55751\ttrain-cox-nloglik:3.90950                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07970\ttrain-cox-nloglik:5.54646                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91780\ttrain-cox-nloglik:4.62441                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.03332\ttrain-cox-nloglik:4.34825                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14573\ttrain-cox-nloglik:4.16595                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.22780\ttrain-cox-nloglik:4.03941                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09400\ttrain-cox-nloglik:5.54850                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10132\ttrain-cox-nloglik:4.60000                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.29864\ttrain-cox-nloglik:4.31681                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.47346\ttrain-cox-nloglik:4.14787                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.57290\ttrain-cox-nloglik:4.03297                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22576\ttrain-cox-nloglik:5.51155                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85537\ttrain-cox-nloglik:4.64410                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89210\ttrain-cox-nloglik:4.38415                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93866\ttrain-cox-nloglik:4.21348                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.98720\ttrain-cox-nloglik:4.08783                          \n",
      "\n",
      "\tScore 0.7076270825837732                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.004905662231286298, 'max_depth': 3, 'min_child_weight': 1.6768014350310072, 'objective': 'survival:cox', 'reg_alpha': 9.781366603936629, 'reg_lambda': 1.6949918999332954, 'subsample': 0.9171842464194184}\n",
      "[0]\teval-cox-nloglik:4.12508\ttrain-cox-nloglik:5.55795                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83273\ttrain-cox-nloglik:5.24394                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.77963\ttrain-cox-nloglik:5.14428                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.75803\ttrain-cox-nloglik:5.09366                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.75160\ttrain-cox-nloglik:5.06440                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26466\ttrain-cox-nloglik:5.51699                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10324\ttrain-cox-nloglik:5.14771                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10384\ttrain-cox-nloglik:5.04694                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11913\ttrain-cox-nloglik:4.99836                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.13494\ttrain-cox-nloglik:4.97180                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08967\ttrain-cox-nloglik:5.56035                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87355\ttrain-cox-nloglik:5.25457                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82226\ttrain-cox-nloglik:5.15803                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.80156\ttrain-cox-nloglik:5.11073                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79134\ttrain-cox-nloglik:5.08586                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10119\ttrain-cox-nloglik:5.56087                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91100\ttrain-cox-nloglik:5.22072                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90095\ttrain-cox-nloglik:5.11951                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91365\ttrain-cox-nloglik:5.06577                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92569\ttrain-cox-nloglik:5.03669                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23812\ttrain-cox-nloglik:5.52456                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97128\ttrain-cox-nloglik:5.22595                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91093\ttrain-cox-nloglik:5.14607                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88091\ttrain-cox-nloglik:5.10674                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86600\ttrain-cox-nloglik:5.08528                          \n",
      "\n",
      "\tScore 0.7328406365103455                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0369240901607349, 'max_depth': 4, 'min_child_weight': 7.452172711284479, 'objective': 'survival:cox', 'reg_alpha': 2.7030466667850055, 'reg_lambda': 0.4530447234624261, 'subsample': 0.8741718135239027}\n",
      "[0]\teval-cox-nloglik:4.09133\ttrain-cox-nloglik:5.52774                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94219\ttrain-cox-nloglik:4.64898                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.09850\ttrain-cox-nloglik:4.42369                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.18850\ttrain-cox-nloglik:4.26748                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.29811\ttrain-cox-nloglik:4.15035                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24115\ttrain-cox-nloglik:5.48332                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.32568\ttrain-cox-nloglik:4.50712                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.40470\ttrain-cox-nloglik:4.25379                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.47245\ttrain-cox-nloglik:4.08810                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.54330\ttrain-cox-nloglik:3.96664                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06939\ttrain-cox-nloglik:5.53083                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94571\ttrain-cox-nloglik:4.62081                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.08478\ttrain-cox-nloglik:4.39203                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.18830\ttrain-cox-nloglik:4.22953                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.31562\ttrain-cox-nloglik:4.10838                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08310\ttrain-cox-nloglik:5.53515                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.17592\ttrain-cox-nloglik:4.60105                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.40053\ttrain-cox-nloglik:4.35855                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.60112\ttrain-cox-nloglik:4.19520                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.71739\ttrain-cox-nloglik:4.07831                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.21146\ttrain-cox-nloglik:5.49735                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90622\ttrain-cox-nloglik:4.65512                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.03666\ttrain-cox-nloglik:4.42840                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11121\ttrain-cox-nloglik:4.27715                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.18004\ttrain-cox-nloglik:4.15611                          \n",
      "\n",
      "\tScore 0.7002225416326061                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.002133620257918376, 'max_depth': 5, 'min_child_weight': 0.11984766860903331, 'objective': 'survival:cox', 'reg_alpha': 9.66166817425443, 'reg_lambda': 9.25743154877652, 'subsample': 0.9114221341149656}\n",
      "[0]\teval-cox-nloglik:4.12760\ttrain-cox-nloglik:5.56002                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96482\ttrain-cox-nloglik:5.38871                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88600\ttrain-cox-nloglik:5.28951                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84232\ttrain-cox-nloglik:5.22265                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.81779\ttrain-cox-nloglik:5.17272                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26633\ttrain-cox-nloglik:5.51934                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16962\ttrain-cox-nloglik:5.31907                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.13230\ttrain-cox-nloglik:5.20949                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11839\ttrain-cox-nloglik:5.13733                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.11730\ttrain-cox-nloglik:5.08810                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09114\ttrain-cox-nloglik:5.56235                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96057\ttrain-cox-nloglik:5.39630                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90442\ttrain-cox-nloglik:5.29909                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.86844\ttrain-cox-nloglik:5.23363                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.84638\ttrain-cox-nloglik:5.18737                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10265\ttrain-cox-nloglik:5.56301                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97860\ttrain-cox-nloglik:5.37014                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92596\ttrain-cox-nloglik:5.26530                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.90229\ttrain-cox-nloglik:5.19829                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.89305\ttrain-cox-nloglik:5.14923                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23978\ttrain-cox-nloglik:5.52639                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.08336\ttrain-cox-nloglik:5.35325                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.00648\ttrain-cox-nloglik:5.26238                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.96167\ttrain-cox-nloglik:5.20824                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.93318\ttrain-cox-nloglik:5.17069                          \n",
      "\n",
      "\tScore 0.7245237676678047                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.004203970873361125, 'max_depth': 2, 'min_child_weight': 0.5485839477969549, 'objective': 'survival:cox', 'reg_alpha': 4.099923308059946, 'reg_lambda': 2.485273934775738, 'subsample': 0.779441660608655}\n",
      "[0]\teval-cox-nloglik:4.12554\ttrain-cox-nloglik:5.55834                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80459\ttrain-cox-nloglik:5.24320                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.72758\ttrain-cox-nloglik:5.14391                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.70191\ttrain-cox-nloglik:5.08939                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.69337\ttrain-cox-nloglik:5.04848                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26501\ttrain-cox-nloglik:5.51749                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.08236\ttrain-cox-nloglik:5.14473                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.09419\ttrain-cox-nloglik:5.03341                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.12087\ttrain-cox-nloglik:4.97658                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.14408\ttrain-cox-nloglik:4.93771                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08939\ttrain-cox-nloglik:5.56073                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85817\ttrain-cox-nloglik:5.24747                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79627\ttrain-cox-nloglik:5.14543                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.77163\ttrain-cox-nloglik:5.08806                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76090\ttrain-cox-nloglik:5.05032                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10150\ttrain-cox-nloglik:5.56134                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88444\ttrain-cox-nloglik:5.22204                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86434\ttrain-cox-nloglik:5.10874                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87514\ttrain-cox-nloglik:5.04773                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88843\ttrain-cox-nloglik:5.00963                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23814\ttrain-cox-nloglik:5.52458                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94366\ttrain-cox-nloglik:5.22395                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86034\ttrain-cox-nloglik:5.13388                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81714\ttrain-cox-nloglik:5.08134                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79308\ttrain-cox-nloglik:5.04478                          \n",
      "\n",
      "\tScore 0.7443673092945464                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.013446062150017582, 'max_depth': 2, 'min_child_weight': 0.4500320159481036, 'objective': 'survival:cox', 'reg_alpha': 3.687710235541385, 'reg_lambda': 5.604356372504721, 'subsample': 0.7825075113379418}\n",
      "[0]\teval-cox-nloglik:4.12011\ttrain-cox-nloglik:5.55356                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.70128\ttrain-cox-nloglik:5.09098                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.68865\ttrain-cox-nloglik:4.98887                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.70754\ttrain-cox-nloglik:4.92704                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.72492\ttrain-cox-nloglik:4.87768                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26142\ttrain-cox-nloglik:5.51189                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11616\ttrain-cox-nloglik:4.98396                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.16418\ttrain-cox-nloglik:4.88811                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.19592\ttrain-cox-nloglik:4.82561                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.21061\ttrain-cox-nloglik:4.77614                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08449\ttrain-cox-nloglik:5.55586                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.77841\ttrain-cox-nloglik:5.09085                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.76293\ttrain-cox-nloglik:4.99919                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.77561\ttrain-cox-nloglik:4.94157                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79221\ttrain-cox-nloglik:4.89559                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09808\ttrain-cox-nloglik:5.55614                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88478\ttrain-cox-nloglik:5.04906                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90926\ttrain-cox-nloglik:4.95854                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.94377\ttrain-cox-nloglik:4.90186                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.95802\ttrain-cox-nloglik:4.85791                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23361\ttrain-cox-nloglik:5.51961                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82003\ttrain-cox-nloglik:5.08450                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.76794\ttrain-cox-nloglik:4.99336                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76914\ttrain-cox-nloglik:4.93457                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.77654\ttrain-cox-nloglik:4.88833                          \n",
      "\n",
      "\tScore 0.7412235420856981                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.02998136329730757, 'max_depth': 2, 'min_child_weight': 0.6244121706885611, 'objective': 'survival:cox', 'reg_alpha': 0.4407217565478763, 'reg_lambda': 2.9749081181657746, 'subsample': 0.7810494854528307}\n",
      "[0]\teval-cox-nloglik:4.10414\ttrain-cox-nloglik:5.53972                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.78231\ttrain-cox-nloglik:4.81776                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86382\ttrain-cox-nloglik:4.62683                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95268\ttrain-cox-nloglik:4.48600                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.03093\ttrain-cox-nloglik:4.37641                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25108\ttrain-cox-nloglik:5.49634                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.23471\ttrain-cox-nloglik:4.72599                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.25928\ttrain-cox-nloglik:4.52329                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.32822\ttrain-cox-nloglik:4.37287                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.41395\ttrain-cox-nloglik:4.25469                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07100\ttrain-cox-nloglik:5.54291                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.75846\ttrain-cox-nloglik:4.85077                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84818\ttrain-cox-nloglik:4.66836                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91904\ttrain-cox-nloglik:4.52531                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.00045\ttrain-cox-nloglik:4.40681                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08856\ttrain-cox-nloglik:5.54166                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95003\ttrain-cox-nloglik:4.80602                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.00226\ttrain-cox-nloglik:4.60809                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.05733\ttrain-cox-nloglik:4.46439                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.08608\ttrain-cox-nloglik:4.34361                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22111\ttrain-cox-nloglik:5.50572                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.78593\ttrain-cox-nloglik:4.83646                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85403\ttrain-cox-nloglik:4.65069                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.92315\ttrain-cox-nloglik:4.52142                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.99644\ttrain-cox-nloglik:4.41040                          \n",
      "\n",
      "\tScore 0.7188293163501944                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.01262151242575188, 'max_depth': 2, 'min_child_weight': 0.07034931864604567, 'objective': 'survival:cox', 'reg_alpha': 3.5794322529647458, 'reg_lambda': 0.17262899140308585, 'subsample': 0.7554527758591322}\n",
      "[0]\teval-cox-nloglik:4.11796\ttrain-cox-nloglik:5.55184                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.69971\ttrain-cox-nloglik:5.04058                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.71497\ttrain-cox-nloglik:4.92257                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.74608\ttrain-cox-nloglik:4.85591                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78524\ttrain-cox-nloglik:4.80280                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26017\ttrain-cox-nloglik:5.51016                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.15411\ttrain-cox-nloglik:4.93466                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.20567\ttrain-cox-nloglik:4.83050                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.22764\ttrain-cox-nloglik:4.76117                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.24598\ttrain-cox-nloglik:4.70672                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08312\ttrain-cox-nloglik:5.55457                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.76347\ttrain-cox-nloglik:5.05810                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.75643\ttrain-cox-nloglik:4.95844                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.77467\ttrain-cox-nloglik:4.89145                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79897\ttrain-cox-nloglik:4.83822                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09746\ttrain-cox-nloglik:5.55479                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87575\ttrain-cox-nloglik:5.01820                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90498\ttrain-cox-nloglik:4.92121                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93399\ttrain-cox-nloglik:4.85687                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.94092\ttrain-cox-nloglik:4.80529                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23216\ttrain-cox-nloglik:5.51815                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.79710\ttrain-cox-nloglik:5.05255                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.75314\ttrain-cox-nloglik:4.94811                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76600\ttrain-cox-nloglik:4.88416                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.77909\ttrain-cox-nloglik:4.83256                          \n",
      "\n",
      "\tScore 0.7387404176310618                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.055221156639051985, 'max_depth': 5, 'min_child_weight': 5.693802627483294, 'objective': 'survival:cox', 'reg_alpha': 1.1671486927589496, 'reg_lambda': 2.9935846816323575, 'subsample': 0.7779498957320528}\n",
      "[0]\teval-cox-nloglik:4.08150\ttrain-cox-nloglik:5.51916                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11064\ttrain-cox-nloglik:4.28650                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.45601\ttrain-cox-nloglik:3.90601                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.70343\ttrain-cox-nloglik:3.66045                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.88475\ttrain-cox-nloglik:3.47763                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24111\ttrain-cox-nloglik:5.47508                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.53347\ttrain-cox-nloglik:4.10684                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.73627\ttrain-cox-nloglik:3.72527                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.88831\ttrain-cox-nloglik:3.48336                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.11947\ttrain-cox-nloglik:3.31899                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.05767\ttrain-cox-nloglik:5.52318                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11657\ttrain-cox-nloglik:4.25501                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.45811\ttrain-cox-nloglik:3.87317                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.76317\ttrain-cox-nloglik:3.62206                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.96588\ttrain-cox-nloglik:3.44954                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07975\ttrain-cox-nloglik:5.52491                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.38687\ttrain-cox-nloglik:4.22444                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.83909\ttrain-cox-nloglik:3.84836                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.03814\ttrain-cox-nloglik:3.62152                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.26040\ttrain-cox-nloglik:3.43712                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.20524\ttrain-cox-nloglik:5.48575                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.08185\ttrain-cox-nloglik:4.30240                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.24615\ttrain-cox-nloglik:3.91192                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.38577\ttrain-cox-nloglik:3.66775                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.51784\ttrain-cox-nloglik:3.48178                          \n",
      "\n",
      "\tScore 0.685668999283639                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.274765408159609, 'max_depth': 4, 'min_child_weight': 0.13462598707244783, 'objective': 'survival:cox', 'reg_alpha': 0.04548145898611578, 'reg_lambda': 1.5078195347255057, 'subsample': 0.7789279059534733}\n",
      "[0]\teval-cox-nloglik:3.90902\ttrain-cox-nloglik:5.28854                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.98884\ttrain-cox-nloglik:2.31962                          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.65771\ttrain-cox-nloglik:2.00167                          \n",
      "\n",
      "[750]\teval-cox-nloglik:8.19682\ttrain-cox-nloglik:2.08255                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.98115\ttrain-cox-nloglik:2.24423                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.12797\ttrain-cox-nloglik:5.22711                            \n",
      "\n",
      "[250]\teval-cox-nloglik:8.85155\ttrain-cox-nloglik:2.20516                          \n",
      "\n",
      "[500]\teval-cox-nloglik:10.75111\ttrain-cox-nloglik:2.01754                         \n",
      "\n",
      "[750]\teval-cox-nloglik:11.53229\ttrain-cox-nloglik:2.23580                         \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                  \n",
      "\n",
      "[0]\teval-cox-nloglik:3.98929\ttrain-cox-nloglik:5.31542                            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.61485\ttrain-cox-nloglik:2.34784                          \n",
      "\n",
      "[500]\teval-cox-nloglik:8.55250\ttrain-cox-nloglik:1.99431                          \n",
      "\n",
      "[750]\teval-cox-nloglik:8.90175\ttrain-cox-nloglik:2.07505                          \n",
      "\n",
      "[999]\teval-cox-nloglik:9.09999\ttrain-cox-nloglik:2.17420                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.02982\ttrain-cox-nloglik:5.30924                            \n",
      "\n",
      "[250]\teval-cox-nloglik:7.55720\ttrain-cox-nloglik:2.26567                          \n",
      "\n",
      "[500]\teval-cox-nloglik:9.89710\ttrain-cox-nloglik:1.93230                          \n",
      "\n",
      "[750]\teval-cox-nloglik:11.90096\ttrain-cox-nloglik:2.07134                         \n",
      "\n",
      "[999]\teval-cox-nloglik:13.55914\ttrain-cox-nloglik:2.21675                         \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06217\ttrain-cox-nloglik:5.26973                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.85112\ttrain-cox-nloglik:2.39296                          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.57019\ttrain-cox-nloglik:1.99830                          \n",
      "\n",
      "[750]\teval-cox-nloglik:8.80200\ttrain-cox-nloglik:2.02689                          \n",
      "\n",
      "[999]\teval-cox-nloglik:9.42504\ttrain-cox-nloglik:2.13708                          \n",
      "\n",
      "\tScore 0.5472816541604564                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.01738391922121636, 'max_depth': 2, 'min_child_weight': 1.993902720080442, 'objective': 'survival:cox', 'reg_alpha': 0.0717175115090811, 'reg_lambda': 0.21432077014537781, 'subsample': 0.8304246260804052}\n",
      "[0]\teval-cox-nloglik:4.11207\ttrain-cox-nloglik:5.54309                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.73063\ttrain-cox-nloglik:4.90949                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83125\ttrain-cox-nloglik:4.71336                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88522\ttrain-cox-nloglik:4.58809                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.95628\ttrain-cox-nloglik:4.47937                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25467\ttrain-cox-nloglik:5.50026                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.22515\ttrain-cox-nloglik:4.79882                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.29525\ttrain-cox-nloglik:4.61178                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.34788\ttrain-cox-nloglik:4.47217                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.36563\ttrain-cox-nloglik:4.36061                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07977\ttrain-cox-nloglik:5.54814                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.73992\ttrain-cox-nloglik:4.91987                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78758\ttrain-cox-nloglik:4.74861                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.85440\ttrain-cox-nloglik:4.62248                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.91411\ttrain-cox-nloglik:4.51860                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09239\ttrain-cox-nloglik:5.54851                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90266\ttrain-cox-nloglik:4.87940                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95592\ttrain-cox-nloglik:4.70433                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.97734\ttrain-cox-nloglik:4.56387                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.00081\ttrain-cox-nloglik:4.44874                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22529\ttrain-cox-nloglik:5.51225                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.73898\ttrain-cox-nloglik:4.89473                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.75913\ttrain-cox-nloglik:4.72206                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.80532\ttrain-cox-nloglik:4.59877                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86896\ttrain-cox-nloglik:4.49451                          \n",
      "\n",
      "\tScore 0.728342542517542                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.006569838329681627, 'max_depth': 6, 'min_child_weight': 0.5555118444142542, 'objective': 'survival:cox', 'reg_alpha': 1.9389213035015431, 'reg_lambda': 0.0788022295037132, 'subsample': 0.8393551065063342}\n",
      "[0]\teval-cox-nloglik:4.12489\ttrain-cox-nloglik:5.55147                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82261\ttrain-cox-nloglik:4.58883                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87611\ttrain-cox-nloglik:4.24549                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.98445\ttrain-cox-nloglik:4.01237                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.07846\ttrain-cox-nloglik:3.84579                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26270\ttrain-cox-nloglik:5.50820                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.33303\ttrain-cox-nloglik:4.47951                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.55631\ttrain-cox-nloglik:4.11321                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.70970\ttrain-cox-nloglik:3.87583                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.83373\ttrain-cox-nloglik:3.70895                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08939\ttrain-cox-nloglik:5.55053                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88389\ttrain-cox-nloglik:4.61299                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97307\ttrain-cox-nloglik:4.25453                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.07716\ttrain-cox-nloglik:4.01670                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.16210\ttrain-cox-nloglik:3.84795                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09901\ttrain-cox-nloglik:5.55537                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98094\ttrain-cox-nloglik:4.55748                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10942\ttrain-cox-nloglik:4.19991                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.23170\ttrain-cox-nloglik:3.97465                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.32854\ttrain-cox-nloglik:3.81457                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23861\ttrain-cox-nloglik:5.51603                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94519\ttrain-cox-nloglik:4.63068                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97616\ttrain-cox-nloglik:4.27220                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.01571\ttrain-cox-nloglik:4.04726                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.07568\ttrain-cox-nloglik:3.88212                          \n",
      "\n",
      "\tScore 0.7048413018770795                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0112513312826462, 'max_depth': 3, 'min_child_weight': 0.038894274194293955, 'objective': 'survival:cox', 'reg_alpha': 0.0043976676938807325, 'reg_lambda': 4.8625033507455235, 'subsample': 0.7505202344320024}\n",
      "[0]\teval-cox-nloglik:4.11929\ttrain-cox-nloglik:5.55249                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.77721\ttrain-cox-nloglik:4.89704                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.81422\ttrain-cox-nloglik:4.68153                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88904\ttrain-cox-nloglik:4.52275                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.95317\ttrain-cox-nloglik:4.39091                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26238\ttrain-cox-nloglik:5.51127                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.20451\ttrain-cox-nloglik:4.79576                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.29024\ttrain-cox-nloglik:4.56771                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.35611\ttrain-cox-nloglik:4.39742                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.41106\ttrain-cox-nloglik:4.26104                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08524\ttrain-cox-nloglik:5.55535                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80066\ttrain-cox-nloglik:4.91320                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82994\ttrain-cox-nloglik:4.70305                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89742\ttrain-cox-nloglik:4.53360                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.96674\ttrain-cox-nloglik:4.39590                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09810\ttrain-cox-nloglik:5.55586                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91981\ttrain-cox-nloglik:4.85844                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97135\ttrain-cox-nloglik:4.64901                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.03527\ttrain-cox-nloglik:4.48661                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.07850\ttrain-cox-nloglik:4.33964                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23357\ttrain-cox-nloglik:5.51904                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82677\ttrain-cox-nloglik:4.91503                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83509\ttrain-cox-nloglik:4.70527                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87642\ttrain-cox-nloglik:4.55042                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92101\ttrain-cox-nloglik:4.42115                          \n",
      "\n",
      "\tScore 0.7173558555205827                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.045998674171476475, 'max_depth': 2, 'min_child_weight': 0.0081502125632017, 'objective': 'survival:cox', 'reg_alpha': 0.08367364337350972, 'reg_lambda': 0.03807236863603934, 'subsample': 0.7699342951027766}\n",
      "[0]\teval-cox-nloglik:4.08760\ttrain-cox-nloglik:5.50826                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.34164\ttrain-cox-nloglik:4.49288                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.60848\ttrain-cox-nloglik:4.18502                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.78217\ttrain-cox-nloglik:3.96941                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.97320\ttrain-cox-nloglik:3.80693                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24600\ttrain-cox-nloglik:5.46800                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.39285\ttrain-cox-nloglik:4.38564                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.69944\ttrain-cox-nloglik:4.04799                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.92248\ttrain-cox-nloglik:3.80323                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.20393\ttrain-cox-nloglik:3.62047                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06036\ttrain-cox-nloglik:5.52398                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82665\ttrain-cox-nloglik:4.54727                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.98743\ttrain-cox-nloglik:4.23591                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.21636\ttrain-cox-nloglik:4.00131                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.42573\ttrain-cox-nloglik:3.82657                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07840\ttrain-cox-nloglik:5.52376                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.33589\ttrain-cox-nloglik:4.45697                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.49917\ttrain-cox-nloglik:4.10815                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.57470\ttrain-cox-nloglik:3.88797                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.66580\ttrain-cox-nloglik:3.69721                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.20540\ttrain-cox-nloglik:5.48797                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97791\ttrain-cox-nloglik:4.52804                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.22026\ttrain-cox-nloglik:4.19376                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.32398\ttrain-cox-nloglik:3.97730                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.46735\ttrain-cox-nloglik:3.79942                          \n",
      "\n",
      "\tScore 0.6970856729609329                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.001822857245351403, 'max_depth': 6, 'min_child_weight': 5.263035670902101, 'objective': 'survival:cox', 'reg_alpha': 0.3827101333635288, 'reg_lambda': 0.8186744933576415, 'subsample': 0.8542348860847817}\n",
      "[0]\teval-cox-nloglik:4.12671\ttrain-cox-nloglik:5.55912                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86755\ttrain-cox-nloglik:5.24507                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79313\ttrain-cox-nloglik:5.06962                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76938\ttrain-cox-nloglik:4.94703                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.77022\ttrain-cox-nloglik:4.84969                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26646\ttrain-cox-nloglik:5.51863                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11709\ttrain-cox-nloglik:5.16399                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.11456\ttrain-cox-nloglik:4.97633                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.15099\ttrain-cox-nloglik:4.84501                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.19533\ttrain-cox-nloglik:4.74168                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09065\ttrain-cox-nloglik:5.56142                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93266\ttrain-cox-nloglik:5.24843                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88366\ttrain-cox-nloglik:5.06335                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88108\ttrain-cox-nloglik:4.93277                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.89185\ttrain-cox-nloglik:4.83574                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10228\ttrain-cox-nloglik:5.56238                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94415\ttrain-cox-nloglik:5.23619                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90520\ttrain-cox-nloglik:5.05689                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91188\ttrain-cox-nloglik:4.93045                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.93612\ttrain-cox-nloglik:4.82873                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23894\ttrain-cox-nloglik:5.52550                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.01339\ttrain-cox-nloglik:5.22681                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92787\ttrain-cox-nloglik:5.05621                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89344\ttrain-cox-nloglik:4.93628                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88204\ttrain-cox-nloglik:4.84317                          \n",
      "\n",
      "\tScore 0.7244703763334702                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.024133366207634364, 'max_depth': 3, 'min_child_weight': 0.25042773937342844, 'objective': 'survival:cox', 'reg_alpha': 0.8362124810614395, 'reg_lambda': 0.36877902262568507, 'subsample': 0.9988483701033237}\n",
      "[0]\teval-cox-nloglik:4.10383\ttrain-cox-nloglik:5.53280                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91917\ttrain-cox-nloglik:4.53697                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.07944\ttrain-cox-nloglik:4.24695                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.24545\ttrain-cox-nloglik:4.02372                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.36482\ttrain-cox-nloglik:3.86315                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24961\ttrain-cox-nloglik:5.48770                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.25829\ttrain-cox-nloglik:4.43616                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.52947\ttrain-cox-nloglik:4.06700                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.75826\ttrain-cox-nloglik:3.83524                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.87490\ttrain-cox-nloglik:3.66481                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07522\ttrain-cox-nloglik:5.53754                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85693\ttrain-cox-nloglik:4.61588                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95643\ttrain-cox-nloglik:4.30613                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14130\ttrain-cox-nloglik:4.06967                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.35334\ttrain-cox-nloglik:3.87657                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09212\ttrain-cox-nloglik:5.53475                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.06030\ttrain-cox-nloglik:4.57950                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.15021\ttrain-cox-nloglik:4.25271                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.26996\ttrain-cox-nloglik:3.98320                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.41345\ttrain-cox-nloglik:3.79417                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.21666\ttrain-cox-nloglik:5.50026                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83180\ttrain-cox-nloglik:4.57652                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97523\ttrain-cox-nloglik:4.29283                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11333\ttrain-cox-nloglik:4.10013                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.21629\ttrain-cox-nloglik:3.93359                          \n",
      "\n",
      "\tScore 0.701062897467997                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.096752964705573, 'max_depth': 2, 'min_child_weight': 0.0030059307249567235, 'objective': 'survival:cox', 'reg_alpha': 0.3050691521539708, 'reg_lambda': 2.9202866073799045, 'subsample': 0.8117645694195381}\n",
      "[0]\teval-cox-nloglik:4.07139\ttrain-cox-nloglik:5.49790                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11335\ttrain-cox-nloglik:4.43525                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.30322\ttrain-cox-nloglik:4.13638                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.46958\ttrain-cox-nloglik:3.91903                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.62272\ttrain-cox-nloglik:3.74429                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.21452\ttrain-cox-nloglik:5.44086                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.36058\ttrain-cox-nloglik:4.31784                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.50087\ttrain-cox-nloglik:3.99411                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.79497\ttrain-cox-nloglik:3.76826                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.04396\ttrain-cox-nloglik:3.59272                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.02211\ttrain-cox-nloglik:5.49598                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96736\ttrain-cox-nloglik:4.47046                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.28028\ttrain-cox-nloglik:4.15559                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.47566\ttrain-cox-nloglik:3.93175                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.79622\ttrain-cox-nloglik:3.75203                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.05914\ttrain-cox-nloglik:5.49254                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10308\ttrain-cox-nloglik:4.40443                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.32037\ttrain-cox-nloglik:4.07627                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.43430\ttrain-cox-nloglik:3.85075                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.56079\ttrain-cox-nloglik:3.67302                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.17920\ttrain-cox-nloglik:5.45831                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97247\ttrain-cox-nloglik:4.47352                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.17079\ttrain-cox-nloglik:4.17601                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.31672\ttrain-cox-nloglik:3.96363                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.46583\ttrain-cox-nloglik:3.78723                          \n",
      "\n",
      "\tScore 0.6901679981580824                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.15816993452685396, 'max_depth': 4, 'min_child_weight': 0.9380759886122763, 'objective': 'survival:cox', 'reg_alpha': 0.02019097426760172, 'reg_lambda': 6.917816248767986, 'subsample': 0.7903431934346715}\n",
      "[0]\teval-cox-nloglik:4.01018\ttrain-cox-nloglik:5.44476                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.52860\ttrain-cox-nloglik:3.23956                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.30580\ttrain-cox-nloglik:2.66959                          \n",
      "\n",
      "[750]\teval-cox-nloglik:6.04070\ttrain-cox-nloglik:2.38554                          \n",
      "\n",
      "[999]\teval-cox-nloglik:6.73391\ttrain-cox-nloglik:2.20327                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.21952\ttrain-cox-nloglik:5.39594                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.60455\ttrain-cox-nloglik:3.09978                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.68077\ttrain-cox-nloglik:2.56752                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.74058\ttrain-cox-nloglik:2.28504                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.58258\ttrain-cox-nloglik:2.11090                          \n",
      "\n",
      "[0]\teval-cox-nloglik:3.99952\ttrain-cox-nloglik:5.46065                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.03423\ttrain-cox-nloglik:3.21660                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.16197\ttrain-cox-nloglik:2.69104                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.10375\ttrain-cox-nloglik:2.40447                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.89900\ttrain-cox-nloglik:2.22050                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.03322\ttrain-cox-nloglik:5.45759                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.93365\ttrain-cox-nloglik:3.17102                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.87775\ttrain-cox-nloglik:2.63528                          \n",
      "\n",
      "[750]\teval-cox-nloglik:6.78741\ttrain-cox-nloglik:2.35284                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.69743\ttrain-cox-nloglik:2.16389                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.16205\ttrain-cox-nloglik:5.41510                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.44251\ttrain-cox-nloglik:3.26840                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.04837\ttrain-cox-nloglik:2.73204                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.48984\ttrain-cox-nloglik:2.44295                          \n",
      "\n",
      "[999]\teval-cox-nloglik:6.02665\ttrain-cox-nloglik:2.25575                          \n",
      "\n",
      "\tScore 0.685328189650425                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.005540426925129735, 'max_depth': 3, 'min_child_weight': 0.049055712073714855, 'objective': 'survival:cox', 'reg_alpha': 4.1648751709157255, 'reg_lambda': 1.154546813405545, 'subsample': 0.7512569389526541}\n",
      "[0]\teval-cox-nloglik:4.12397\ttrain-cox-nloglik:5.55690                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80288\ttrain-cox-nloglik:5.13225                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.77693\ttrain-cox-nloglik:5.00081                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79053\ttrain-cox-nloglik:4.91732                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80705\ttrain-cox-nloglik:4.85417                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26447\ttrain-cox-nloglik:5.51615                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11576\ttrain-cox-nloglik:5.03195                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.15842\ttrain-cox-nloglik:4.90339                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.19970\ttrain-cox-nloglik:4.81933                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.23342\ttrain-cox-nloglik:4.75167                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08864\ttrain-cox-nloglik:5.55945                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83127\ttrain-cox-nloglik:5.14093                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78402\ttrain-cox-nloglik:5.01432                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.78480\ttrain-cox-nloglik:4.93181                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79160\ttrain-cox-nloglik:4.87089                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10050\ttrain-cox-nloglik:5.56014                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89481\ttrain-cox-nloglik:5.10719                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91285\ttrain-cox-nloglik:4.96877                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95168\ttrain-cox-nloglik:4.88740                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.97700\ttrain-cox-nloglik:4.82726                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23703\ttrain-cox-nloglik:5.52339                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89940\ttrain-cox-nloglik:5.13542                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82780\ttrain-cox-nloglik:5.01616                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.80155\ttrain-cox-nloglik:4.93800                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79522\ttrain-cox-nloglik:4.87874                          \n",
      "\n",
      "\tScore 0.7368087275131361                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.013928566034893095, 'max_depth': 9, 'min_child_weight': 0.3777454353760868, 'objective': 'survival:cox', 'reg_alpha': 2.267504979968981, 'reg_lambda': 0.5304233559765404, 'subsample': 0.7679943387332921}\n",
      "[0]\teval-cox-nloglik:4.10993\ttrain-cox-nloglik:5.53862                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90963\ttrain-cox-nloglik:4.28854                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.07078\ttrain-cox-nloglik:3.89430                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.22843\ttrain-cox-nloglik:3.67390                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.33606\ttrain-cox-nloglik:3.53724                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26208\ttrain-cox-nloglik:5.49487                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.46409\ttrain-cox-nloglik:4.16244                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.64694\ttrain-cox-nloglik:3.77533                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.77564\ttrain-cox-nloglik:3.56831                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.89616\ttrain-cox-nloglik:3.43283                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08368\ttrain-cox-nloglik:5.54642                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93422\ttrain-cox-nloglik:4.28140                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.05659\ttrain-cox-nloglik:3.90550                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.19018\ttrain-cox-nloglik:3.68779                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.27595\ttrain-cox-nloglik:3.54637                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09690\ttrain-cox-nloglik:5.55028                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05980\ttrain-cox-nloglik:4.24799                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.25049\ttrain-cox-nloglik:3.87634                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.38790\ttrain-cox-nloglik:3.66743                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.48118\ttrain-cox-nloglik:3.52440                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23207\ttrain-cox-nloglik:5.51348                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93462\ttrain-cox-nloglik:4.29980                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.00317\ttrain-cox-nloglik:3.92804                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.07390\ttrain-cox-nloglik:3.71937                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.12686\ttrain-cox-nloglik:3.58001                          \n",
      "\n",
      "\tScore 0.70337000007063                                                           \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.008078380554777454, 'max_depth': 2, 'min_child_weight': 0.1558917470017001, 'objective': 'survival:cox', 'reg_alpha': 0.6127860264232194, 'reg_lambda': 0.1365183237889266, 'subsample': 0.844132992771417}\n",
      "[0]\teval-cox-nloglik:4.12179\ttrain-cox-nloglik:5.55257                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.74198\ttrain-cox-nloglik:5.02416                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82454\ttrain-cox-nloglik:4.87336                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88582\ttrain-cox-nloglik:4.77838                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90923\ttrain-cox-nloglik:4.70251                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26126\ttrain-cox-nloglik:5.51126                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.13784\ttrain-cox-nloglik:4.92396                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.20715\ttrain-cox-nloglik:4.78507                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.25041\ttrain-cox-nloglik:4.68990                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.27498\ttrain-cox-nloglik:4.61141                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08607\ttrain-cox-nloglik:5.55616                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.76364\ttrain-cox-nloglik:5.05709                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.72747\ttrain-cox-nloglik:4.91801                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.74211\ttrain-cox-nloglik:4.82604                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.77400\ttrain-cox-nloglik:4.75001                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09824\ttrain-cox-nloglik:5.55689                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86140\ttrain-cox-nloglik:5.00975                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87839\ttrain-cox-nloglik:4.86912                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88624\ttrain-cox-nloglik:4.77278                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88798\ttrain-cox-nloglik:4.69226                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23351\ttrain-cox-nloglik:5.52032                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80645\ttrain-cox-nloglik:5.02820                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.74514\ttrain-cox-nloglik:4.89398                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.73883\ttrain-cox-nloglik:4.80206                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76009\ttrain-cox-nloglik:4.72422                          \n",
      "\n",
      "\tScore 0.7362128016008604                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.003671487728572456, 'max_depth': 10, 'min_child_weight': 0.09357535665898213, 'objective': 'survival:cox', 'reg_alpha': 1.6942626218980275, 'reg_lambda': 3.7934707679658857, 'subsample': 0.8122434282227463}\n",
      "[0]\teval-cox-nloglik:4.12691\ttrain-cox-nloglik:5.55785                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86333\ttrain-cox-nloglik:5.04998                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83715\ttrain-cox-nloglik:4.77681                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.85615\ttrain-cox-nloglik:4.57430                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88135\ttrain-cox-nloglik:4.41589                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26532\ttrain-cox-nloglik:5.51710                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.14567\ttrain-cox-nloglik:4.96784                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.22567\ttrain-cox-nloglik:4.67426                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.31327\ttrain-cox-nloglik:4.46041                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.37563\ttrain-cox-nloglik:4.29273                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08974\ttrain-cox-nloglik:5.55996                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87337\ttrain-cox-nloglik:5.06468                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85025\ttrain-cox-nloglik:4.78256                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.86498\ttrain-cox-nloglik:4.57461                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88985\ttrain-cox-nloglik:4.41412                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10169\ttrain-cox-nloglik:5.56094                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91837\ttrain-cox-nloglik:5.04818                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92071\ttrain-cox-nloglik:4.75282                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.96429\ttrain-cox-nloglik:4.54336                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.00948\ttrain-cox-nloglik:4.37720                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23829\ttrain-cox-nloglik:5.52416                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95877\ttrain-cox-nloglik:5.06039                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89690\ttrain-cox-nloglik:4.79107                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88266\ttrain-cox-nloglik:4.59124                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88163\ttrain-cox-nloglik:4.43191                          \n",
      "\n",
      "\tScore 0.7145993578961269                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0010442368784777548, 'max_depth': 5, 'min_child_weight': 2.198584634340027, 'objective': 'survival:cox', 'reg_alpha': 0.20280913809487816, 'reg_lambda': 0.043525700699158114, 'subsample': 0.7603550525511082}\n",
      "[0]\teval-cox-nloglik:4.12710\ttrain-cox-nloglik:5.55938                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91632\ttrain-cox-nloglik:5.26656                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83756\ttrain-cox-nloglik:5.07392                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.80769\ttrain-cox-nloglik:4.93289                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79476\ttrain-cox-nloglik:4.82377                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26630\ttrain-cox-nloglik:5.51861                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.14323\ttrain-cox-nloglik:5.19085                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12527\ttrain-cox-nloglik:4.98613                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14260\ttrain-cox-nloglik:4.83921                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.16691\ttrain-cox-nloglik:4.72519                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09154\ttrain-cox-nloglik:5.56176                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97798\ttrain-cox-nloglik:5.26663                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92180\ttrain-cox-nloglik:5.07266                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89703\ttrain-cox-nloglik:4.92886                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88563\ttrain-cox-nloglik:4.82032                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10245\ttrain-cox-nloglik:5.56277                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97103\ttrain-cox-nloglik:5.25579                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92749\ttrain-cox-nloglik:5.05544                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91984\ttrain-cox-nloglik:4.90911                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92354\ttrain-cox-nloglik:4.79887                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23967\ttrain-cox-nloglik:5.52585                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05859\ttrain-cox-nloglik:5.24504                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97545\ttrain-cox-nloglik:5.06481                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93907\ttrain-cox-nloglik:4.93541                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92378\ttrain-cox-nloglik:4.83480                          \n",
      "\n",
      "\tScore 0.7259973784802038                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0214011280076223, 'max_depth': 8, 'min_child_weight': 1.3757466224792427, 'objective': 'survival:cox', 'reg_alpha': 0.12070905632813805, 'reg_lambda': 1.9794095042840492, 'subsample': 0.9477475947865457}\n",
      "[0]\teval-cox-nloglik:4.11512\ttrain-cox-nloglik:5.53462                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12066\ttrain-cox-nloglik:3.60407                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.62491\ttrain-cox-nloglik:3.03869                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.13493\ttrain-cox-nloglik:2.74111                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.63021\ttrain-cox-nloglik:2.55119                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25421\ttrain-cox-nloglik:5.48785                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.88212\ttrain-cox-nloglik:3.49915                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.74427\ttrain-cox-nloglik:2.95397                          \n",
      "\n",
      "[750]\teval-cox-nloglik:6.47470\ttrain-cox-nloglik:2.66461                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.14185\ttrain-cox-nloglik:2.47540                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08190\ttrain-cox-nloglik:5.53600                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.32001\ttrain-cox-nloglik:3.61077                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.87002\ttrain-cox-nloglik:3.05900                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.34664\ttrain-cox-nloglik:2.76926                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.74736\ttrain-cox-nloglik:2.57554                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09476\ttrain-cox-nloglik:5.53658                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.58514\ttrain-cox-nloglik:3.59352                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.20127\ttrain-cox-nloglik:3.01844                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.73555\ttrain-cox-nloglik:2.70918                          \n",
      "\n",
      "[999]\teval-cox-nloglik:6.23148\ttrain-cox-nloglik:2.51360                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22408\ttrain-cox-nloglik:5.49876                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.18733\ttrain-cox-nloglik:3.68224                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.49991\ttrain-cox-nloglik:3.14789                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.92654\ttrain-cox-nloglik:2.83772                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.29017\ttrain-cox-nloglik:2.63143                          \n",
      "\n",
      "\tScore 0.6925968210443081                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.039026188467523114, 'max_depth': 10, 'min_child_weight': 9.295516921078269, 'objective': 'survival:cox', 'reg_alpha': 0.9058033104439362, 'reg_lambda': 0.2853579113107244, 'subsample': 0.8218051096349731}\n",
      "[0]\teval-cox-nloglik:4.08951\ttrain-cox-nloglik:5.52720                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96756\ttrain-cox-nloglik:4.54184                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.22887\ttrain-cox-nloglik:4.23610                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.44968\ttrain-cox-nloglik:4.02691                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.59065\ttrain-cox-nloglik:3.85969                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25025\ttrain-cox-nloglik:5.48183                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.37831\ttrain-cox-nloglik:4.40234                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.52161\ttrain-cox-nloglik:4.08855                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.66922\ttrain-cox-nloglik:3.87485                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.80402\ttrain-cox-nloglik:3.72077                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06706\ttrain-cox-nloglik:5.52707                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.04337\ttrain-cox-nloglik:4.51311                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.29331\ttrain-cox-nloglik:4.19882                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.45720\ttrain-cox-nloglik:3.97746                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.62541\ttrain-cox-nloglik:3.81194                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08005\ttrain-cox-nloglik:5.53087                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.22886\ttrain-cox-nloglik:4.50551                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.62938\ttrain-cox-nloglik:4.19489                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.80975\ttrain-cox-nloglik:3.98877                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.03124\ttrain-cox-nloglik:3.82674                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.20697\ttrain-cox-nloglik:5.49336                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97594\ttrain-cox-nloglik:4.54254                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.14987\ttrain-cox-nloglik:4.25005                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.25868\ttrain-cox-nloglik:4.03037                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.37305\ttrain-cox-nloglik:3.86211                          \n",
      "\n",
      "\tScore 0.6884757256370225                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.001854319161382903, 'max_depth': 2, 'min_child_weight': 0.6636667033364428, 'objective': 'survival:cox', 'reg_alpha': 0.01834600990603057, 'reg_lambda': 0.014650602019953352, 'subsample': 0.7892158680232143}\n",
      "[0]\teval-cox-nloglik:4.12632\ttrain-cox-nloglik:5.55884                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86468\ttrain-cox-nloglik:5.29133                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.76625\ttrain-cox-nloglik:5.16418                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.74185\ttrain-cox-nloglik:5.08603                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.74563\ttrain-cox-nloglik:5.02709                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26655\ttrain-cox-nloglik:5.51875                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12320\ttrain-cox-nloglik:5.20321                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10474\ttrain-cox-nloglik:5.06446                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11944\ttrain-cox-nloglik:4.98160                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.14196\ttrain-cox-nloglik:4.92412                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09119\ttrain-cox-nloglik:5.56167                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91917\ttrain-cox-nloglik:5.30729                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82839\ttrain-cox-nloglik:5.19037                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.77522\ttrain-cox-nloglik:5.11421                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.74335\ttrain-cox-nloglik:5.06010                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10226\ttrain-cox-nloglik:5.56254                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92115\ttrain-cox-nloglik:5.28242                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86007\ttrain-cox-nloglik:5.14859                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84079\ttrain-cox-nloglik:5.06805                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.83418\ttrain-cox-nloglik:5.01072                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23916\ttrain-cox-nloglik:5.52569                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98986\ttrain-cox-nloglik:5.27599                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88176\ttrain-cox-nloglik:5.15559                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82108\ttrain-cox-nloglik:5.08286                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78448\ttrain-cox-nloglik:5.02827                          \n",
      "\n",
      "\tScore 0.7454201352258301                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0014605770418113398, 'max_depth': 4, 'min_child_weight': 0.6843977063552243, 'objective': 'survival:cox', 'reg_alpha': 0.015144388331054283, 'reg_lambda': 0.018401012848639813, 'subsample': 0.984880528965375}\n",
      "[0]\teval-cox-nloglik:4.12621\ttrain-cox-nloglik:5.55794                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87364\ttrain-cox-nloglik:5.16435                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78728\ttrain-cox-nloglik:4.95685                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.73735\ttrain-cox-nloglik:4.80949                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.73430\ttrain-cox-nloglik:4.69466                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26535\ttrain-cox-nloglik:5.51768                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16844\ttrain-cox-nloglik:5.09620                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.19695\ttrain-cox-nloglik:4.86674                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.23398\ttrain-cox-nloglik:4.71103                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.28234\ttrain-cox-nloglik:4.60173                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09127\ttrain-cox-nloglik:5.56051                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.01724\ttrain-cox-nloglik:5.17558                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97994\ttrain-cox-nloglik:4.97844                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.97914\ttrain-cox-nloglik:4.83728                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.98692\ttrain-cox-nloglik:4.73948                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10293\ttrain-cox-nloglik:5.56141                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.04862\ttrain-cox-nloglik:5.16750                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.09938\ttrain-cox-nloglik:4.96283                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.12399\ttrain-cox-nloglik:4.82303                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.13985\ttrain-cox-nloglik:4.71549                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23829\ttrain-cox-nloglik:5.52477                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.01468\ttrain-cox-nloglik:5.17425                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95094\ttrain-cox-nloglik:4.99520                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93686\ttrain-cox-nloglik:4.86608                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92869\ttrain-cox-nloglik:4.76184                           \n",
      "\n",
      "\tScore 0.7119839365805847                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.001809805894527412, 'max_depth': 6, 'min_child_weight': 3.917590876981757, 'objective': 'survival:cox', 'reg_alpha': 0.005349956720397532, 'reg_lambda': 0.0012237575789430164, 'subsample': 0.8876531552397493}\n",
      "[0]\teval-cox-nloglik:4.12615\ttrain-cox-nloglik:5.55844                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85090\ttrain-cox-nloglik:5.15675                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79598\ttrain-cox-nloglik:4.92270                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79349\ttrain-cox-nloglik:4.76031                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79605\ttrain-cox-nloglik:4.63898                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26573\ttrain-cox-nloglik:5.51745                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10856\ttrain-cox-nloglik:5.07063                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.13771\ttrain-cox-nloglik:4.82507                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.19970\ttrain-cox-nloglik:4.65973                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.25186\ttrain-cox-nloglik:4.53904                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09077\ttrain-cox-nloglik:5.56097                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92620\ttrain-cox-nloglik:5.15500                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90445\ttrain-cox-nloglik:4.92232                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.90961\ttrain-cox-nloglik:4.76257                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.93700\ttrain-cox-nloglik:4.64138                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10193\ttrain-cox-nloglik:5.56184                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93796\ttrain-cox-nloglik:5.14394                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91568\ttrain-cox-nloglik:4.90955                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.94464\ttrain-cox-nloglik:4.74983                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.98379\ttrain-cox-nloglik:4.63274                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23881\ttrain-cox-nloglik:5.52485                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.99980\ttrain-cox-nloglik:5.13206                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.94052\ttrain-cox-nloglik:4.91354                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93509\ttrain-cox-nloglik:4.76582                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.93261\ttrain-cox-nloglik:4.65088                           \n",
      "\n",
      "\tScore 0.7198886980415274                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0010466342006121138, 'max_depth': 5, 'min_child_weight': 0.21416681549121303, 'objective': 'survival:cox', 'reg_alpha': 0.0026458494686641782, 'reg_lambda': 0.010768462857003155, 'subsample': 0.8607417624276339}\n",
      "[0]\teval-cox-nloglik:4.12796\ttrain-cox-nloglik:5.55846                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86438\ttrain-cox-nloglik:5.09857                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78264\ttrain-cox-nloglik:4.83244                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81887\ttrain-cox-nloglik:4.64057                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86974\ttrain-cox-nloglik:4.48775                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26536\ttrain-cox-nloglik:5.51800                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.15979\ttrain-cox-nloglik:5.01341                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.17521\ttrain-cox-nloglik:4.73248                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.22648\ttrain-cox-nloglik:4.52974                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.29228\ttrain-cox-nloglik:4.37033                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09157\ttrain-cox-nloglik:5.56053                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96631\ttrain-cox-nloglik:5.10538                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.93539\ttrain-cox-nloglik:4.84061                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.94048\ttrain-cox-nloglik:4.64031                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.96204\ttrain-cox-nloglik:4.48419                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10308\ttrain-cox-nloglik:5.56179                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.03573\ttrain-cox-nloglik:5.07534                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.06290\ttrain-cox-nloglik:4.79571                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.12100\ttrain-cox-nloglik:4.60176                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.17415\ttrain-cox-nloglik:4.44715                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24029\ttrain-cox-nloglik:5.52423                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05384\ttrain-cox-nloglik:5.11155                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.99129\ttrain-cox-nloglik:4.86916                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.97095\ttrain-cox-nloglik:4.68355                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.97311\ttrain-cox-nloglik:4.53324                           \n",
      "\n",
      "\tScore 0.7062171176045939                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0056274186292521915, 'max_depth': 3, 'min_child_weight': 0.00944494267392485, 'objective': 'survival:cox', 'reg_alpha': 0.027083881252537776, 'reg_lambda': 0.005679057934943142, 'subsample': 0.8021939208947649}\n",
      "[0]\teval-cox-nloglik:4.08380\ttrain-cox-nloglik:5.54602                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.21103\ttrain-cox-nloglik:4.83953                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.38128\ttrain-cox-nloglik:4.58046                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.54425\ttrain-cox-nloglik:4.41062                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.74358\ttrain-cox-nloglik:4.25678                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25493\ttrain-cox-nloglik:5.50907                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16593\ttrain-cox-nloglik:4.72554                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.32214\ttrain-cox-nloglik:4.47244                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.44727\ttrain-cox-nloglik:4.29497                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.59054\ttrain-cox-nloglik:4.14072                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08854\ttrain-cox-nloglik:5.55422                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.79322\ttrain-cox-nloglik:4.85739                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85628\ttrain-cox-nloglik:4.59909                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91954\ttrain-cox-nloglik:4.42968                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.98640\ttrain-cox-nloglik:4.28758                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09709\ttrain-cox-nloglik:5.55443                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.48154\ttrain-cox-nloglik:4.78039                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.69950\ttrain-cox-nloglik:4.53694                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.82423\ttrain-cox-nloglik:4.35928                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.83979\ttrain-cox-nloglik:4.20438                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23688\ttrain-cox-nloglik:5.52062                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.76952\ttrain-cox-nloglik:4.86033                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.72444\ttrain-cox-nloglik:4.62753                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.72932\ttrain-cox-nloglik:4.46178                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79174\ttrain-cox-nloglik:4.31914                           \n",
      "\n",
      "\tScore 0.7238353015193756                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.6952253886922246, 'max_depth': 7, 'min_child_weight': 0.016211654355545883, 'objective': 'survival:cox', 'reg_alpha': 0.012984457451533782, 'reg_lambda': 0.0010199446298600318, 'subsample': 0.7902401572106663}\n",
      "[0]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                     \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:31.51268\ttrain-cox-nloglik:nan                                \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:35.55289\ttrain-cox-nloglik:nan                                \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:21.05761\ttrain-cox-nloglik:12.83059                           \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:20.31788\ttrain-cox-nloglik:19.53284                           \n",
      "\n",
      "[250]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[500]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[750]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "\tScore 0.0                                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0016958715941142552, 'max_depth': 4, 'min_child_weight': 0.8319848508730331, 'objective': 'survival:cox', 'reg_alpha': 0.008764348412176676, 'reg_lambda': 0.012378501473418829, 'subsample': 0.8340819015514838}\n",
      "[0]\teval-cox-nloglik:4.12701\ttrain-cox-nloglik:5.55809                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85107\ttrain-cox-nloglik:5.11624                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78087\ttrain-cox-nloglik:4.90019                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.75194\ttrain-cox-nloglik:4.75485                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.77036\ttrain-cox-nloglik:4.63988                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26497\ttrain-cox-nloglik:5.51711                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.15133\ttrain-cox-nloglik:5.03086                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.17374\ttrain-cox-nloglik:4.79656                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.22797\ttrain-cox-nloglik:4.63687                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.28949\ttrain-cox-nloglik:4.51331                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09081\ttrain-cox-nloglik:5.56046                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94431\ttrain-cox-nloglik:5.12590                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90123\ttrain-cox-nloglik:4.91196                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88995\ttrain-cox-nloglik:4.76551                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.89096\ttrain-cox-nloglik:4.65927                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10235\ttrain-cox-nloglik:5.56158                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96136\ttrain-cox-nloglik:5.10949                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.94332\ttrain-cox-nloglik:4.87876                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95835\ttrain-cox-nloglik:4.72530                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.96842\ttrain-cox-nloglik:4.61388                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23866\ttrain-cox-nloglik:5.52428                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97806\ttrain-cox-nloglik:5.12656                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91068\ttrain-cox-nloglik:4.92307                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88106\ttrain-cox-nloglik:4.77965                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.87223\ttrain-cox-nloglik:4.66491                           \n",
      "\n",
      "\tScore 0.7216843547691711                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0037013424755576773, 'max_depth': 9, 'min_child_weight': 1.2483088707706358, 'objective': 'survival:cox', 'reg_alpha': 0.0010586423889863725, 'reg_lambda': 0.006911437642539865, 'subsample': 0.771403253013077}\n",
      "[0]\teval-cox-nloglik:4.12362\ttrain-cox-nloglik:5.55296                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82966\ttrain-cox-nloglik:4.48776                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88986\ttrain-cox-nloglik:3.99676                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.01892\ttrain-cox-nloglik:3.67712                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.16558\ttrain-cox-nloglik:3.44342                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26471\ttrain-cox-nloglik:5.51191                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.21677\ttrain-cox-nloglik:4.39140                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.45466\ttrain-cox-nloglik:3.89622                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.67332\ttrain-cox-nloglik:3.57139                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.89585\ttrain-cox-nloglik:3.33698                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09144\ttrain-cox-nloglik:5.55512                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93189\ttrain-cox-nloglik:4.48532                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.02569\ttrain-cox-nloglik:3.99624                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.17719\ttrain-cox-nloglik:3.68068                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.34395\ttrain-cox-nloglik:3.45295                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09947\ttrain-cox-nloglik:5.55731                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.01790\ttrain-cox-nloglik:4.44419                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.20674\ttrain-cox-nloglik:3.95534                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.40919\ttrain-cox-nloglik:3.64033                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.60356\ttrain-cox-nloglik:3.40960                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23798\ttrain-cox-nloglik:5.51975                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96852\ttrain-cox-nloglik:4.48230                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.05542\ttrain-cox-nloglik:4.01805                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.12478\ttrain-cox-nloglik:3.71289                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.19518\ttrain-cox-nloglik:3.48591                           \n",
      "\n",
      "\tScore 0.7058500315688517                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.003005575009246616, 'max_depth': 2, 'min_child_weight': 2.440167557542844, 'objective': 'survival:cox', 'reg_alpha': 0.0649085326346111, 'reg_lambda': 0.02819368648432979, 'subsample': 0.8467334243153021}\n",
      "[0]\teval-cox-nloglik:4.12560\ttrain-cox-nloglik:5.55776                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80955\ttrain-cox-nloglik:5.23103                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.72719\ttrain-cox-nloglik:5.11738                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.69561\ttrain-cox-nloglik:5.04676                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.69293\ttrain-cox-nloglik:4.99204                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26520\ttrain-cox-nloglik:5.51693                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11144\ttrain-cox-nloglik:5.12481                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12999\ttrain-cox-nloglik:4.99206                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.16674\ttrain-cox-nloglik:4.91843                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.20211\ttrain-cox-nloglik:4.86826                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09046\ttrain-cox-nloglik:5.56079                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87337\ttrain-cox-nloglik:5.23688                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79250\ttrain-cox-nloglik:5.11799                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.75343\ttrain-cox-nloglik:5.04535                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.73447\ttrain-cox-nloglik:4.99401                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10124\ttrain-cox-nloglik:5.56139                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88741\ttrain-cox-nloglik:5.21094                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85554\ttrain-cox-nloglik:5.08386                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.86005\ttrain-cox-nloglik:5.01020                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86799\ttrain-cox-nloglik:4.96053                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23783\ttrain-cox-nloglik:5.52465                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93271\ttrain-cox-nloglik:5.21420                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83730\ttrain-cox-nloglik:5.10036                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79187\ttrain-cox-nloglik:5.02989                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76064\ttrain-cox-nloglik:4.97837                           \n",
      "\n",
      "\tScore 0.7457378609624472                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0022363509925486533, 'max_depth': 8, 'min_child_weight': 2.6345794992894214, 'objective': 'survival:cox', 'reg_alpha': 0.034866600153878456, 'reg_lambda': 0.053485098546865895, 'subsample': 0.9081045487516499}\n",
      "[0]\teval-cox-nloglik:4.12578\ttrain-cox-nloglik:5.55757                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83832\ttrain-cox-nloglik:4.98181                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82332\ttrain-cox-nloglik:4.65695                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.83708\ttrain-cox-nloglik:4.42436                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86243\ttrain-cox-nloglik:4.25304                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26481\ttrain-cox-nloglik:5.51637                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12622\ttrain-cox-nloglik:4.88560                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.19619\ttrain-cox-nloglik:4.54881                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.28456\ttrain-cox-nloglik:4.31416                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.37999\ttrain-cox-nloglik:4.13893                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09111\ttrain-cox-nloglik:5.55959                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94761\ttrain-cox-nloglik:4.97122                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95527\ttrain-cox-nloglik:4.65204                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.98620\ttrain-cox-nloglik:4.42828                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.03231\ttrain-cox-nloglik:4.25541                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10203\ttrain-cox-nloglik:5.56028                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.93518\ttrain-cox-nloglik:4.97145                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.96430\ttrain-cox-nloglik:4.64147                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.04248\ttrain-cox-nloglik:4.41476                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.12793\ttrain-cox-nloglik:4.24102                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23827\ttrain-cox-nloglik:5.52376                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98720\ttrain-cox-nloglik:4.96646                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.96510\ttrain-cox-nloglik:4.65756                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.99374\ttrain-cox-nloglik:4.44090                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.01405\ttrain-cox-nloglik:4.27186                          \n",
      "\n",
      "\tScore 0.7118564016369373                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.009814399759280187, 'max_depth': 3, 'min_child_weight': 6.409351333554157, 'objective': 'survival:cox', 'reg_alpha': 0.06168100108683449, 'reg_lambda': 0.002069508247333244, 'subsample': 0.9203684023114481}\n",
      "[0]\teval-cox-nloglik:4.11922\ttrain-cox-nloglik:5.55385                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.75138\ttrain-cox-nloglik:4.89790                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85280\ttrain-cox-nloglik:4.70903                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.94453\ttrain-cox-nloglik:4.59062                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.00947\ttrain-cox-nloglik:4.48994                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26203\ttrain-cox-nloglik:5.51030                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.22928\ttrain-cox-nloglik:4.81710                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.30348\ttrain-cox-nloglik:4.63296                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.32145\ttrain-cox-nloglik:4.50146                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.34747\ttrain-cox-nloglik:4.38576                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08520\ttrain-cox-nloglik:5.55502                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83468\ttrain-cox-nloglik:4.91381                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90987\ttrain-cox-nloglik:4.72268                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.97707\ttrain-cox-nloglik:4.59299                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.04117\ttrain-cox-nloglik:4.48485                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09786\ttrain-cox-nloglik:5.55304                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95203\ttrain-cox-nloglik:4.87446                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.02263\ttrain-cox-nloglik:4.68529                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11425\ttrain-cox-nloglik:4.55156                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.19621\ttrain-cox-nloglik:4.44787                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23042\ttrain-cox-nloglik:5.51670                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83228\ttrain-cox-nloglik:4.91932                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85787\ttrain-cox-nloglik:4.74063                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91949\ttrain-cox-nloglik:4.61698                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.98751\ttrain-cox-nloglik:4.51760                          \n",
      "\n",
      "\tScore 0.7109634292319267                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.002952617948956581, 'max_depth': 5, 'min_child_weight': 0.0038864295376288727, 'objective': 'survival:cox', 'reg_alpha': 0.00816820031806467, 'reg_lambda': 0.02622720065905732, 'subsample': 0.8219215989112314}\n",
      "[0]\teval-cox-nloglik:4.11987\ttrain-cox-nloglik:5.55257                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96114\ttrain-cox-nloglik:4.61255                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.15337\ttrain-cox-nloglik:4.22659                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.34339\ttrain-cox-nloglik:3.98107                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.43354\ttrain-cox-nloglik:3.79316                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25787\ttrain-cox-nloglik:5.51224                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.20950\ttrain-cox-nloglik:4.49554                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.39351\ttrain-cox-nloglik:4.10520                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.55220\ttrain-cox-nloglik:3.85433                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.67570\ttrain-cox-nloglik:3.66261                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08966\ttrain-cox-nloglik:5.55491                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05605\ttrain-cox-nloglik:4.61757                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.18042\ttrain-cox-nloglik:4.22146                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.27078\ttrain-cox-nloglik:3.97173                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.36251\ttrain-cox-nloglik:3.78366                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09943\ttrain-cox-nloglik:5.55773                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.61719\ttrain-cox-nloglik:4.59042                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.97876\ttrain-cox-nloglik:4.19234                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.20765\ttrain-cox-nloglik:3.93767                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.35810\ttrain-cox-nloglik:3.75485                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24039\ttrain-cox-nloglik:5.51865                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92677\ttrain-cox-nloglik:4.66239                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92523\ttrain-cox-nloglik:4.27862                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93673\ttrain-cox-nloglik:4.02249                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.95864\ttrain-cox-nloglik:3.83968                          \n",
      "\n",
      "\tScore 0.7106061239807125                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0074273267628735045, 'max_depth': 4, 'min_child_weight': 4.248443746474201, 'objective': 'survival:cox', 'reg_alpha': 0.0032605113101644005, 'reg_lambda': 0.007683620944434898, 'subsample': 0.844652863709187}\n",
      "[0]\teval-cox-nloglik:4.11876\ttrain-cox-nloglik:5.55100                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.76423\ttrain-cox-nloglik:4.80113                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84105\ttrain-cox-nloglik:4.57112                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.92070\ttrain-cox-nloglik:4.40561                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.00859\ttrain-cox-nloglik:4.26616                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26114\ttrain-cox-nloglik:5.50922                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.20428\ttrain-cox-nloglik:4.72087                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.32000\ttrain-cox-nloglik:4.47423                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.40619\ttrain-cox-nloglik:4.28063                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.47320\ttrain-cox-nloglik:4.13530                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08673\ttrain-cox-nloglik:5.55509                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86713\ttrain-cox-nloglik:4.81339                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95710\ttrain-cox-nloglik:4.56716                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.02590\ttrain-cox-nloglik:4.40614                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.08784\ttrain-cox-nloglik:4.26297                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09785\ttrain-cox-nloglik:5.55499                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96294\ttrain-cox-nloglik:4.78111                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.04857\ttrain-cox-nloglik:4.53082                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14946\ttrain-cox-nloglik:4.34635                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.22166\ttrain-cox-nloglik:4.20096                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23444\ttrain-cox-nloglik:5.51801                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86059\ttrain-cox-nloglik:4.82121                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86523\ttrain-cox-nloglik:4.59943                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91087\ttrain-cox-nloglik:4.44369                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.95886\ttrain-cox-nloglik:4.30921                          \n",
      "\n",
      "\tScore 0.7100800627435421                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.08042742042470227, 'max_depth': 3, 'min_child_weight': 9.401422727075483, 'objective': 'survival:cox', 'reg_alpha': 0.1276699239956225, 'reg_lambda': 0.10100649054784532, 'subsample': 0.8853131668588056}\n",
      "[0]\teval-cox-nloglik:4.04296\ttrain-cox-nloglik:5.48623                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.20367\ttrain-cox-nloglik:4.33401                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.57353\ttrain-cox-nloglik:3.97473                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.84635\ttrain-cox-nloglik:3.72706                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.09837\ttrain-cox-nloglik:3.53460                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23009\ttrain-cox-nloglik:5.44066                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.51338\ttrain-cox-nloglik:4.19591                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.70846\ttrain-cox-nloglik:3.82804                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.89159\ttrain-cox-nloglik:3.60146                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.06424\ttrain-cox-nloglik:3.41977                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.03731\ttrain-cox-nloglik:5.48580                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.17480\ttrain-cox-nloglik:4.32677                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.53433\ttrain-cox-nloglik:3.96789                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.89084\ttrain-cox-nloglik:3.71290                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.19032\ttrain-cox-nloglik:3.53016                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.05620\ttrain-cox-nloglik:5.49031                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.56224\ttrain-cox-nloglik:4.25730                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.94289\ttrain-cox-nloglik:3.90898                          \n",
      "\n",
      "[750]\teval-cox-nloglik:5.24226\ttrain-cox-nloglik:3.66721                          \n",
      "\n",
      "[999]\teval-cox-nloglik:5.47206\ttrain-cox-nloglik:3.48095                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.17167\ttrain-cox-nloglik:5.45624                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16479\ttrain-cox-nloglik:4.36590                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.39967\ttrain-cox-nloglik:4.01271                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.61544\ttrain-cox-nloglik:3.75070                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.81745\ttrain-cox-nloglik:3.55718                          \n",
      "\n",
      "\tScore 0.6743860730653325                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.47814082454953594, 'max_depth': 2, 'min_child_weight': 1.5972966866015195, 'objective': 'survival:cox', 'reg_alpha': 0.0017752391636099356, 'reg_lambda': 0.014616903911413166, 'subsample': 0.8669152262000129}\n",
      "[0]\teval-cox-nloglik:4.10738\ttrain-cox-nloglik:5.32430                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.75452\ttrain-cox-nloglik:3.34329                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.97232\ttrain-cox-nloglik:2.80970                          \n",
      "\n",
      "[750]\teval-cox-nloglik:7.04719\ttrain-cox-nloglik:2.51362                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.78612\ttrain-cox-nloglik:2.31539                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.41653\ttrain-cox-nloglik:5.20815                            \n",
      "\n",
      "[250]\teval-cox-nloglik:6.66176\ttrain-cox-nloglik:3.19156                          \n",
      "\n",
      "[500]\teval-cox-nloglik:8.84611\ttrain-cox-nloglik:2.65099                          \n",
      "\n",
      "[750]\teval-cox-nloglik:10.42319\ttrain-cox-nloglik:2.35167                         \n",
      "\n",
      "[999]\teval-cox-nloglik:10.75683\ttrain-cox-nloglik:2.18350                         \n",
      "\n",
      "[0]\teval-cox-nloglik:3.86762\ttrain-cox-nloglik:5.25780                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.13051\ttrain-cox-nloglik:3.37888                          \n",
      "\n",
      "[500]\teval-cox-nloglik:7.48364\ttrain-cox-nloglik:2.83301                          \n",
      "\n",
      "[750]\teval-cox-nloglik:9.00160\ttrain-cox-nloglik:2.53635                          \n",
      "\n",
      "[999]\teval-cox-nloglik:10.25905\ttrain-cox-nloglik:2.33944                         \n",
      "\n",
      "[0]\teval-cox-nloglik:3.89861\ttrain-cox-nloglik:5.24614                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.61230\ttrain-cox-nloglik:3.22885                          \n",
      "\n",
      "[500]\teval-cox-nloglik:6.93089\ttrain-cox-nloglik:2.67439                          \n",
      "\n",
      "[750]\teval-cox-nloglik:8.08339\ttrain-cox-nloglik:2.38398                          \n",
      "\n",
      "[999]\teval-cox-nloglik:8.92594\ttrain-cox-nloglik:2.19541                          \n",
      "\n",
      "[0]\teval-cox-nloglik:3.93160\ttrain-cox-nloglik:5.24296                            \n",
      "\n",
      "[250]\teval-cox-nloglik:5.08127\ttrain-cox-nloglik:3.38503                          \n",
      "\n",
      "[500]\teval-cox-nloglik:5.76405\ttrain-cox-nloglik:2.88256                          \n",
      "\n",
      "[750]\teval-cox-nloglik:6.50654\ttrain-cox-nloglik:2.57833                          \n",
      "\n",
      "[999]\teval-cox-nloglik:7.38666\ttrain-cox-nloglik:2.36990                          \n",
      "\n",
      "\tScore 0.6721296549713841                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.003363477202682104, 'max_depth': 2, 'min_child_weight': 0.35880788137919845, 'objective': 'survival:cox', 'reg_alpha': 0.027310436746429436, 'reg_lambda': 0.03025190368137196, 'subsample': 0.8025190828835662}\n",
      "[0]\teval-cox-nloglik:4.12552\ttrain-cox-nloglik:5.55713                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.77200\ttrain-cox-nloglik:5.17533                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.76946\ttrain-cox-nloglik:5.03807                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81481\ttrain-cox-nloglik:4.95060                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86427\ttrain-cox-nloglik:4.88359                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26458\ttrain-cox-nloglik:5.51633                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.09953\ttrain-cox-nloglik:5.07923                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12863\ttrain-cox-nloglik:4.93766                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.17013\ttrain-cox-nloglik:4.85509                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.20524\ttrain-cox-nloglik:4.79499                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08955\ttrain-cox-nloglik:5.56027                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.84524\ttrain-cox-nloglik:5.20290                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.76309\ttrain-cox-nloglik:5.07021                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.72485\ttrain-cox-nloglik:4.98384                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.70983\ttrain-cox-nloglik:4.92447                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10134\ttrain-cox-nloglik:5.56114                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87513\ttrain-cox-nloglik:5.16137                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84664\ttrain-cox-nloglik:5.01569                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.85150\ttrain-cox-nloglik:4.93217                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.85697\ttrain-cox-nloglik:4.86943                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23786\ttrain-cox-nloglik:5.52436                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88744\ttrain-cox-nloglik:5.16986                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79771\ttrain-cox-nloglik:5.04161                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.74705\ttrain-cox-nloglik:4.96376                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.71886\ttrain-cox-nloglik:4.90375                          \n",
      "\n",
      "\tScore 0.7438119776720009                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.004865518768518773, 'max_depth': 3, 'min_child_weight': 0.7825964138241928, 'objective': 'survival:cox', 'reg_alpha': 0.26024820032240353, 'reg_lambda': 0.06966771348119516, 'subsample': 0.8177188434229613}\n",
      "[0]\teval-cox-nloglik:4.12362\ttrain-cox-nloglik:5.55434                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.73679\ttrain-cox-nloglik:4.98084                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.77946\ttrain-cox-nloglik:4.76777                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82996\ttrain-cox-nloglik:4.62486                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86789\ttrain-cox-nloglik:4.51014                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26156\ttrain-cox-nloglik:5.51302                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.15641\ttrain-cox-nloglik:4.86813                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.25717\ttrain-cox-nloglik:4.66301                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.31658\ttrain-cox-nloglik:4.51852                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.37340\ttrain-cox-nloglik:4.40037                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08861\ttrain-cox-nloglik:5.55757                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83458\ttrain-cox-nloglik:5.00131                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79771\ttrain-cox-nloglik:4.81420                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81913\ttrain-cox-nloglik:4.67450                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86468\ttrain-cox-nloglik:4.55888                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10056\ttrain-cox-nloglik:5.55839                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90374\ttrain-cox-nloglik:4.96837                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92564\ttrain-cox-nloglik:4.76798                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95379\ttrain-cox-nloglik:4.62834                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.95696\ttrain-cox-nloglik:4.50369                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23655\ttrain-cox-nloglik:5.52172                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86089\ttrain-cox-nloglik:4.98295                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.80382\ttrain-cox-nloglik:4.78506                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79405\ttrain-cox-nloglik:4.64609                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.81731\ttrain-cox-nloglik:4.53367                          \n",
      "\n",
      "\tScore 0.7304233391147932                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0012585631541089915, 'max_depth': 2, 'min_child_weight': 0.2808930246089617, 'objective': 'survival:cox', 'reg_alpha': 0.055742280048580936, 'reg_lambda': 0.005043867810818231, 'subsample': 0.8309850165479331}\n",
      "[0]\teval-cox-nloglik:4.12749\ttrain-cox-nloglik:5.55959                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90229\ttrain-cox-nloglik:5.34595                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79645\ttrain-cox-nloglik:5.22930                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.75849\ttrain-cox-nloglik:5.15257                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.75284\ttrain-cox-nloglik:5.09603                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26610\ttrain-cox-nloglik:5.51898                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.14538\ttrain-cox-nloglik:5.26879                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10805\ttrain-cox-nloglik:5.14021                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.10339\ttrain-cox-nloglik:5.05718                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.11032\ttrain-cox-nloglik:4.99930                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09136\ttrain-cox-nloglik:5.56226                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96005\ttrain-cox-nloglik:5.36505                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87667\ttrain-cox-nloglik:5.25646                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82040\ttrain-cox-nloglik:5.18260                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78775\ttrain-cox-nloglik:5.12927                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10274\ttrain-cox-nloglik:5.56300                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96139\ttrain-cox-nloglik:5.34173                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89764\ttrain-cox-nloglik:5.21914                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.86740\ttrain-cox-nloglik:5.13757                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.85074\ttrain-cox-nloglik:5.07842                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23936\ttrain-cox-nloglik:5.52614                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.04299\ttrain-cox-nloglik:5.32780                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.93675\ttrain-cox-nloglik:5.21822                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87287\ttrain-cox-nloglik:5.14731                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.83392\ttrain-cox-nloglik:5.09517                          \n",
      "\n",
      "\tScore 0.7435517864622595                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                             \n",
      "{'eta': 0.0020570934235303907, 'max_depth': 2, 'min_child_weight': 1.0366918633482902, 'objective': 'survival:cox', 'reg_alpha': 0.09867275783575628, 'reg_lambda': 0.018996023853840978, 'subsample': 0.7939301950114278}\n",
      "[0]\teval-cox-nloglik:4.12608\ttrain-cox-nloglik:5.55861                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.84872\ttrain-cox-nloglik:5.28211                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.74697\ttrain-cox-nloglik:5.15663                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.72002\ttrain-cox-nloglik:5.07892                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.72490\ttrain-cox-nloglik:5.02013                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26655\ttrain-cox-nloglik:5.51858                            \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11652\ttrain-cox-nloglik:5.18848                          \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10628\ttrain-cox-nloglik:5.05117                          \n",
      "\n",
      "[750]\teval-cox-nloglik:4.12611\ttrain-cox-nloglik:4.97018                          \n",
      "\n",
      "[999]\teval-cox-nloglik:4.15452\ttrain-cox-nloglik:4.91539                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09109\ttrain-cox-nloglik:5.56154                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90917\ttrain-cox-nloglik:5.29355                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82101\ttrain-cox-nloglik:5.17659                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76991\ttrain-cox-nloglik:5.10277                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.74190\ttrain-cox-nloglik:5.05094                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10215\ttrain-cox-nloglik:5.56232                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90921\ttrain-cox-nloglik:5.27193                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85257\ttrain-cox-nloglik:5.13959                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.83753\ttrain-cox-nloglik:5.06015                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.83617\ttrain-cox-nloglik:5.00470                          \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23900\ttrain-cox-nloglik:5.52552                            \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98010\ttrain-cox-nloglik:5.26631                          \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87659\ttrain-cox-nloglik:5.14594                          \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82174\ttrain-cox-nloglik:5.07341                          \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79101\ttrain-cox-nloglik:5.02087                          \n",
      "\n",
      "\tScore 0.7470501181713894                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0020386120939279986, 'max_depth': 3, 'min_child_weight': 2.7280058737244803, 'objective': 'survival:cox', 'reg_alpha': 0.08934868156931172, 'reg_lambda': 0.02171965831890231, 'subsample': 0.8094994319105069}\n",
      "[0]\teval-cox-nloglik:4.12594\ttrain-cox-nloglik:5.55831                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83625\ttrain-cox-nloglik:5.21357                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.76306\ttrain-cox-nloglik:5.06456                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.74092\ttrain-cox-nloglik:4.96751                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.73801\ttrain-cox-nloglik:4.89390                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26514\ttrain-cox-nloglik:5.51758                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11962\ttrain-cox-nloglik:5.11996                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.13474\ttrain-cox-nloglik:4.95258                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.17147\ttrain-cox-nloglik:4.85007                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.20462\ttrain-cox-nloglik:4.77682                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09055\ttrain-cox-nloglik:5.56104                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91514\ttrain-cox-nloglik:5.21569                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85248\ttrain-cox-nloglik:5.06384                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81746\ttrain-cox-nloglik:4.96759                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80361\ttrain-cox-nloglik:4.89843                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10210\ttrain-cox-nloglik:5.56190                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92536\ttrain-cox-nloglik:5.20081                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89094\ttrain-cox-nloglik:5.03933                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88991\ttrain-cox-nloglik:4.94412                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.89603\ttrain-cox-nloglik:4.87390                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23926\ttrain-cox-nloglik:5.52518                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97374\ttrain-cox-nloglik:5.20632                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88359\ttrain-cox-nloglik:5.06441                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84513\ttrain-cox-nloglik:4.97307                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.82179\ttrain-cox-nloglik:4.90170                           \n",
      "\n",
      "\tScore 0.736911054219269                                                           \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.00243817377084671, 'max_depth': 2, 'min_child_weight': 1.2314220223045542, 'objective': 'survival:cox', 'reg_alpha': 0.03552050717456614, 'reg_lambda': 0.004354482603941066, 'subsample': 0.8486363682031695}\n",
      "[0]\teval-cox-nloglik:4.12616\ttrain-cox-nloglik:5.55837                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.84362\ttrain-cox-nloglik:5.26049                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.73331\ttrain-cox-nloglik:5.13207                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.71343\ttrain-cox-nloglik:5.05244                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.72733\ttrain-cox-nloglik:4.99190                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26553\ttrain-cox-nloglik:5.51759                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.11045\ttrain-cox-nloglik:5.15769                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10956\ttrain-cox-nloglik:5.02161                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.13668\ttrain-cox-nloglik:4.94148                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.16357\ttrain-cox-nloglik:4.88735                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09025\ttrain-cox-nloglik:5.56112                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89190\ttrain-cox-nloglik:5.26900                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.80744\ttrain-cox-nloglik:5.15072                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.75880\ttrain-cox-nloglik:5.07736                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.73171\ttrain-cox-nloglik:5.02445                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10176\ttrain-cox-nloglik:5.56187                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89291\ttrain-cox-nloglik:5.24192                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84569\ttrain-cox-nloglik:5.10905                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.83943\ttrain-cox-nloglik:5.02997                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.84311\ttrain-cox-nloglik:4.97588                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23835\ttrain-cox-nloglik:5.52515                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95678\ttrain-cox-nloglik:5.23764                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85835\ttrain-cox-nloglik:5.11894                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81181\ttrain-cox-nloglik:5.04537                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78355\ttrain-cox-nloglik:4.99155                           \n",
      "\n",
      "\tScore 0.7462247428024449                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0024092437523159354, 'max_depth': 2, 'min_child_weight': 4.557016684998857, 'objective': 'survival:cox', 'reg_alpha': 0.18484387319667853, 'reg_lambda': 0.0023172304718813534, 'subsample': 0.859431049524723}\n",
      "[0]\teval-cox-nloglik:4.12590\ttrain-cox-nloglik:5.55852                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83883\ttrain-cox-nloglik:5.27063                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.74787\ttrain-cox-nloglik:5.16174                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.70629\ttrain-cox-nloglik:5.09587                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.69497\ttrain-cox-nloglik:5.04675                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26548\ttrain-cox-nloglik:5.51800                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10841\ttrain-cox-nloglik:5.17355                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12457\ttrain-cox-nloglik:5.04652                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.16047\ttrain-cox-nloglik:4.97527                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.19458\ttrain-cox-nloglik:4.92702                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09028\ttrain-cox-nloglik:5.56116                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90037\ttrain-cox-nloglik:5.27585                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82632\ttrain-cox-nloglik:5.16182                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79392\ttrain-cox-nloglik:5.09209                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78022\ttrain-cox-nloglik:5.04275                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10174\ttrain-cox-nloglik:5.56202                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90394\ttrain-cox-nloglik:5.25493                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87357\ttrain-cox-nloglik:5.13168                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87685\ttrain-cox-nloglik:5.05989                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88817\ttrain-cox-nloglik:5.01392                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23844\ttrain-cox-nloglik:5.52523                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97077\ttrain-cox-nloglik:5.25300                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87191\ttrain-cox-nloglik:5.14929                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82240\ttrain-cox-nloglik:5.08455                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79562\ttrain-cox-nloglik:5.03626                           \n",
      "\n",
      "\tScore 0.7403216914575554                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0010152455569870436, 'max_depth': 3, 'min_child_weight': 2.3521506252461846, 'objective': 'survival:cox', 'reg_alpha': 0.0334086902697349, 'reg_lambda': 0.004299328543526874, 'subsample': 0.8475773377570163}\n",
      "[0]\teval-cox-nloglik:4.12735\ttrain-cox-nloglik:5.55972                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92490\ttrain-cox-nloglik:5.33722                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.83923\ttrain-cox-nloglik:5.21048                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.79197\ttrain-cox-nloglik:5.12461                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76756\ttrain-cox-nloglik:5.05806                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26613\ttrain-cox-nloglik:5.51907                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.14469\ttrain-cox-nloglik:5.26106                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12030\ttrain-cox-nloglik:5.11854                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.12101\ttrain-cox-nloglik:5.01975                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.13106\ttrain-cox-nloglik:4.94789                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09148\ttrain-cox-nloglik:5.56218                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98439\ttrain-cox-nloglik:5.33863                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.92668\ttrain-cox-nloglik:5.20931                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88944\ttrain-cox-nloglik:5.12051                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.85905\ttrain-cox-nloglik:5.05597                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10252\ttrain-cox-nloglik:5.56299                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98702\ttrain-cox-nloglik:5.33251                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.93429\ttrain-cox-nloglik:5.19861                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91107\ttrain-cox-nloglik:5.10666                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90213\ttrain-cox-nloglik:5.03886                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23971\ttrain-cox-nloglik:5.52618                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.06131\ttrain-cox-nloglik:5.32083                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97414\ttrain-cox-nloglik:5.20240                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.92535\ttrain-cox-nloglik:5.12179                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.89526\ttrain-cox-nloglik:5.06088                           \n",
      "\n",
      "\tScore 0.7312149868032731                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.006317767122061554, 'max_depth': 4, 'min_child_weight': 7.389907756600384, 'objective': 'survival:cox', 'reg_alpha': 0.011877391362908987, 'reg_lambda': 0.0016477947789366213, 'subsample': 0.8934946827144847}\n",
      "[0]\teval-cox-nloglik:4.12073\ttrain-cox-nloglik:5.55389                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.73516\ttrain-cox-nloglik:4.96311                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78090\ttrain-cox-nloglik:4.76425                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.85299\ttrain-cox-nloglik:4.63107                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.91887\ttrain-cox-nloglik:4.52871                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26390\ttrain-cox-nloglik:5.51368                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.15648\ttrain-cox-nloglik:4.86244                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.28390\ttrain-cox-nloglik:4.66548                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.35067\ttrain-cox-nloglik:4.52806                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.38935\ttrain-cox-nloglik:4.41516                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08761\ttrain-cox-nloglik:5.55744                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85165\ttrain-cox-nloglik:4.95986                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90431\ttrain-cox-nloglik:4.76574                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95418\ttrain-cox-nloglik:4.63376                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.01093\ttrain-cox-nloglik:4.52920                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09945\ttrain-cox-nloglik:5.55708                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.91654\ttrain-cox-nloglik:4.94224                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97011\ttrain-cox-nloglik:4.74849                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.03844\ttrain-cox-nloglik:4.61057                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.12898\ttrain-cox-nloglik:4.49962                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23413\ttrain-cox-nloglik:5.52064                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85550\ttrain-cox-nloglik:4.95599                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85622\ttrain-cox-nloglik:4.77695                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89777\ttrain-cox-nloglik:4.65976                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.95154\ttrain-cox-nloglik:4.56349                           \n",
      "\n",
      "\tScore 0.7178202412618753                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0015845773989506668, 'max_depth': 3, 'min_child_weight': 1.1016038369443424, 'objective': 'survival:cox', 'reg_alpha': 0.46679170927001784, 'reg_lambda': 0.008511181104087719, 'subsample': 0.8359076708701262}\n",
      "[0]\teval-cox-nloglik:4.12675\ttrain-cox-nloglik:5.55885                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87492\ttrain-cox-nloglik:5.25054                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.77692\ttrain-cox-nloglik:5.10285                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.73708\ttrain-cox-nloglik:5.00673                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.72781\ttrain-cox-nloglik:4.93080                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26539\ttrain-cox-nloglik:5.51820                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12825\ttrain-cox-nloglik:5.16699                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12051\ttrain-cox-nloglik:5.00295                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14674\ttrain-cox-nloglik:4.89446                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.17958\ttrain-cox-nloglik:4.81336                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09134\ttrain-cox-nloglik:5.56131                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95104\ttrain-cox-nloglik:5.25715                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88859\ttrain-cox-nloglik:5.11133                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84777\ttrain-cox-nloglik:5.01679                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.82284\ttrain-cox-nloglik:4.94734                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10221\ttrain-cox-nloglik:5.56234                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95536\ttrain-cox-nloglik:5.24733                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91340\ttrain-cox-nloglik:5.08959                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.90580\ttrain-cox-nloglik:4.98789                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.90375\ttrain-cox-nloglik:4.91331                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23924\ttrain-cox-nloglik:5.52553                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.00548\ttrain-cox-nloglik:5.24323                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91685\ttrain-cox-nloglik:5.10334                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87505\ttrain-cox-nloglik:5.00923                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.84904\ttrain-cox-nloglik:4.93617                           \n",
      "\n",
      "\tScore 0.7315107881082853                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0030571257013776274, 'max_depth': 2, 'min_child_weight': 1.7238770921811668, 'objective': 'survival:cox', 'reg_alpha': 0.15652228605030946, 'reg_lambda': 0.0032024824350171074, 'subsample': 0.8514656445415808}\n",
      "[0]\teval-cox-nloglik:4.12555\ttrain-cox-nloglik:5.55772                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80972\ttrain-cox-nloglik:5.22677                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.73398\ttrain-cox-nloglik:5.11265                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.71133\ttrain-cox-nloglik:5.03915                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.71332\ttrain-cox-nloglik:4.98168                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26516\ttrain-cox-nloglik:5.51687                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10147\ttrain-cox-nloglik:5.11752                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12406\ttrain-cox-nloglik:4.98378                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.16208\ttrain-cox-nloglik:4.90801                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.19523\ttrain-cox-nloglik:4.85415                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08981\ttrain-cox-nloglik:5.56058                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86973\ttrain-cox-nloglik:5.23415                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.78656\ttrain-cox-nloglik:5.11465                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.74878\ttrain-cox-nloglik:5.04137                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.73308\ttrain-cox-nloglik:4.98935                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10136\ttrain-cox-nloglik:5.56130                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87515\ttrain-cox-nloglik:5.20452                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84246\ttrain-cox-nloglik:5.07426                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84855\ttrain-cox-nloglik:4.99967                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.85757\ttrain-cox-nloglik:4.94874                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23785\ttrain-cox-nloglik:5.52467                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92574\ttrain-cox-nloglik:5.20523                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.82779\ttrain-cox-nloglik:5.08790                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.78456\ttrain-cox-nloglik:5.01427                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.75940\ttrain-cox-nloglik:4.96057                           \n",
      "\n",
      "\tScore 0.7448445864356522                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0110828212314653, 'max_depth': 4, 'min_child_weight': 3.690000755814607, 'objective': 'survival:cox', 'reg_alpha': 0.10789969868957595, 'reg_lambda': 0.12404246659237014, 'subsample': 0.9031957345742221}\n",
      "[0]\teval-cox-nloglik:4.11416\ttrain-cox-nloglik:5.54649                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.78598\ttrain-cox-nloglik:4.63737                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91350\ttrain-cox-nloglik:4.36387                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.03291\ttrain-cox-nloglik:4.15293                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.10699\ttrain-cox-nloglik:3.99710                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25648\ttrain-cox-nloglik:5.50333                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.26129\ttrain-cox-nloglik:4.54423                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.40271\ttrain-cox-nloglik:4.23598                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.52962\ttrain-cox-nloglik:4.01127                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.65267\ttrain-cox-nloglik:3.83608                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08343\ttrain-cox-nloglik:5.55008                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90534\ttrain-cox-nloglik:4.66505                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.01239\ttrain-cox-nloglik:4.37162                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.15007\ttrain-cox-nloglik:4.15547                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.27714\ttrain-cox-nloglik:3.98255                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09919\ttrain-cox-nloglik:5.54923                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.00733\ttrain-cox-nloglik:4.64253                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.11034\ttrain-cox-nloglik:4.33398                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.27620\ttrain-cox-nloglik:4.11130                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.40185\ttrain-cox-nloglik:3.93872                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22840\ttrain-cox-nloglik:5.51279                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86462\ttrain-cox-nloglik:4.69027                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91037\ttrain-cox-nloglik:4.40424                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.99760\ttrain-cox-nloglik:4.20708                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.06137\ttrain-cox-nloglik:4.04156                           \n",
      "\n",
      "\tScore 0.7018703124406219                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0012364031316426398, 'max_depth': 2, 'min_child_weight': 0.1994592878769995, 'objective': 'survival:cox', 'reg_alpha': 0.006878304853826192, 'reg_lambda': 0.0014351965579106338, 'subsample': 0.8787320630531853}\n",
      "[0]\teval-cox-nloglik:4.12750\ttrain-cox-nloglik:5.55960                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89986\ttrain-cox-nloglik:5.34588                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79680\ttrain-cox-nloglik:5.22830                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76207\ttrain-cox-nloglik:5.15159                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76135\ttrain-cox-nloglik:5.09589                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26610\ttrain-cox-nloglik:5.51900                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.14254\ttrain-cox-nloglik:5.27176                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10569\ttrain-cox-nloglik:5.14210                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.09903\ttrain-cox-nloglik:5.05933                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.10425\ttrain-cox-nloglik:5.00109                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09092\ttrain-cox-nloglik:5.56211                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.95936\ttrain-cox-nloglik:5.36648                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88031\ttrain-cox-nloglik:5.25706                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82647\ttrain-cox-nloglik:5.18476                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78905\ttrain-cox-nloglik:5.13123                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10283\ttrain-cox-nloglik:5.56289                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97608\ttrain-cox-nloglik:5.34324                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91406\ttrain-cox-nloglik:5.22038                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88210\ttrain-cox-nloglik:5.13843                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86417\ttrain-cox-nloglik:5.07950                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23932\ttrain-cox-nloglik:5.52615                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05281\ttrain-cox-nloglik:5.33113                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.94947\ttrain-cox-nloglik:5.22337                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88587\ttrain-cox-nloglik:5.15163                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.84192\ttrain-cox-nloglik:5.09845                           \n",
      "\n",
      "\tScore 0.7414258713661697                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.01567263020995118, 'max_depth': 3, 'min_child_weight': 0.41038059790401415, 'objective': 'survival:cox', 'reg_alpha': 0.05112789204217516, 'reg_lambda': 0.04350865122227041, 'subsample': 0.9233494197357279}\n",
      "[0]\teval-cox-nloglik:4.10568\ttrain-cox-nloglik:5.53840                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98557\ttrain-cox-nloglik:4.56511                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.09408\ttrain-cox-nloglik:4.24273                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.21946\ttrain-cox-nloglik:3.99997                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.31459\ttrain-cox-nloglik:3.80422                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24952\ttrain-cox-nloglik:5.49534                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.34417\ttrain-cox-nloglik:4.45866                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.50702\ttrain-cox-nloglik:4.11132                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.68016\ttrain-cox-nloglik:3.86806                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.86920\ttrain-cox-nloglik:3.66303                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08471\ttrain-cox-nloglik:5.54340                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83399\ttrain-cox-nloglik:4.59325                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.93813\ttrain-cox-nloglik:4.26521                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.03989\ttrain-cox-nloglik:4.03372                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.16709\ttrain-cox-nloglik:3.84681                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09205\ttrain-cox-nloglik:5.54437                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.99532\ttrain-cox-nloglik:4.55134                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.06491\ttrain-cox-nloglik:4.21772                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.13743\ttrain-cox-nloglik:3.95673                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.27572\ttrain-cox-nloglik:3.76845                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22336\ttrain-cox-nloglik:5.50825                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.76469\ttrain-cox-nloglik:4.58618                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86590\ttrain-cox-nloglik:4.25856                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.96018\ttrain-cox-nloglik:4.02636                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.07002\ttrain-cox-nloglik:3.83466                           \n",
      "\n",
      "\tScore 0.7129407429483764                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.005011566869941168, 'max_depth': 2, 'min_child_weight': 0.06365428029748096, 'objective': 'survival:cox', 'reg_alpha': 0.06569357074066172, 'reg_lambda': 0.010309322304418845, 'subsample': 0.8663489372525387}\n",
      "[0]\teval-cox-nloglik:4.12411\ttrain-cox-nloglik:5.55534                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80124\ttrain-cox-nloglik:5.08307                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91159\ttrain-cox-nloglik:4.93657                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.02678\ttrain-cox-nloglik:4.84333                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.07838\ttrain-cox-nloglik:4.77066                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26342\ttrain-cox-nloglik:5.51431                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.09989\ttrain-cox-nloglik:4.98967                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.15241\ttrain-cox-nloglik:4.84551                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.21120\ttrain-cox-nloglik:4.75997                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.25643\ttrain-cox-nloglik:4.68643                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08770\ttrain-cox-nloglik:5.55849                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.77940\ttrain-cox-nloglik:5.12104                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.71709\ttrain-cox-nloglik:4.97491                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.70243\ttrain-cox-nloglik:4.88734                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.71079\ttrain-cox-nloglik:4.81730                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10019\ttrain-cox-nloglik:5.55921                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85370\ttrain-cox-nloglik:5.07323                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84690\ttrain-cox-nloglik:4.92549                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.86248\ttrain-cox-nloglik:4.83621                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86867\ttrain-cox-nloglik:4.76948                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23564\ttrain-cox-nloglik:5.52270                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82651\ttrain-cox-nloglik:5.09448                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.75248\ttrain-cox-nloglik:4.95798                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.72894\ttrain-cox-nloglik:4.87153                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.72474\ttrain-cox-nloglik:4.80398                           \n",
      "\n",
      "\tScore 0.7422832515501422                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.008583094224573618, 'max_depth': 5, 'min_child_weight': 0.03329684168593331, 'objective': 'survival:cox', 'reg_alpha': 0.07843683248701298, 'reg_lambda': 0.05416669350725301, 'subsample': 0.8292100705566082}\n",
      "[0]\teval-cox-nloglik:4.11608\ttrain-cox-nloglik:5.53877                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.06461\ttrain-cox-nloglik:4.03100                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.29150\ttrain-cox-nloglik:3.57511                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.53263\ttrain-cox-nloglik:3.27874                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.72655\ttrain-cox-nloglik:3.07104                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25399\ttrain-cox-nloglik:5.49576                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.53358\ttrain-cox-nloglik:3.92067                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.91507\ttrain-cox-nloglik:3.44507                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.16341\ttrain-cox-nloglik:3.15186                           \n",
      "\n",
      "[999]\teval-cox-nloglik:5.42769\ttrain-cox-nloglik:2.94784                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09194\ttrain-cox-nloglik:5.53946                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.27126\ttrain-cox-nloglik:4.06290                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.54404\ttrain-cox-nloglik:3.58162                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.76237\ttrain-cox-nloglik:3.29241                           \n",
      "\n",
      "[999]\teval-cox-nloglik:5.00233\ttrain-cox-nloglik:3.08218                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09438\ttrain-cox-nloglik:5.54516                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.89804\ttrain-cox-nloglik:4.01893                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.49770\ttrain-cox-nloglik:3.54922                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.92835\ttrain-cox-nloglik:3.26183                           \n",
      "\n",
      "[999]\teval-cox-nloglik:6.33504\ttrain-cox-nloglik:3.05123                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24019\ttrain-cox-nloglik:5.50415                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97614\ttrain-cox-nloglik:4.11226                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.03978\ttrain-cox-nloglik:3.65169                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.13163\ttrain-cox-nloglik:3.35892                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.25806\ttrain-cox-nloglik:3.13679                           \n",
      "\n",
      "\tScore 0.7081843419667249                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0026152620101261735, 'max_depth': 6, 'min_child_weight': 0.10258510362421491, 'objective': 'survival:cox', 'reg_alpha': 0.30694944750216085, 'reg_lambda': 0.017861554984862194, 'subsample': 0.9419770143925023}\n",
      "[0]\teval-cox-nloglik:4.12639\ttrain-cox-nloglik:5.55220                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80816\ttrain-cox-nloglik:4.54364                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.88767\ttrain-cox-nloglik:4.07663                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.00370\ttrain-cox-nloglik:3.78959                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.13535\ttrain-cox-nloglik:3.58898                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26325\ttrain-cox-nloglik:5.51092                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.25069\ttrain-cox-nloglik:4.45364                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.44738\ttrain-cox-nloglik:4.02541                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.62781\ttrain-cox-nloglik:3.74397                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.80494\ttrain-cox-nloglik:3.52802                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09143\ttrain-cox-nloglik:5.55489                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05356\ttrain-cox-nloglik:4.51351                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.23471\ttrain-cox-nloglik:4.06965                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.36857\ttrain-cox-nloglik:3.79709                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.49375\ttrain-cox-nloglik:3.60235                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10198\ttrain-cox-nloglik:5.55745                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.32076\ttrain-cox-nloglik:4.49325                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.59701\ttrain-cox-nloglik:4.05845                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.85935\ttrain-cox-nloglik:3.78732                           \n",
      "\n",
      "[999]\teval-cox-nloglik:5.25887\ttrain-cox-nloglik:3.60188                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23670\ttrain-cox-nloglik:5.51933                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.05337\ttrain-cox-nloglik:4.58770                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.07785\ttrain-cox-nloglik:4.15549                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.16424\ttrain-cox-nloglik:3.88701                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.23036\ttrain-cox-nloglik:3.71120                           \n",
      "\n",
      "\tScore 0.6996325418881313                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.2818070813452793, 'max_depth': 4, 'min_child_weight': 0.5025296127612215, 'objective': 'survival:cox', 'reg_alpha': 0.03666472173117706, 'reg_lambda': 0.00410839969642594, 'subsample': 0.9715804994693026}\n",
      "[0]\teval-cox-nloglik:3.85186\ttrain-cox-nloglik:5.22168                             \n",
      "\n",
      "[250]\teval-cox-nloglik:8.23249\ttrain-cox-nloglik:2.11216                           \n",
      "\n",
      "[500]\teval-cox-nloglik:8.88046\ttrain-cox-nloglik:2.41949                           \n",
      "\n",
      "[750]\teval-cox-nloglik:9.17564\ttrain-cox-nloglik:2.50047                           \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:4.15610\ttrain-cox-nloglik:5.11038                             \n",
      "\n",
      "[250]\teval-cox-nloglik:9.82343\ttrain-cox-nloglik:2.05963                           \n",
      "\n",
      "[500]\teval-cox-nloglik:10.17413\ttrain-cox-nloglik:2.29458                          \n",
      "\n",
      "[750]\teval-cox-nloglik:11.72044\ttrain-cox-nloglik:2.40071                          \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:4.04827\ttrain-cox-nloglik:5.12708                             \n",
      "\n",
      "[250]\teval-cox-nloglik:10.33414\ttrain-cox-nloglik:2.06327                          \n",
      "\n",
      "[500]\teval-cox-nloglik:10.00915\ttrain-cox-nloglik:2.31784                          \n",
      "\n",
      "[750]\teval-cox-nloglik:10.37454\ttrain-cox-nloglik:2.46014                          \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:3.98097\ttrain-cox-nloglik:5.13710                             \n",
      "\n",
      "[250]\teval-cox-nloglik:9.12189\ttrain-cox-nloglik:2.03866                           \n",
      "\n",
      "[500]\teval-cox-nloglik:10.87502\ttrain-cox-nloglik:2.27388                          \n",
      "\n",
      "[750]\teval-cox-nloglik:10.69134\ttrain-cox-nloglik:2.37876                          \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "[0]\teval-cox-nloglik:3.94030\ttrain-cox-nloglik:5.14968                             \n",
      "\n",
      "[250]\teval-cox-nloglik:6.28440\ttrain-cox-nloglik:2.10191                           \n",
      "\n",
      "[500]\teval-cox-nloglik:7.64287\ttrain-cox-nloglik:2.16272                           \n",
      "\n",
      "[750]\teval-cox-nloglik:8.48522\ttrain-cox-nloglik:2.47923                           \n",
      "\n",
      "[999]\teval-cox-nloglik:nan\ttrain-cox-nloglik:nan                                   \n",
      "\n",
      "\tScore 0.0                                                                         \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0043824261697617975, 'max_depth': 2, 'min_child_weight': 1.739847761706657, 'objective': 'survival:cox', 'reg_alpha': 0.02320932899650902, 'reg_lambda': 0.02642017981915707, 'subsample': 0.892287312696807}\n",
      "[0]\teval-cox-nloglik:4.12423\ttrain-cox-nloglik:5.55627                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.76679\ttrain-cox-nloglik:5.17030                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.70680\ttrain-cox-nloglik:5.04691                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.71195\ttrain-cox-nloglik:4.96605                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.75026\ttrain-cox-nloglik:4.88371                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26432\ttrain-cox-nloglik:5.51522                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10387\ttrain-cox-nloglik:5.04784                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.16120\ttrain-cox-nloglik:4.91881                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.20659\ttrain-cox-nloglik:4.84282                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.24320\ttrain-cox-nloglik:4.78357                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09051\ttrain-cox-nloglik:5.55929                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82817\ttrain-cox-nloglik:5.17517                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.75798\ttrain-cox-nloglik:5.05406                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.73702\ttrain-cox-nloglik:4.97851                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.72810\ttrain-cox-nloglik:4.92143                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10075\ttrain-cox-nloglik:5.55998                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85451\ttrain-cox-nloglik:5.13734                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84872\ttrain-cox-nloglik:5.00731                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.87008\ttrain-cox-nloglik:4.93171                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.88857\ttrain-cox-nloglik:4.87788                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23671\ttrain-cox-nloglik:5.52358                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88181\ttrain-cox-nloglik:5.14594                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.80334\ttrain-cox-nloglik:5.02045                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.77284\ttrain-cox-nloglik:4.94319                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76184\ttrain-cox-nloglik:4.88317                           \n",
      "\n",
      "\tScore 0.7435467777790642                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.020503282625672033, 'max_depth': 3, 'min_child_weight': 1.042809733040623, 'objective': 'survival:cox', 'reg_alpha': 0.1511400376184174, 'reg_lambda': 0.21346746522637813, 'subsample': 0.7976612267368641}\n",
      "[0]\teval-cox-nloglik:4.10508\ttrain-cox-nloglik:5.53432                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88923\ttrain-cox-nloglik:4.52655                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.07107\ttrain-cox-nloglik:4.16691                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.18424\ttrain-cox-nloglik:3.89893                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.31430\ttrain-cox-nloglik:3.69966                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24835\ttrain-cox-nloglik:5.49332                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.37666\ttrain-cox-nloglik:4.40114                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.52153\ttrain-cox-nloglik:4.02083                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.67644\ttrain-cox-nloglik:3.76549                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.83139\ttrain-cox-nloglik:3.56751                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08529\ttrain-cox-nloglik:5.53769                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89156\ttrain-cox-nloglik:4.54493                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.10481\ttrain-cox-nloglik:4.18936                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.31241\ttrain-cox-nloglik:3.93876                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.45243\ttrain-cox-nloglik:3.74290                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09132\ttrain-cox-nloglik:5.54273                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96673\ttrain-cox-nloglik:4.50729                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.08387\ttrain-cox-nloglik:4.12278                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.22110\ttrain-cox-nloglik:3.86752                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.35448\ttrain-cox-nloglik:3.65269                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22413\ttrain-cox-nloglik:5.50616                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.84119\ttrain-cox-nloglik:4.54889                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95397\ttrain-cox-nloglik:4.22017                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.03639\ttrain-cox-nloglik:3.96368                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.13146\ttrain-cox-nloglik:3.76499                           \n",
      "\n",
      "\tScore 0.7081277502877866                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.1377140270567776, 'max_depth': 3, 'min_child_weight': 3.0228174998718425, 'objective': 'survival:cox', 'reg_alpha': 0.011408126447058534, 'reg_lambda': 0.0026341714976867163, 'subsample': 0.8405107460865282}\n",
      "[0]\teval-cox-nloglik:3.98195\ttrain-cox-nloglik:5.40015                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.46231\ttrain-cox-nloglik:3.55822                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.21300\ttrain-cox-nloglik:2.99422                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.83006\ttrain-cox-nloglik:2.66762                           \n",
      "\n",
      "[999]\teval-cox-nloglik:6.54195\ttrain-cox-nloglik:2.45454                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.16927\ttrain-cox-nloglik:5.33583                             \n",
      "\n",
      "[250]\teval-cox-nloglik:5.19685\ttrain-cox-nloglik:3.39801                           \n",
      "\n",
      "[500]\teval-cox-nloglik:6.04288\ttrain-cox-nloglik:2.88551                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.96256\ttrain-cox-nloglik:2.58966                           \n",
      "\n",
      "[999]\teval-cox-nloglik:7.72792\ttrain-cox-nloglik:2.37849                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.01634\ttrain-cox-nloglik:5.42511                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.68711\ttrain-cox-nloglik:3.55769                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.76331\ttrain-cox-nloglik:3.04084                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.94630\ttrain-cox-nloglik:2.70853                           \n",
      "\n",
      "[999]\teval-cox-nloglik:8.06415\ttrain-cox-nloglik:2.49582                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.01260\ttrain-cox-nloglik:5.41890                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.75807\ttrain-cox-nloglik:3.43834                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.63527\ttrain-cox-nloglik:2.91680                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.32091\ttrain-cox-nloglik:2.61376                           \n",
      "\n",
      "[999]\teval-cox-nloglik:7.00514\ttrain-cox-nloglik:2.41786                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.12958\ttrain-cox-nloglik:5.38482                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.41374\ttrain-cox-nloglik:3.58081                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.91865\ttrain-cox-nloglik:3.05845                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.30980\ttrain-cox-nloglik:2.73851                           \n",
      "\n",
      "[999]\teval-cox-nloglik:5.85236\ttrain-cox-nloglik:2.52178                           \n",
      "\n",
      "\tScore 0.6745341575329855                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0014385124148817228, 'max_depth': 7, 'min_child_weight': 0.16517465027965386, 'objective': 'survival:cox', 'reg_alpha': 0.015537420769069013, 'reg_lambda': 0.012251880932639844, 'subsample': 0.9299321451337333}\n",
      "[0]\teval-cox-nloglik:4.12768\ttrain-cox-nloglik:5.55574                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80024\ttrain-cox-nloglik:4.70646                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87475\ttrain-cox-nloglik:4.26981                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.98346\ttrain-cox-nloglik:3.96761                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.13329\ttrain-cox-nloglik:3.74165                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26407\ttrain-cox-nloglik:5.51413                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.16564\ttrain-cox-nloglik:4.61555                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.27182\ttrain-cox-nloglik:4.16820                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.39110\ttrain-cox-nloglik:3.87033                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.51250\ttrain-cox-nloglik:3.65750                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09065\ttrain-cox-nloglik:5.55748                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98262\ttrain-cox-nloglik:4.68141                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.08711\ttrain-cox-nloglik:4.24050                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.20659\ttrain-cox-nloglik:3.94177                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.31027\ttrain-cox-nloglik:3.72415                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10339\ttrain-cox-nloglik:5.55941                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.21743\ttrain-cox-nloglik:4.66022                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.47909\ttrain-cox-nloglik:4.21462                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.73192\ttrain-cox-nloglik:3.92475                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.94896\ttrain-cox-nloglik:3.71705                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23878\ttrain-cox-nloglik:5.52203                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.06723\ttrain-cox-nloglik:4.74258                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.04517\ttrain-cox-nloglik:4.30880                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.05682\ttrain-cox-nloglik:4.01891                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.10950\ttrain-cox-nloglik:3.81224                           \n",
      "\n",
      "\tScore 0.694846176223194                                                           \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.006362186704307189, 'max_depth': 2, 'min_child_weight': 6.711902262286368, 'objective': 'survival:cox', 'reg_alpha': 0.4975325914143788, 'reg_lambda': 0.16353369967292336, 'subsample': 0.817307407858587}\n",
      "[0]\teval-cox-nloglik:4.12256\ttrain-cox-nloglik:5.55551                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.72708\ttrain-cox-nloglik:5.12545                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.69875\ttrain-cox-nloglik:5.00854                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.72396\ttrain-cox-nloglik:4.93436                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.75995\ttrain-cox-nloglik:4.88018                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26503\ttrain-cox-nloglik:5.51576                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12379\ttrain-cox-nloglik:5.01085                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.19800\ttrain-cox-nloglik:4.89945                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.25041\ttrain-cox-nloglik:4.83160                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.28096\ttrain-cox-nloglik:4.77663                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08777\ttrain-cox-nloglik:5.55790                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.80388\ttrain-cox-nloglik:5.12843                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.77393\ttrain-cox-nloglik:5.01646                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.78439\ttrain-cox-nloglik:4.94684                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80804\ttrain-cox-nloglik:4.89016                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09942\ttrain-cox-nloglik:5.55857                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.87034\ttrain-cox-nloglik:5.09363                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89186\ttrain-cox-nloglik:4.97917                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91225\ttrain-cox-nloglik:4.91088                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92712\ttrain-cox-nloglik:4.85589                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23573\ttrain-cox-nloglik:5.52189                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.84233\ttrain-cox-nloglik:5.11824                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.77447\ttrain-cox-nloglik:5.00229                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76586\ttrain-cox-nloglik:4.93317                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78197\ttrain-cox-nloglik:4.87965                           \n",
      "\n",
      "\tScore 0.7401448725849102                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.003279881919403085, 'max_depth': 4, 'min_child_weight': 5.15271340390784, 'objective': 'survival:cox', 'reg_alpha': 0.2627473787453417, 'reg_lambda': 0.0070587072102921795, 'subsample': 0.7846970855224039}\n",
      "[0]\teval-cox-nloglik:4.12435\ttrain-cox-nloglik:5.55700                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.78669\ttrain-cox-nloglik:5.09593                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.74665\ttrain-cox-nloglik:4.90956                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76921\ttrain-cox-nloglik:4.78573                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.80763\ttrain-cox-nloglik:4.69372                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26491\ttrain-cox-nloglik:5.51638                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10590\ttrain-cox-nloglik:5.00891                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.17293\ttrain-cox-nloglik:4.81799                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.24829\ttrain-cox-nloglik:4.69547                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.29166\ttrain-cox-nloglik:4.59874                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08990\ttrain-cox-nloglik:5.55985                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.86713\ttrain-cox-nloglik:5.09537                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84668\ttrain-cox-nloglik:4.90826                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.86818\ttrain-cox-nloglik:4.78341                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.91143\ttrain-cox-nloglik:4.68983                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10140\ttrain-cox-nloglik:5.56088                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89053\ttrain-cox-nloglik:5.07562                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90599\ttrain-cox-nloglik:4.88540                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95587\ttrain-cox-nloglik:4.75952                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.99928\ttrain-cox-nloglik:4.65976                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23841\ttrain-cox-nloglik:5.52394                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92082\ttrain-cox-nloglik:5.08746                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.85924\ttrain-cox-nloglik:4.91162                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84464\ttrain-cox-nloglik:4.79627                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.84999\ttrain-cox-nloglik:4.70965                           \n",
      "\n",
      "\tScore 0.7281950382504784                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.05438270926117756, 'max_depth': 5, 'min_child_weight': 0.3057877718771979, 'objective': 'survival:cox', 'reg_alpha': 0.823832164965931, 'reg_lambda': 0.0915297442016918, 'subsample': 0.7634991972907516}\n",
      "[0]\teval-cox-nloglik:4.02861\ttrain-cox-nloglik:5.44385                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.84194\ttrain-cox-nloglik:3.07735                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.48029\ttrain-cox-nloglik:2.70201                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.92872\ttrain-cox-nloglik:2.53072                           \n",
      "\n",
      "[999]\teval-cox-nloglik:6.23392\ttrain-cox-nloglik:2.42282                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22948\ttrain-cox-nloglik:5.42584                             \n",
      "\n",
      "[250]\teval-cox-nloglik:5.52382\ttrain-cox-nloglik:2.98496                           \n",
      "\n",
      "[500]\teval-cox-nloglik:6.24925\ttrain-cox-nloglik:2.61753                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.85144\ttrain-cox-nloglik:2.44174                           \n",
      "\n",
      "[999]\teval-cox-nloglik:7.29304\ttrain-cox-nloglik:2.33208                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.06193\ttrain-cox-nloglik:5.46675                             \n",
      "\n",
      "[250]\teval-cox-nloglik:5.01361\ttrain-cox-nloglik:3.12101                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.74023\ttrain-cox-nloglik:2.72748                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.31365\ttrain-cox-nloglik:2.54017                           \n",
      "\n",
      "[999]\teval-cox-nloglik:6.77065\ttrain-cox-nloglik:2.42690                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07047\ttrain-cox-nloglik:5.48901                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.95964\ttrain-cox-nloglik:3.04644                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.74010\ttrain-cox-nloglik:2.67620                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.24147\ttrain-cox-nloglik:2.49659                           \n",
      "\n",
      "[999]\teval-cox-nloglik:6.60155\ttrain-cox-nloglik:2.38615                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23212\ttrain-cox-nloglik:5.43720                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.61164\ttrain-cox-nloglik:3.14145                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.04918\ttrain-cox-nloglik:2.76131                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.30256\ttrain-cox-nloglik:2.58024                           \n",
      "\n",
      "[999]\teval-cox-nloglik:5.53681\ttrain-cox-nloglik:2.46187                           \n",
      "\n",
      "\tScore 0.688807170458547                                                           \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.01039292410151151, 'max_depth': 2, 'min_child_weight': 1.3375023327235849, 'objective': 'survival:cox', 'reg_alpha': 0.043731031250551555, 'reg_lambda': 0.031497624625173214, 'subsample': 0.8071304770068263}\n",
      "[0]\teval-cox-nloglik:4.11805\ttrain-cox-nloglik:5.54963                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.71531\ttrain-cox-nloglik:4.98436                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84126\ttrain-cox-nloglik:4.81530                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88591\ttrain-cox-nloglik:4.70725                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.91607\ttrain-cox-nloglik:4.61937                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25924\ttrain-cox-nloglik:5.50780                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.17622\ttrain-cox-nloglik:4.87329                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.24994\ttrain-cox-nloglik:4.72130                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.31818\ttrain-cox-nloglik:4.60774                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.33220\ttrain-cox-nloglik:4.51824                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08444\ttrain-cox-nloglik:5.55425                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.73501\ttrain-cox-nloglik:5.01379                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.73403\ttrain-cox-nloglik:4.86860                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.74928\ttrain-cox-nloglik:4.76316                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78526\ttrain-cox-nloglik:4.67333                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09656\ttrain-cox-nloglik:5.55495                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.84912\ttrain-cox-nloglik:4.96239                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87252\ttrain-cox-nloglik:4.81408                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89676\ttrain-cox-nloglik:4.70709                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92035\ttrain-cox-nloglik:4.61532                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23217\ttrain-cox-nloglik:5.51826                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.77389\ttrain-cox-nloglik:4.98220                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.72977\ttrain-cox-nloglik:4.83520                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.73367\ttrain-cox-nloglik:4.73346                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.78287\ttrain-cox-nloglik:4.64401                           \n",
      "\n",
      "\tScore 0.7361388235185398                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.033494128630722556, 'max_depth': 7, 'min_child_weight': 0.12978516015496855, 'objective': 'survival:cox', 'reg_alpha': 0.34185174790564216, 'reg_lambda': 0.0010174241551712565, 'subsample': 0.8729177584408624}\n",
      "[0]\teval-cox-nloglik:4.10077\ttrain-cox-nloglik:5.43637                             \n",
      "\n",
      "[250]\teval-cox-nloglik:5.40693\ttrain-cox-nloglik:2.67475                           \n",
      "\n",
      "[500]\teval-cox-nloglik:6.26490\ttrain-cox-nloglik:2.34351                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.97461\ttrain-cox-nloglik:2.16174                           \n",
      "\n",
      "[999]\teval-cox-nloglik:7.46313\ttrain-cox-nloglik:2.05935                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.21815\ttrain-cox-nloglik:5.37063                             \n",
      "\n",
      "[250]\teval-cox-nloglik:6.13410\ttrain-cox-nloglik:2.59111                           \n",
      "\n",
      "[500]\teval-cox-nloglik:7.42817\ttrain-cox-nloglik:2.25555                           \n",
      "\n",
      "[750]\teval-cox-nloglik:8.30183\ttrain-cox-nloglik:2.09003                           \n",
      "\n",
      "[999]\teval-cox-nloglik:8.94880\ttrain-cox-nloglik:2.00982                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09208\ttrain-cox-nloglik:5.42171                             \n",
      "\n",
      "[250]\teval-cox-nloglik:5.42118\ttrain-cox-nloglik:2.69338                           \n",
      "\n",
      "[500]\teval-cox-nloglik:6.28109\ttrain-cox-nloglik:2.35242                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.85977\ttrain-cox-nloglik:2.17649                           \n",
      "\n",
      "[999]\teval-cox-nloglik:7.26638\ttrain-cox-nloglik:2.06584                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08806\ttrain-cox-nloglik:5.46885                             \n",
      "\n",
      "[250]\teval-cox-nloglik:7.17039\ttrain-cox-nloglik:2.66338                           \n",
      "\n",
      "[500]\teval-cox-nloglik:8.34086\ttrain-cox-nloglik:2.31204                           \n",
      "\n",
      "[750]\teval-cox-nloglik:9.15836\ttrain-cox-nloglik:2.13513                           \n",
      "\n",
      "[999]\teval-cox-nloglik:9.78653\ttrain-cox-nloglik:2.02163                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.21059\ttrain-cox-nloglik:5.40056                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.76865\ttrain-cox-nloglik:2.74115                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.63706\ttrain-cox-nloglik:2.38406                           \n",
      "\n",
      "[750]\teval-cox-nloglik:6.23496\ttrain-cox-nloglik:2.20231                           \n",
      "\n",
      "[999]\teval-cox-nloglik:6.65119\ttrain-cox-nloglik:2.08710                           \n",
      "\n",
      "\tScore 0.6967322361652866                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.002000063943145783, 'max_depth': 9, 'min_child_weight': 2.10209709582729, 'objective': 'survival:cox', 'reg_alpha': 0.00431587596093417, 'reg_lambda': 0.03979010035565558, 'subsample': 0.773526718605636}\n",
      "[0]\teval-cox-nloglik:4.12651\ttrain-cox-nloglik:5.55757                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.84072\ttrain-cox-nloglik:5.00805                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.79888\ttrain-cox-nloglik:4.68436                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.81608\ttrain-cox-nloglik:4.44499                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.81724\ttrain-cox-nloglik:4.26199                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26571\ttrain-cox-nloglik:5.51650                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12929\ttrain-cox-nloglik:4.91246                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.18629\ttrain-cox-nloglik:4.57306                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.27039\ttrain-cox-nloglik:4.33088                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.34951\ttrain-cox-nloglik:4.14619                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09110\ttrain-cox-nloglik:5.55999                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94030\ttrain-cox-nloglik:5.00158                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91806\ttrain-cox-nloglik:4.67617                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.93681\ttrain-cox-nloglik:4.44314                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.97444\ttrain-cox-nloglik:4.26135                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10151\ttrain-cox-nloglik:5.56120                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92263\ttrain-cox-nloglik:4.99428                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.93010\ttrain-cox-nloglik:4.66309                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.97501\ttrain-cox-nloglik:4.42362                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.04201\ttrain-cox-nloglik:4.23529                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23873\ttrain-cox-nloglik:5.52424                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98990\ttrain-cox-nloglik:4.98530                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95905\ttrain-cox-nloglik:4.67307                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.98277\ttrain-cox-nloglik:4.44866                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.00406\ttrain-cox-nloglik:4.27079                           \n",
      "\n",
      "\tScore 0.7165880716981938                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0012349270716175038, 'max_depth': 3, 'min_child_weight': 0.23849131563620052, 'objective': 'survival:cox', 'reg_alpha': 0.13682665169192393, 'reg_lambda': 0.2613056897039727, 'subsample': 0.757698615760998}\n",
      "[0]\teval-cox-nloglik:4.12713\ttrain-cox-nloglik:5.55934                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90753\ttrain-cox-nloglik:5.29256                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.80634\ttrain-cox-nloglik:5.14525                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.75748\ttrain-cox-nloglik:5.04475                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.74240\ttrain-cox-nloglik:4.96444                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26637\ttrain-cox-nloglik:5.51900                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.14899\ttrain-cox-nloglik:5.21409                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.12876\ttrain-cox-nloglik:5.05028                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.14480\ttrain-cox-nloglik:4.93904                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.16891\ttrain-cox-nloglik:4.85745                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09134\ttrain-cox-nloglik:5.56188                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96401\ttrain-cox-nloglik:5.30416                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.89116\ttrain-cox-nloglik:5.16112                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84526\ttrain-cox-nloglik:5.06136                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.81696\ttrain-cox-nloglik:4.98771                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10259\ttrain-cox-nloglik:5.56283                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.96183\ttrain-cox-nloglik:5.28699                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.90706\ttrain-cox-nloglik:5.12887                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88443\ttrain-cox-nloglik:5.02093                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.87636\ttrain-cox-nloglik:4.93751                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23946\ttrain-cox-nloglik:5.52595                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.03276\ttrain-cox-nloglik:5.28096                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.93421\ttrain-cox-nloglik:5.14087                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.88022\ttrain-cox-nloglik:5.04449                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.84943\ttrain-cox-nloglik:4.96864                           \n",
      "\n",
      "\tScore 0.7338577130394736                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0038755049373182487, 'max_depth': 6, 'min_child_weight': 8.457396320603513, 'objective': 'survival:cox', 'reg_alpha': 0.21228661651041295, 'reg_lambda': 0.004964915655759022, 'subsample': 0.8631992434536773}\n",
      "[0]\teval-cox-nloglik:4.12436\ttrain-cox-nloglik:5.55730                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.75642\ttrain-cox-nloglik:5.11479                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.73262\ttrain-cox-nloglik:4.93738                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.75684\ttrain-cox-nloglik:4.81679                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79861\ttrain-cox-nloglik:4.72347                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26506\ttrain-cox-nloglik:5.51633                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10106\ttrain-cox-nloglik:5.01609                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.17518\ttrain-cox-nloglik:4.82740                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.24036\ttrain-cox-nloglik:4.69942                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.28561\ttrain-cox-nloglik:4.59589                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08933\ttrain-cox-nloglik:5.55926                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85338\ttrain-cox-nloglik:5.10966                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86525\ttrain-cox-nloglik:4.92101                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.89021\ttrain-cox-nloglik:4.79892                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.92635\ttrain-cox-nloglik:4.70626                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10088\ttrain-cox-nloglik:5.56042                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89553\ttrain-cox-nloglik:5.09666                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.91907\ttrain-cox-nloglik:4.92164                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.95914\ttrain-cox-nloglik:4.80191                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.00918\ttrain-cox-nloglik:4.70582                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23701\ttrain-cox-nloglik:5.52362                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90349\ttrain-cox-nloglik:5.09603                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.84405\ttrain-cox-nloglik:4.93140                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.84977\ttrain-cox-nloglik:4.81690                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86363\ttrain-cox-nloglik:4.72687                           \n",
      "\n",
      "\tScore 0.7236567193266663                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.012955055097256984, 'max_depth': 4, 'min_child_weight': 0.642259641003232, 'objective': 'survival:cox', 'reg_alpha': 1.3139689709262952, 'reg_lambda': 0.06351836572126525, 'subsample': 0.8260470267206428}\n",
      "[0]\teval-cox-nloglik:4.11744\ttrain-cox-nloglik:5.54386                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.81788\ttrain-cox-nloglik:4.47915                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.96194\ttrain-cox-nloglik:4.11984                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.07036\ttrain-cox-nloglik:3.87405                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.17156\ttrain-cox-nloglik:3.69793                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25887\ttrain-cox-nloglik:5.49954                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.39403\ttrain-cox-nloglik:4.36358                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.56204\ttrain-cox-nloglik:3.98806                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.70807\ttrain-cox-nloglik:3.74218                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.86039\ttrain-cox-nloglik:3.56448                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08621\ttrain-cox-nloglik:5.54599                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92638\ttrain-cox-nloglik:4.52795                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.15978\ttrain-cox-nloglik:4.15211                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.31958\ttrain-cox-nloglik:3.89660                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.49310\ttrain-cox-nloglik:3.71512                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09458\ttrain-cox-nloglik:5.54651                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.03503\ttrain-cox-nloglik:4.46001                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.19070\ttrain-cox-nloglik:4.07613                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.34058\ttrain-cox-nloglik:3.82758                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.46623\ttrain-cox-nloglik:3.64739                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.22829\ttrain-cox-nloglik:5.50854                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.88883\ttrain-cox-nloglik:4.52882                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.95839\ttrain-cox-nloglik:4.16889                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.04149\ttrain-cox-nloglik:3.93460                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.09588\ttrain-cox-nloglik:3.75633                           \n",
      "\n",
      "\tScore 0.7075342330025503                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.02700293462076552, 'max_depth': 3, 'min_child_weight': 0.7431739657196806, 'objective': 'survival:cox', 'reg_alpha': 0.09815684781983035, 'reg_lambda': 0.0193317877147046, 'subsample': 0.8494584138524962}\n",
      "[0]\teval-cox-nloglik:4.10089\ttrain-cox-nloglik:5.52295                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.06093\ttrain-cox-nloglik:4.33097                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.17553\ttrain-cox-nloglik:3.90814                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.35105\ttrain-cox-nloglik:3.62680                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.56660\ttrain-cox-nloglik:3.41038                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23703\ttrain-cox-nloglik:5.47688                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.53509\ttrain-cox-nloglik:4.19910                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.71694\ttrain-cox-nloglik:3.78008                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.02726\ttrain-cox-nloglik:3.48434                           \n",
      "\n",
      "[999]\teval-cox-nloglik:5.27638\ttrain-cox-nloglik:3.26979                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.07337\ttrain-cox-nloglik:5.53109                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89787\ttrain-cox-nloglik:4.37486                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.18325\ttrain-cox-nloglik:3.97736                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.41995\ttrain-cox-nloglik:3.68224                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.66188\ttrain-cox-nloglik:3.45640                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08370\ttrain-cox-nloglik:5.53282                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.98450\ttrain-cox-nloglik:4.32157                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.20741\ttrain-cox-nloglik:3.88238                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.41750\ttrain-cox-nloglik:3.57374                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.66076\ttrain-cox-nloglik:3.33827                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.21625\ttrain-cox-nloglik:5.49614                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.82071\ttrain-cox-nloglik:4.35970                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.03089\ttrain-cox-nloglik:3.96797                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.19555\ttrain-cox-nloglik:3.67637                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.34028\ttrain-cox-nloglik:3.46139                           \n",
      "\n",
      "\tScore 0.7010166602382188                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.007561633267207135, 'max_depth': 2, 'min_child_weight': 0.0542567604968899, 'objective': 'survival:cox', 'reg_alpha': 0.023975105545422058, 'reg_lambda': 0.001995888831287718, 'subsample': 0.8982985515029455}\n",
      "[0]\teval-cox-nloglik:4.12180\ttrain-cox-nloglik:5.55239                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.81300\ttrain-cox-nloglik:5.00440                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.97288\ttrain-cox-nloglik:4.84258                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.06009\ttrain-cox-nloglik:4.73845                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.08549\ttrain-cox-nloglik:4.65534                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26130\ttrain-cox-nloglik:5.51128                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.12555\ttrain-cox-nloglik:4.90710                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.19700\ttrain-cox-nloglik:4.76027                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.25143\ttrain-cox-nloglik:4.65069                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.31766\ttrain-cox-nloglik:4.56027                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.08892\ttrain-cox-nloglik:5.55609                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.73787\ttrain-cox-nloglik:5.04029                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.70562\ttrain-cox-nloglik:4.88798                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.72479\ttrain-cox-nloglik:4.78734                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.75378\ttrain-cox-nloglik:4.69863                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10012\ttrain-cox-nloglik:5.55649                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.85998\ttrain-cox-nloglik:4.98362                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87656\ttrain-cox-nloglik:4.83238                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.91220\ttrain-cox-nloglik:4.72828                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.94545\ttrain-cox-nloglik:4.64329                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23250\ttrain-cox-nloglik:5.52006                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.78402\ttrain-cox-nloglik:5.01265                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.73000\ttrain-cox-nloglik:4.86597                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.73234\ttrain-cox-nloglik:4.76861                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.76494\ttrain-cox-nloglik:4.67590                           \n",
      "\n",
      "\tScore 0.7345663424168986                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0055799032546492815, 'max_depth': 5, 'min_child_weight': 0.08405868603328875, 'objective': 'survival:cox', 'reg_alpha': 0.01680580658248227, 'reg_lambda': 0.0036001190117109943, 'subsample': 0.8576408978546822}\n",
      "[0]\teval-cox-nloglik:4.12571\ttrain-cox-nloglik:5.54613                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.92901\ttrain-cox-nloglik:4.25429                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.07290\ttrain-cox-nloglik:3.82587                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.22096\ttrain-cox-nloglik:3.55460                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.34985\ttrain-cox-nloglik:3.35802                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.25375\ttrain-cox-nloglik:5.50460                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.37660\ttrain-cox-nloglik:4.13884                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.69019\ttrain-cox-nloglik:3.69491                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.91671\ttrain-cox-nloglik:3.41801                           \n",
      "\n",
      "[999]\teval-cox-nloglik:5.06748\ttrain-cox-nloglik:3.21560                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09422\ttrain-cox-nloglik:5.54510                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.23951\ttrain-cox-nloglik:4.26757                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.49437\ttrain-cox-nloglik:3.82971                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.67194\ttrain-cox-nloglik:3.54927                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.81442\ttrain-cox-nloglik:3.35029                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09901\ttrain-cox-nloglik:5.55284                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.58742\ttrain-cox-nloglik:4.23593                           \n",
      "\n",
      "[500]\teval-cox-nloglik:5.39160\ttrain-cox-nloglik:3.80328                           \n",
      "\n",
      "[750]\teval-cox-nloglik:5.81124\ttrain-cox-nloglik:3.53516                           \n",
      "\n",
      "[999]\teval-cox-nloglik:6.06519\ttrain-cox-nloglik:3.33922                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.24063\ttrain-cox-nloglik:5.51002                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.94912\ttrain-cox-nloglik:4.32092                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.00125\ttrain-cox-nloglik:3.89629                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.07273\ttrain-cox-nloglik:3.63485                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.14677\ttrain-cox-nloglik:3.43103                           \n",
      "\n",
      "\tScore 0.7108876305573134                                                          \n",
      "\n",
      "\n",
      "Training with params:                                                              \n",
      "{'eta': 0.0023706877388078753, 'max_depth': 2, 'min_child_weight': 0.5268138074878487, 'objective': 'survival:cox', 'reg_alpha': 0.6815394402955302, 'reg_lambda': 0.009238773307101288, 'subsample': 0.8842122623754963}\n",
      "[0]\teval-cox-nloglik:4.12654\ttrain-cox-nloglik:5.55844                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.83275\ttrain-cox-nloglik:5.26055                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.73295\ttrain-cox-nloglik:5.13377                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.71710\ttrain-cox-nloglik:5.05631                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.73054\ttrain-cox-nloglik:4.99672                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.26524\ttrain-cox-nloglik:5.51773                             \n",
      "\n",
      "[250]\teval-cox-nloglik:4.10699\ttrain-cox-nloglik:5.16965                           \n",
      "\n",
      "[500]\teval-cox-nloglik:4.09942\ttrain-cox-nloglik:5.03232                           \n",
      "\n",
      "[750]\teval-cox-nloglik:4.11630\ttrain-cox-nloglik:4.95483                           \n",
      "\n",
      "[999]\teval-cox-nloglik:4.13978\ttrain-cox-nloglik:4.89923                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.09029\ttrain-cox-nloglik:5.56111                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.89930\ttrain-cox-nloglik:5.28029                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.81463\ttrain-cox-nloglik:5.16349                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.76625\ttrain-cox-nloglik:5.09062                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.73492\ttrain-cox-nloglik:5.03539                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.10247\ttrain-cox-nloglik:5.56221                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.90231\ttrain-cox-nloglik:5.24878                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.86090\ttrain-cox-nloglik:5.11805                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.85644\ttrain-cox-nloglik:5.03943                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.86184\ttrain-cox-nloglik:4.98448                           \n",
      "\n",
      "[0]\teval-cox-nloglik:4.23860\ttrain-cox-nloglik:5.52532                             \n",
      "\n",
      "[250]\teval-cox-nloglik:3.97312\ttrain-cox-nloglik:5.24401                           \n",
      "\n",
      "[500]\teval-cox-nloglik:3.87569\ttrain-cox-nloglik:5.12717                           \n",
      "\n",
      "[750]\teval-cox-nloglik:3.82496\ttrain-cox-nloglik:5.05286                           \n",
      "\n",
      "[999]\teval-cox-nloglik:3.79692\ttrain-cox-nloglik:5.00034                           \n",
      "\n",
      "\tScore 0.7433323019624504                                                          \n",
      "\n",
      "\n",
      "100%|| 100/100 [15:06<00:00,  9.07s/trial, best loss: 0.25294988182861056]\n",
      "Done: took 15.112412182490031 minutes\n",
      "---- Results for XGBoost ----\n",
      "The best hyperparameters are:  \n",
      "\n",
      "{'eta': 0.0020570934235303907, 'max_depth': 2.0, 'min_child_weight': 1.0366918633482902, 'reg_alpha': 0.09867275783575628, 'reg_lambda': 0.018996023853840978, 'subsample': 0.7939301950114278}\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Running XGBoost ----\")\n",
    "start=time.time()\n",
    "xgb_best_hyperparams = optimize_xgb(score_xgb)\n",
    "end=time.time()\n",
    "print(\"Done: took\", (end-start)/60, \"minutes\")\n",
    "print(\"---- Results for XGBoost ----\")\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(xgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.0020570934235303907, 'max_depth': 2, 'min_child_weight': 1.0366918633482902, 'reg_alpha': 0.09867275783575628, 'reg_lambda': 0.018996023853840978, 'subsample': 0.7939301950114278, 'objective': 'survival:cox'}\n"
     ]
    }
   ],
   "source": [
    "xgb_best_hyperparams['max_depth']=round(xgb_best_hyperparams['max_depth'])\n",
    "xgb_best_hyperparams['objective']=\"survival:cox\"\n",
    "print(xgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_hyperparams = {'eta': 0.002329846232948934, 'max_depth': 2, 'min_child_weight': 0.0017462626013389445, 'reg_alpha': 0.07220221910190468, 'reg_lambda': 1.6058311333673232, 'subsample': 0.7582893091214069, 'objective': 'survival:cox'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Start\n",
      "[0]\teval-cox-nloglik:4.12657\ttrain-cox-nloglik:5.55922\n",
      "[250]\teval-cox-nloglik:3.85962\ttrain-cox-nloglik:5.28377\n",
      "[500]\teval-cox-nloglik:3.76334\ttrain-cox-nloglik:5.16440\n",
      "[750]\teval-cox-nloglik:3.72765\ttrain-cox-nloglik:5.08977\n",
      "[999]\teval-cox-nloglik:3.70900\ttrain-cox-nloglik:5.03299\n",
      "XGB Done\n",
      "Round 1 Done: 0.02184113661448161 minutes\n",
      "Round 2 Start\n",
      "[0]\teval-cox-nloglik:4.26564\ttrain-cox-nloglik:5.51851\n",
      "[250]\teval-cox-nloglik:4.10865\ttrain-cox-nloglik:5.19495\n",
      "[500]\teval-cox-nloglik:4.10332\ttrain-cox-nloglik:5.06193\n",
      "[750]\teval-cox-nloglik:4.12105\ttrain-cox-nloglik:4.98221\n",
      "[999]\teval-cox-nloglik:4.14724\ttrain-cox-nloglik:4.92680\n",
      "XGB Done\n",
      "Round 2 Done: 0.019694801171620688 minutes\n",
      "Round 3 Start\n",
      "[0]\teval-cox-nloglik:4.09051\ttrain-cox-nloglik:5.56152\n",
      "[250]\teval-cox-nloglik:3.90447\ttrain-cox-nloglik:5.29184\n",
      "[500]\teval-cox-nloglik:3.82392\ttrain-cox-nloglik:5.17513\n",
      "[750]\teval-cox-nloglik:3.78274\ttrain-cox-nloglik:5.10356\n",
      "[999]\teval-cox-nloglik:3.76112\ttrain-cox-nloglik:5.05316\n",
      "XGB Done\n",
      "Round 3 Done: 0.019648154576619465 minutes\n",
      "Round 4 Start\n",
      "[0]\teval-cox-nloglik:4.10210\ttrain-cox-nloglik:5.56232\n",
      "[250]\teval-cox-nloglik:3.91254\ttrain-cox-nloglik:5.26935\n",
      "[500]\teval-cox-nloglik:3.86449\ttrain-cox-nloglik:5.13966\n",
      "[750]\teval-cox-nloglik:3.85472\ttrain-cox-nloglik:5.06093\n",
      "[999]\teval-cox-nloglik:3.85477\ttrain-cox-nloglik:5.00742\n",
      "XGB Done\n",
      "Round 4 Done: 0.020128901799519858 minutes\n",
      "Round 5 Start\n",
      "[0]\teval-cox-nloglik:4.23896\ttrain-cox-nloglik:5.52547\n",
      "[250]\teval-cox-nloglik:3.97850\ttrain-cox-nloglik:5.26669\n",
      "[500]\teval-cox-nloglik:3.87897\ttrain-cox-nloglik:5.15404\n",
      "[750]\teval-cox-nloglik:3.82786\ttrain-cox-nloglik:5.08388\n",
      "[999]\teval-cox-nloglik:3.79817\ttrain-cox-nloglik:5.03253\n",
      "XGB Done\n",
      "Round 5 Done: 0.021503531932830812 minutes\n"
     ]
    }
   ],
   "source": [
    "xgb_scores =[]\n",
    "\n",
    "n_folds = 5\n",
    "num_boost_round=1000\n",
    "skf = KFold(n_splits=n_folds)\n",
    "c = 1\n",
    "#k-fold CV \n",
    "for train_index, val_index in skf.split(X_train): \n",
    "    print (\"Round\", c, \"Start\")\n",
    "    start = time.time()\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        \n",
    "    dtrain = xgboost.DMatrix(X_tr, label=y_tr)\n",
    "    dval = xgboost.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "    xgb_model = xgboost.train(xgb_best_hyperparams, dtrain, num_boost_round,\n",
    "                          evals=watchlist,\n",
    "                          verbose_eval=250)\n",
    "\n",
    "    predictions = xgb_model.predict(dval,\n",
    "                                ntree_limit=xgb_model.best_iteration + 1)\n",
    "    xgb_scores.append(c_statistic_harrell(predictions, list(y_val)))\n",
    "    print(\"XGB Done\")\n",
    "    end=time.time()\n",
    "    print(\"Round\", c, \"Done:\", (end-start)/60, \"minutes\")\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7839305103148752,\n",
       " 0.6783340717766947,\n",
       " 0.7650669642857143,\n",
       " 0.7093124456048738,\n",
       " 0.8002033553634977]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-cox-nloglik:4.46372\ttrain-cox-nloglik:5.76823\n",
      "[250]\teval-cox-nloglik:4.21004\ttrain-cox-nloglik:5.49720\n",
      "[500]\teval-cox-nloglik:4.14188\ttrain-cox-nloglik:5.38288\n",
      "[750]\teval-cox-nloglik:4.12351\ttrain-cox-nloglik:5.31458\n",
      "[999]\teval-cox-nloglik:4.13030\ttrain-cox-nloglik:5.26651\n",
      "XGB Done: 0.7380418535127056\n"
     ]
    }
   ],
   "source": [
    "num_boost_round=1000\n",
    "dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "dval = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "xgb_model = xgboost.train(xgb_best_hyperparams, dtrain, num_boost_round,\n",
    "                      evals=watchlist,\n",
    "                      verbose_eval=250)\n",
    "\n",
    "predictions = xgb_model.predict(dval,\n",
    "                            ntree_limit=xgb_model.best_iteration + 1)\n",
    "\n",
    "xgb_test_score = c_statistic_harrell(predictions, list(y_test))\n",
    "print(\"XGB Done:\", xgb_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Cox Bootstrap SHAP Vals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All covs feature set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'eta': 0.002329846232948934,\n",
    "          'max_depth': 2, \n",
    "          'min_child_weight': 0.0017462626013389445, \n",
    "          'reg_alpha': 0.07220221910190468, \n",
    "          'reg_lambda': 1.6058311333673232, \n",
    "          'subsample': 0.7582893091214069, \n",
    "          'objective': 'survival:cox'}\n",
    "\n",
    "full_xy = X_bcd.copy()\n",
    "y_labels = y_bcd.copy()\n",
    "full_xy['y'] = y_labels\n",
    "X_features = X_bcd.columns\n",
    "\n",
    "HazardRatioAge = [] \n",
    "idx_age=X_features.get_loc('age')\n",
    "\n",
    "HazardRatioMenopause = [] \n",
    "idx_menopause=X_features.get_loc('menopause')\n",
    "\n",
    "HazardRatioHormone = [] \n",
    "idx_hormone=X_features.get_loc('hormone')\n",
    "\n",
    "HazardRatioSize = [] \n",
    "idx_size=X_features.get_loc('size')\n",
    "\n",
    "HazardRatioGrade = [] \n",
    "idx_grade=X_features.get_loc('grade')\n",
    "\n",
    "HazardRatioNodes = [] \n",
    "idx_nodes=X_features.get_loc('nodes')\n",
    "\n",
    "HazardRatioProgRecp = [] \n",
    "idx_progrecp=X_features.get_loc('prog_recp')\n",
    "\n",
    "HazardRatioEstrgRecp = []\n",
    "idx_estrgrecp=X_features.get_loc('estrg_recp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5423728813559322"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bcd.age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bcd.menopause.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12820513, 0.14529915, 0.23076923, 0.17948718, 0.13675214,\n",
       "       0.45299145, 0.41880342, 0.16239316, 0.18803419, 0.31623932,\n",
       "       0.1025641 , 0.27350427, 0.4017094 , 0.15384615, 0.05982906,\n",
       "       0.35897436, 0.11965812, 0.07692308, 0.17094017, 0.48717949,\n",
       "       0.34188034, 0.22222222, 0.26495726, 0.04273504, 0.06837607,\n",
       "       0.2991453 , 0.21367521, 0.82905983, 0.44444444, 0.11111111,\n",
       "       0.28205128, 0.20512821, 0.24786325, 0.65811966, 0.4957265 ,\n",
       "       0.23931624, 0.52991453, 0.33333333, 0.08547009, 0.1965812 ,\n",
       "       0.25641026, 0.39316239, 0.29059829, 0.46153846, 0.30769231,\n",
       "       0.05128205, 0.09401709, 0.61538462, 0.03418803, 0.57264957,\n",
       "       0.47008547, 0.38461538, 1.        , 0.01709402, 0.        ,\n",
       "       0.35042735, 0.64102564, 0.00854701])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bcd['size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bcd.grade.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18803418803418806"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bcd['size'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01365546218487395"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bcd.prog_recp.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03146853146853147"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bcd.estrg_recp.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>menopause</th>\n",
       "      <th>hormone</th>\n",
       "      <th>size</th>\n",
       "      <th>grade</th>\n",
       "      <th>nodes</th>\n",
       "      <th>prog_recp</th>\n",
       "      <th>estrg_recp</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059244</td>\n",
       "      <td>0.091783</td>\n",
       "      <td>-2282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032773</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.440678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177311</td>\n",
       "      <td>0.077797</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.322034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>-148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728814</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>-1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.508475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.049825</td>\n",
       "      <td>-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0.711864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.026891</td>\n",
       "      <td>0.016608</td>\n",
       "      <td>-857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.677966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>-768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.423729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013866</td>\n",
       "      <td>0.059441</td>\n",
       "      <td>-858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.711864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>-770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  menopause  hormone      size  grade  nodes  prog_recp  \\\n",
       "0    0.288136          0        0  0.128205      3      5   0.059244   \n",
       "1    0.525424          0        0  0.145299      1      1   0.032773   \n",
       "2    0.440678          0        0  0.230769      2      1   0.177311   \n",
       "3    0.322034          0        0  0.179487      1      3   0.010504   \n",
       "4    0.728814          1        1  0.136752      2      1   0.007983   \n",
       "..        ...        ...      ...       ...    ...    ...        ...   \n",
       "681  0.508475          0        0  0.401709      2      5   0.151261   \n",
       "682  0.711864          1        1  0.162393      2      9   0.026891   \n",
       "683  0.677966          1        0  0.487179      2     51   0.018908   \n",
       "684  0.423729          0        0  0.196581      1      3   0.013866   \n",
       "685  0.711864          1        1  0.170940      2      3   0.001261   \n",
       "\n",
       "     estrg_recp     y  \n",
       "0      0.091783 -2282  \n",
       "1      0.012238 -2006  \n",
       "2      0.077797  1456  \n",
       "3      0.009615  -148  \n",
       "4      0.007867 -1863  \n",
       "..          ...   ...  \n",
       "681    0.049825   -17  \n",
       "682    0.016608  -857  \n",
       "683    0.033217  -768  \n",
       "684    0.059441  -858  \n",
       "685    0.001748  -770  \n",
       "\n",
       "[686 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My list of binary columns are :\n",
      " ['menopause', 'hormone']\n",
      "\n",
      "My list of cont. columns are :\n",
      " ['age', 'size', 'grade', 'nodes', 'prog_recp', 'estrg_recp']\n"
     ]
    }
   ],
   "source": [
    "full_xy = X_bcd.copy()\n",
    "y_labels = y_bcd.copy()\n",
    "full_xy['y'] = y_labels\n",
    "X_features = X_bcd.columns\n",
    "myHazRatios = [[] for i in range(len(X_bcd.columns))]\n",
    "myIndexes = [i for i in range(len(X_bcd.columns))]\n",
    "# print(myHazRatios_all, myIndexes_all)\n",
    "myBinCols = [col for col in X_bcd.columns if all(X_bcd[col].value_counts().index.isin([0, 1]))]\n",
    "myContCols = [col for col in X_bcd.columns if not all(X_bcd[col].value_counts().index.isin([0, 1]))]\n",
    "\n",
    "print(\"My list of binary columns are :\\n\", myBinCols)\n",
    "\n",
    "print(\"\\nMy list of cont. columns are :\\n\", myContCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>menopause</th>\n",
       "      <th>hormone</th>\n",
       "      <th>size</th>\n",
       "      <th>grade</th>\n",
       "      <th>nodes</th>\n",
       "      <th>prog_recp</th>\n",
       "      <th>estrg_recp</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059244</td>\n",
       "      <td>0.091783</td>\n",
       "      <td>-2282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032773</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.440678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177311</td>\n",
       "      <td>0.077797</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.322034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>-148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728814</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>-1863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  menopause  hormone      size  grade  nodes  prog_recp  \\\n",
       "0  0.288136          0        0  0.128205      3      5   0.059244   \n",
       "1  0.525424          0        0  0.145299      1      1   0.032773   \n",
       "2  0.440678          0        0  0.230769      2      1   0.177311   \n",
       "3  0.322034          0        0  0.179487      1      3   0.010504   \n",
       "4  0.728814          1        1  0.136752      2      1   0.007983   \n",
       "\n",
       "   estrg_recp     y  \n",
       "0    0.091783 -2282  \n",
       "1    0.012238 -2006  \n",
       "2    0.077797  1456  \n",
       "3    0.009615  -148  \n",
       "4    0.007867 -1863  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrap!\n",
    "for i in range(1, 1001):\n",
    "#   sample with replacement:\n",
    "    X_train = full_xy.sample(n = full_xy.shape[0], random_state = i, replace = True) #sample w/ replacement num rows\n",
    "    y_train = X_train['y'] #y train are X_trains y column\n",
    "    X_train = X_train.drop(columns = ['y']) #X_train then needs to drop the y column\n",
    "    X_test = full_xy.drop(X_train.index) #test features are the full - X_train\n",
    "    y_test = X_test['y'] #y test are X_tests y column\n",
    "    X_test = X_test.drop(columns = ['y']) #X_test then needs to drop they column\n",
    "    xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "    xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "    model_train = xgboost.train(params, xgb_train, 1000, evals = [(xgb_test, \"test\")], verbose_eval=False)\n",
    "    \n",
    "#   let's get the SHAP vals and a HR from these based on our model\n",
    "    shap_values_full = shap.TreeExplainer(model_train).shap_values(X_bcd)\n",
    "    \n",
    "#   let's build a list of HazRatios indexing by j columns\n",
    "    for j in range(len(myIndexes)):\n",
    "        curSHAP = shap_values_full[:, j]\n",
    "        curCol = X_bcd.columns[j]\n",
    "        # if continuous, split by median\n",
    "        if (curCol in myContCols):\n",
    "            myMed = X_bcd[curCol].median()\n",
    "            myHazRatios[j].append(np.mean(np.exp(curSHAP[X_bcd[curCol] >= myMed]))\n",
    "                                  /np.mean(np.exp(curSHAP[X_bcd[curCol] < myMed])))\n",
    "        # else, split by 1 or 0\n",
    "        else:\n",
    "            myHazRatios[j].append(np.mean(np.exp(curSHAP[X_bcd[curCol] == 1]))\n",
    "                                  /np.mean(np.exp(curSHAP[X_bcd[curCol] == 0])))\n",
    "\n",
    "  \n",
    "#Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0755843, 0.94723684, 1.2668722], [1.0, 0.99099153, 1.0089844], [0.9562363, 0.7792321, 1.0], [1.1982852, 1.0276458, 1.5030464], [1.0220244, 1.0, 1.223608], [1.8678429, 1.4421599, 2.5125444], [0.38551936, 0.27466166, 0.53775483], [0.9298928, 0.736622, 1.0447654]]\n"
     ]
    }
   ],
   "source": [
    "# myHazRatios \n",
    "# indexed by column index\n",
    "X_features = X_bcd.columns\n",
    "# create a list of lists of length 4: [[Median, Mean, LB, UB], [...]]\n",
    "mySummaries = []\n",
    "for i in range(len(myHazRatios)):\n",
    "    myHazRatios[i].sort()\n",
    "    mySummaries.append([np.median(myHazRatios[i]), \n",
    "                                  myHazRatios[i][24], myHazRatios[i][974]])\n",
    "\n",
    "# print([i for i in range(len(myHazRatios_all)) if X_features[i] in myContinuousCols])\n",
    "print(mySummaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all binary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "COX_bins_all = pd.read_csv(\"summary_coxPH_BINARYVARS_bcd.csv\")\n",
    "# get only HR, LB, and UB\n",
    "COX_bins_all = COX_bins_all[[\"Covariate\", \"HR\", \"LB\", \"UB\"]]\n",
    "# COX_bins.Covariate\n",
    "list_HRs_all = [[COX_bins_all['HR'][i], COX_bins_all['LB'][i], COX_bins_all['UB'][i]] for i in range(len(COX_bins_all['Covariate']))]\n",
    "df_cox_bins_all = pd.DataFrame(list_HRs_all, \n",
    "                           columns = [\"medianHR\", \"LB_HR\", \"UB_HR\"], \n",
    "                           index = COX_bins_all['Covariate'])\n",
    "\n",
    "# errors_bin_cox_all = np.array([list(df_cox_bins_all.medianHR - df_cox_bins_all.LB_HR),list(df_cox_bins_all.UB_HR - df_cox_bins_all.medianHR)])\n",
    "\n",
    "COX_conts_all = pd.read_csv(\"summary_coxPH_nonbinVARS.csv\")\n",
    "myList_all = list(COX_conts_all.iloc[0])\n",
    "HRs_cont_all = []\n",
    "# print(int(len(myList) / 3))\n",
    "for i in range(int(len(myList_all)/3)):\n",
    "    HRs_cont_all.append([myList_all[(3*i)], \n",
    "                     myList_all[(3*i) + 1], \n",
    "                     myList_all[(3*i) + 2]])\n",
    "    \n",
    "df_cox_conts_all = pd.DataFrame(HRs_cont_all, index = [\"age\", \"size\", \"grade\", \"nodes\", \"prog_recp\",\"estrg_recp\"], columns = [\"medianHR\", \"LB_HR\", \"UB_HR\"])\n",
    "# print(df_cox_conts_all)\n",
    "# errorsContCOXAll = np.array([list(df_cox_conts_all.medianHR - df_cox_conts_all.LB_HR),list(df_cox_conts_all.UB_HR - df_cox_conts_all.medianHR)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           medianHR     LB_HR     UB_HR\n",
      "Covariate                              \n",
      "menopause  1.105178  0.673560  1.813377\n",
      "hormone    0.767082  0.551216  1.067484\n",
      "           medianHR     LB_HR     UB_HR\n",
      "age        1.118705  0.751723  1.664844\n",
      "size       1.284994  1.074148  1.537227\n",
      "grade      1.718134  1.196677  2.466817\n",
      "nodes      1.404701  1.245998  1.583618\n",
      "prog_recp  0.342240  0.214867  0.545121\n"
     ]
    }
   ],
   "source": [
    "print(df_cox_bins_all.head())\n",
    "print(df_cox_conts_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'size',\n",
       " 'grade',\n",
       " 'nodes',\n",
       " 'prog_recp',\n",
       " 'estrg_recp',\n",
       " 'menopause',\n",
       " 'hormone']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origCols = list(X_features)\n",
    "origCols = origCols[:1] + origCols[3:8] + origCols[1:3]\n",
    "origCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABbEAAAJkCAYAAAAvEmwyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZSdVZkv/u9OJQQCAcKgDCFEbCaZMUA3IDMI8lNR6dsOjM3QzuJ1uN3YLQFsWhAU+woOIILQ13ZAQFFRQQIoiAZsUZkUjZEZTIBAGDLs3x/nJCSVU5WqpIY35PNZ66xU7Xe/+zznVLFW+J6dZ5daawAAAAAAoIlGDHcBAAAAAADQEyE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGmvkcBcAAMDgKqXsk+T6pUybl+SZJE8kuS/J7Um+U2u9cXCrWzmUUiZ3GL641jptEJ+zK8lBSfZJskeSjZOsm2S1JLOS3J/kt0mmJPlerfWBwaoFAACWR6m1DncNAAAMoj6G2D25Oclba61/GbiKVj6llE5/6d631jplEJ5rRJJ/SvKRJK/o423zklxdaz1soOsBAIDlZSc2AAC92T3JlFLK9rXWZ4a7GHpXSnl5ksuSHNDPW7uSvHHgKwIAgOUnxAYAWHlNS/LX9tddSTZJq91Ed5sleWeSc4amLJZFKWVcWq1Btupl2iNJHk0yJskGSVYf/MoAAGD5ONgRAGDldWqtdVL7sVOSlyV5bw9zDx7Culg230rnAHtOks8m2bzWukGtdfta698kWSvJpCRnJ5kxdGUCAED/CLEBAEiS1Frn11rPS3J3h8vjO91TSrm4lFK7PS5uX9uklHJWKeW3pZQn29fO7WGdiaWUU0op15VS7i+lzC6lPFNKmVZKubyUcmwpZZXe6i+ljCml7FtK+XAp5WullF+WUu4rpcwopcxp1/CnUsr3Sin/XErp+Jo6rLt/KeWLpZSppZS/llKeb9c3vZRyeynl2+3aDyiljOn03vSw9PU9vXf9VUo5PMl+HS49m+R1tdaTaq1/WPRCrXVerfW2WuuC3tmf6bDuWqWU15ZSTm7/HG5rv4dPtN/TmaWU35dSriilvL+U0mkn/6LrHdPhNU9rX+sqpRxXSrm2lPJo+33+Synl/5VSdu7HezGxlPKvpZRr2j+jWaWUZ0spfy6l/LyU8ulSysGllNFLWefgUsrnSym/LqU8Vkp5of27dEcp5f+WUnbrQy3TOrzeY9rXdiulfKWU8sd2fbWUoic5AEAH2okAANBd6TA2q18LlPKGJJcmWXMp88Yk+XSS49NqadLdpu3Hm5NMLqUcVWu9oYflXpfkm7083Zrtx8T23NNKKZ9IcnrtcNp5KWVskq8nOaSH9TZpP3ZK8qb22JlJ/rmXGgbLv/Uw/uFa67VLu7nW+lSS/93h0glJPtXLrWu3H3+T5LAkZ5RS/net9UtLe85FlVImJrkiyY7dLo1P8rYk/6uUclyt9ZJe1lgzrR3nR6bz79KE9mO3JB9Msm9a7Ve6r7NDkkuS7NBhjXHtx3ZJ3ltKuSrJsbXWmT2/uo61nprkX2NTEQBAnwixAQBIkpRSSpITk2zZ4fLUfiz16iRvTbK0na5rpRUidg8uezIhybWllH+otX67H/X0ZFSSU9MKEid3uH5eeg6wG6OUsmmS7Ttcmp7ki0NczupJvlhKmVNr/Uof71kryU+TbNzLnK72uj+vtd7T/WIpZYMkN6UVpi+zUsprk1yZZNU+3vLGJD8vpexea/3rUme3vCetNi4AAPSREBsAYOV1SillQQ/srrR2va7XYd7sJB3bgPRg20W+fjbJH5OskSVbkvy/dA6wn00rgF2tfc+iu1VHJvlqKeU3tdbfL6WOx9uPZ9MK1Men887wk0spF9Vapy8YKK1DEt/WYe6ctA7EnN1ea5P0/HfqPyW5rf31qztcvzdL7nD/Uw9r9Wb/HsavqLXOW4b1elLTOhhyZpLn0joccnw6Hw75qVLKN2qtz/Rh3QW7uZNWb+4Hk2yRpHv7mNFJPpDk3YsOllK6klydngPsWUn+nNaHFhPTw4crpZRXJvlGOgfYj6f12jdKayf2orZI63f5tT08f3eLBtgzkjyQZP20DtoEAKAD/3wNAGDlNTGtcPXVaYXJnQLsB5O8odZ6bz/Xrkk+lmTdWuu2tdaJaQWAX02SUspBabX0WNT8JB9q37NVrXXTJFsn+WW3easnOa3Dc85M8p9phYlr1VrXr7VuXWvduda6TVpB6WvSCjQXNSrJO7qN/U2WDKd/mGT9WusWtdYda62bpRXk7phWuHp9koWhca114cGZHWpNkn9a5GDNBY9Te5jbmwk9jPdn93xPHkxyRpJ9kqxRa92w1vqq9nu6VVpB/huy5MGQ67bH+6qm9bN/Wa11u7SC4T90mNfpgNFj0vlDggfTavMyrta6Xbvetdp13dhh/ulZ8kOO+5K8pv27tG1ar+utaYX4izqovYu7r2am1SJn/fZBmxum9bv+q36sAQCw0rATGwCA3nw9yR3LcN/ptdYzFh2otT6a5NH2tyd0uOfTtdZPd7vn3lLK25N033X996WUf2r3cl4w97ok1/VUULvv9U9LKZ9Nqw/3onbv9dW0TKm1PtltzTlJft1+/Gd7V/BQW7+H8ceXd+Fa6/9byvX5Sb5bSrksyfu7Xd49ydf6+FT/tejPvtb651LKx9Pa4byoV5RSVqu1PrvI2Ikd1ns6yd4dDrN8Psl32zUv3JHd7qf99x3WeWOt9XeL3F+TfL2Usl1aH9Is6ri0Pujoi8NrrT/pVlunA1UBAIgQGwCA3n0wyTtKKfstGuYtxbNJzlnKnP06jB1WStm3j8/Rldau6u91v1BK2TutQwZfneSVae2+HZPOB1YusFG37+9K8kIWb2lxSrvlxNQkdye5p9b68KI3DXD7jr7q6XUtcVjlMi1eyoi0eoO/Pq3DDl+RZGxa72lvur+nvenUrqanUHfttH7HFvRV77TT/cLuAXZ37UB7gb2z5P8bzU1ySatV/BLW7TDW19/dn3UPsAEA6J0QGwBg5XVsrfXiZOGhjhumFS6f1f56gZcl+X4p5W/aO4+X5rZFd0h3V0pZI8k6HS7191C+Tbutu2FaO8df0891khd7MidJaq1Pl1IuSOsQvgVWTXJ8+7HgOZ9IcmuSHyS5rB+H+w2kR3sY72mHdp+VUrZK8s0s3ue8r9Ze+pQkrTYynXb7P93D/EV7Wnfvmb7A9X187gU27TA2Mp3blPRkvVLKmFrr7KXM629tAAArPT2xAQBIbXmw1npZkiM6TJmQVi/gvrh/KdfX6ldxPVu4G7bdGuLaLFuAnbR2dnf3v5NckN53NK+dVg/uc5PcV0p58zI+//KY3sN4T724+6SUsm6SKVm2ADvp/J528mgPH47M7cO9PQXl3Xt0L82A/072Ymn/fQAA0I0QGwCA7q5Pu11DN3v08f7nl3L9yaVc76tFQ9K3J3lVt+s1yX8k2TLJarXWUmstafUuXqpa6wu11hPTakny0SRXJ/lTWjuHO1kryX+VUjbp+0sYED31AX/Tcvbofn+Sl3cbeyHJh9NqKTJ6kff09OV4np5+X/rSDuWJHsY77fTvzWD8TvZkaf99AADQjRAbAIDFtA+ve6HDpQkDtP7T6bxT9h0LQtE+PiYvcu/+Hdb7Rq315FrrvbXW55b1ddRa/1Rr/VSt9fW11s3SamfxN2kF59O6TV81nQ8IHDS11j+nczuOCUn+aTmW7vSefqbWek6tdVqtddHfkQH53VgG96fzhwr79HOdTrvZn06yaj9/J6f183kBAOgDITYAAIsppWyXzu0VOu3OXladDrY7oS87h0spa5RSDuw2/LIOUx/rcO/qSY7uS4HtuUuotc6ttd5Xa/1aks92mNKpt3endhlLOxixP3raCX12KeWApd1cSlmzlHJ2t+G+vqcbJHnT0ksceLXWJ5P8ssOl40spm/V2byll1UW+vSFLti9ZI51b63Raa6tSSvd/CQAAwAARYgMAsFApZZskX+3h8p0D+FRf7jC2T5JvtUP07nVtUEp5SynlkiQPJvlYtymd2kG8vZSy8yJrbJLkO0km9rHGh0spXymlHN4OarvXtHE69wnvFFjP7DB2aPtAzeVWa/1WOn8wsFpah3J+ppTyykUvlFK6SimvLqWcleSPST7U7d5O7+m7Fg2H28HtNUnWXK4XsHwu6DA2NskNpZQ3LPrBSClllVLKwaWUnyT52wXj7TD88g7rnF9K+VApZbEPddrv3TallJNKKTckuSvJrgPyagAAWMLI4S4AAIBhc0op5b3tr0uSDZNs0P66u/lJvj5QT1xrvaaUck2Sg7tdOizJYaWUmUkeSOvvq+tn6Qfm3Zjk8G5j6ySZWkqZllYf4i3Sv00cayQ5pv1IKeXJJI8kmZ3WTvWJ6fxe3dZh7DdZsj3Hu5McXkp5MMm89tg/1Frv60eNizo8yc1Jtuo2PirJSUlOKqU8nNZu6tXS+nl33G3edmOWPBzylUnuLaX8Ma3X3mnX+VC7OMk7s2St45NcleSpUsqf03ofJqbV8iVJTus2/1+THJrWz32BVZKcneTM9nv3eFoB+UaLrAMAwCCzExsAYOU1Mcmr24+d0wo1e9oZ/Kla628H+PnfmuTXPVwbl2TbtALZpQXYSfKVtHZod1fSOoRwq7T+7vt8ki/1u9KWtdIKwndsr9npvfp9km91GO+0yzdptezYMS/+HFZbxtpSa52Z1m72ng56TFofUmyXVvjcW4CdtFqlPNNhvCvJ5nkxwJ6R5L/6U+tAqrXOS/L6JH/oYcqaab3mrdJL8Fxr/UNa/cw7HbzYlWTjJDsk2ay3dQAAGHhCbAAAejM7yb/UWv95oBdut3DYPcn5WbIfcW8eTGuH7aJrPZ1WkPlwL/c9lVZwfksfn6dTW5De/CrJwbXW2R2uXZjkpn6u12+11keSHJTkPUn+1I9b5yf5bre1pid5S5JZvdz3cHoPkIdErfXhtD4EuCQv7mpflnWuSbJLktv7eevN6Xy4JgAAA0A7EQAAFpib5Om0gsk70+qx/M1a66OD9YTtwPc9pZQzkhyZZK8k26TVCmS1Req5J60D/K5LcmutdX6HtW4vpWyf5INJ3pDWjtl5Se5P8v0kn6u1/qmUckwfy1unXc/fJtkprVYaG6bVbqKmFe7+Oa3w+qok36211h5e55z2AYvvSisY3iatnd1LPciyv9rvzfmllC8meW2SfdP6sGB8+zWtmtb7+kBaP+cpSb5Ta72/w1o/bPco/1BarV8mJHkurdd9VVrv6aOllIMG+nX0V631qSTHlFImp/W7tGeSrdN6zSOTPJrWByA/T/LD9PBhRq31N0leXUrZO8mbk/xdkk2TrJ3Wz/2pJNPSeu9uSvLjduAPAMAgKT38PXvYtXsXbtrD5UdqrUscrgMAAAAAwEtL03diP5nk3A7jTw91IQAAAAAADL2m78ROrXXi8FYCAAAAAMBwcbAjAAAAAACN1fR2IqNLKUekdYDMM2md+H1jrXWZTxwHAAAAAGDF0fR2Ip0OdvxTkmNrrTf0cN+JSU5MktVXX/3VW2211aDVCAAAAADA8rvtttser7Wu3+lak0PsU5LclOR3SWYl2SzJe9MKqJ9L8ne11l/3tsakSZPq1KlTB7tUAAAAAACWQynltlrrpE7XGttOpNZ6areh3yZ5Zynl6SQfSjI5yZuGui4AAAAAAIbOiniw4xfaf+41rFUAAAAAADDoVsQQ+9H2n6sPaxUAAAAAAAy6FTHE/rv2n38c1ioAAAAAABh0jQyxSynblFLW6TC+aZLPtb+9bGirAgAAAABgqDX1YMe/T/LPpZTrk/wpyawkr0xyaJJVk3w/ydnDVx4AAAAAAEOhqSH29Um2TLJTWu1DVk/yRJKfJrk0yaW11jp85QEAAAAAMBQaGWLXWm9IcsNw1wEAAAAAwPBqZIgNAAAAAKzcnn/++cyYMSOzZs3KvHnzhrsc+qGrqytjx47NOuusk9GjRy/3ekJsAAAAAKBRnn/++UyfPj3jxo3LxIkTM2rUqJRShrss+qDWmjlz5uSpp57K9OnTM2HChOUOskcMUG0AAAAAAANixowZGTduXNZbb72sssoqAuwVSCklq6yyStZbb72MGzcuM2bMWO41hdgAAAAAQKPMmjUra6655nCXwXJac801M2vWrOVeR4gNAAAAADTKvHnzMmrUqOEug+U0atSoAelnLsQGAAAAABpHC5EV30D9DIXYAAAAAAA0lhAbAAAAAIDGEmIDAAAAANBYI4e7AAAAAACA/pj4z98b7hJ6Ne2Thw53CS8pdmIDAAAAADTY3Xffnfe9733Zdttts9Zaa2WVVVbJRhttlEMPPTRf/vKX89xzzy1xz9SpU3Psscdms802y2qrrZY111wz2223XT7ykY/kgQceWGzu7Nmzs+WWW6arqys/+9nPOtZwyy23ZOTIkXnlK1+Zp59+elBeZ0+E2AAAAAAADXXaaadlm222yec+97mMHTs2Rx99dD784Q/nkEMOyd13353jjz8+e+6558L5tdb8n//zf7LLLrvksssuy1ZbbZX3v//9Oe644zJmzJicffbZ2WKLLfKtb31r4T1jxozJpZdemhEjRuTII4/MrFmzFqvh6aefzpFHHpkk+epXv5o11lhjaF58m3YiAAAAAAANdMYZZ+SUU07JJptskm9+85vZbbfdlphz9dVX55xzzln4/emnn56zzjorEydOzNVXX51tttlmsfmXX355jjjiiLz1rW/Nj3/84+y7775Jkl133TUf+9jHcuqpp+akk07Kl7/85YX3nHTSSbnvvvty8sknZ4899hikV9uzUmsd8icdKpMmTapTp04d7jIAAAAAgH646667svXWW/d4fWXoiT1t2rRsscUWSZLbb7892267bY9zn3/++YwePTrTpk3L5ptvnlJKbrvttmy33XYd53/hC1/Iu971rmy55Za58847M2JEq2HH3Llzs/vuu+eXv/xlrrjiihx22GG56qqrcthhh2XnnXfOz3/+84waNapfr2NpP8sFSim31VondbqmnQgAAAAAQMN85StfyZw5c/KWt7yl1wA7SUaPHr3wnrlz5+ZNb3pTjwF2khx//PHZaKONcs899+SGG25YOD5y5MhceumlGTNmTE488cTccccdOeGEE7Laaqvlsssu63eAPVCE2AAAAAAADfPTn/40SbL//vv3+54DDjig13kjR47MPvvskyRLHOS45ZZb5qyzzspjjz2WXXfdNY899ljOPPPMPu2mHixCbAAAAACAhnnooYeSJOPHj+/3PZtssslS5y6Y8+CDDy5x7d3vfncmTpyY559/Prvttlve+9739rmGwSDEBgAAAABomAVnGZZSBuWe3uZefPHFmTZtWpLkjjvuyO9///s+1zAYhNgAAAAAAA2z0UYbJUnuv//+Pt+z4YYbJkmmT5++1LkL1l1wzwLTpk3LBz7wgay99tr5zGc+k2effTZHHXVU5s2b1+c6BpoQGwAAAACgYfbcc88kyXXXXdfve6699tpe582bNy9TpkxJkuyxxx4Lx+fPn5+jjjoqs2bNyvnnn5+TTjopb3/723PrrbfmP/7jP/r5CgaOEBsAAAAAoGGOPfbYjBo1KpdffnnuvPPOXuc+//zzSZJjjjkmXV1dueKKK/K73/2ux/kXXXRRHnzwwWy55ZbZe++9F46fddZZuemmm/LWt741b3vb25Ik5513XsaPH5/TTjstv/rVrwbglfWfEBsAAAAAoGEmTpyYyZMn54UXXsihhx6aqVOndpx3zTXX5JBDDkmSbLbZZjn55JMzZ86cvOENb+gYfl955ZX5wAc+kK6urpx//vkZMaIVEf/P//xPTjnllGy88cY5//zzF85fe+21c9FFF2Xu3Lk58sgjFwbmQ2nkkD8jAAAAAABLdfLJJ2fu3Lk59dRTs8suu2T33XfPpEmTssYaa+SRRx7JjTfemN///veZNGnSwnsmT56cZ555Jp/+9Kezww475LWvfW222WabzJkzJzfffHNuvfXWrLbaavna176W/fbbL0ny3HPP5YgjjsicOXNy8cUXZ9y4cYvVceCBB+Zd73pXzj///HzsYx/L2WefPaTvQ1lwCuVL0aRJk2pPn1AAAAAAAM101113Zeuttx7uMhrjrrvuyvnnn5/rr78+06dPz3PPPZd11103O+64Yw4//PAcccQRGT169GL3/OIXv8h5552XG2+8MQ8//HC6uroyceLEHHzwwTnppJMyfvz4hXM/+MEP5txzz8373//+fPazn+1Yw+zZs7PTTjvlD3/4Q66//vrstddefa69Lz/LUspttdZJHa8JsQEAAACAJhFiv3QMRIitJzYAAAAAAI0lxAYAAAAAoLGE2AAAAAAANJYQGwAAAACAxhJiAwAAAADQWEJsAAAAAAAaS4gNAAAAAEBjCbEBAAAAAGgsITYAAAAAAI0lxAYAAAAAoLGE2AAAAAAANJYQGwAAAACAxhJiAwAAAADQWCOHuwAAAAAAgH6ZvNZwV9C7yU8OdwUvKXZiAwAAAAA00IUXXphSSg455JAe5xx66KEppeT8889f4tr111+fo48+OltssUXGjh2bVVZZJRtssEH233//fPKTn8z999+/xD377LNPSimLPUaOHJmXv/zlOfTQQ/ODH/xgQF9jX9iJDQAAAADQQMcff3y++93v5jvf+U7OO++8vOc971ns+uc///l8//vfzyGHHJJ3v/vdC8efeuqpHH300bnyyiszatSo7LXXXnnd616X1VdfPY899lh+8Ytf5F/+5V9yyimn5Oc//3l22mmnJZ776KOPzsSJE5Mkzz77bO65555873vfy/e///188YtfzIknnjior31RQmwAAAAAgIa64IILcsstt+SjH/1oDjjggGy55ZZJknvvvTcf/vCHs+666+aiiy5aOH/evHl5y1vekmuvvTZ77713Lr300myyySZLrHvnnXfm4x//eJ566qmOz3vMMcdkn332WWzs8ssvz+GHH54zzjhjSENs7UQAAAAAABrqZS97WS644ILMnj07RxxxRObOnZu5c+fmiCOOyOzZs/OlL30pG2ywwcL5l112Wa699tpsvvnm+d73vtcxwE6SV73qVfnWt76VPfbYo8+1HHTQQUmSxx57bPleVD/ZiQ0AAAAA0GBvfOMb84//+I+56KKLctpppyVJfvnLX+aYY47Jm9/85sXmXnjhhUmSj3zkI1l99dWXuvbIkX2PiK+99tokyaRJk/p8z0AQYgMAAAAANNy5556b66+/PmeccUaSZOLEifnP//zPxebMnTs3t956a5Jkv/32W67nu/jiizNlypQkyXPPPZd77703V199dV71qlfl85///HKt3V9CbAAAAACAhhs7dmw+/vGP59hjj03SOtRx7Nixi82ZMWNG5syZkyTZeOONl1hjypQpC4PpBXbcccccdthhS8y95JJLlhhbZ5118o53vCOvfOUrl/VlLBMhNgAAAABAwz377LM588wzF37/zW9+MwcffPBic2qtva4xZcqUnHrqqYuNHX300R1D7Ouvv37hwY5z5szJtGnTcu655+ZjH/tYrrnmmkyZMiUjRgzNkYsOdgQAAAAAaLiPfvSjufvuu/OBD3wgO+64Yy666KJ897vfXWzOuuuum1GjRiVJHnzwwSXWmDx5cmqtqbXmxz/+cZ+fe9SoUdl8881z3nnnZY899shNN92Ur3/968v3gvpBiA0AAAAA0GA/+tGPct5552W77bbLmWeemUsvvTSjR4/OCSeckMcff3zhvJEjR2a33XZLklx33XWDUsuC9X/xi18MyvqdCLEBAAAAABpqxowZOfbYYzNq1KhcdtllGT16dLbddtucfvrpeeSRR/LOd75zsfnHH398kuScc87J7NmzB7yemTNnJknmz58/4Gv3RIgNAAAAANBQ73rXu/Lggw/mE5/4RLbffvuF4x/60Ifymte8Jpdffnkuu+yyheNHHHFE9t9//9xzzz15/etfn/vvv7/juk888US/a5k2bVq+/e1vJ8nCftlDwcGOAAAAAAANdOmll+Yb3/hG9tprr3zoQx9a7NqIESNyySWXZPvtt8/73ve+7LPPPhk/fny6urry7W9/O0cddVSuuuqqbLbZZtl7772z7bbbZsyYMXnsscfyu9/9LjfffHNWWWWVhe1Burv44oszZcqUJK2DHf/85z/nyiuvzDPPPJPXv/71HQ+DHCxlaSdWrsgmTZpUp06dOtxlAAAAAAD9cNddd2Xrrbce7jKG1fTp07P99tun1po77rgjm266acd5F154YU444YQceOCB+eEPf5hSysJr1113XS655JLcfPPNeeihhzJnzpyMGzcu22yzTQ444IAcddRRGT9+/GLr7bPPPrnhhhsWGyulZK211sq2226bI488Mscdd1y6urr69Dr6+rMspdxWa53U8ZoQGwAAAABoEiH2S8dAhNh6YgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAQOPUWoe7BJbTQP0MhdgAAAAAQKN0dXVlzpw5w10Gy2nOnDnp6upa7nWE2AAAAABAo4wdOzZPPfXUcJfBcnrqqacyduzY5V5HiA0AAAAANMo666yTmTNn5vHHH88LL7ygtcgKpNaaF154IY8//nhmzpyZddZZZ7nXHDkAdQEAAAAADJjRo0dnwoQJmTFjRqZNm5Z58+YNd0n0Q1dXV8aOHZsJEyZk9OjRy72eEBsAAAAAaJzRo0dnww03zIYbbjjcpTDMtBMBAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEOm9j1gAACAASURBVBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMZaYULsUsqRpZTafhw/3PUAAAAAADD4VogQu5SySZL/m+Tp4a4FAAAAAICh0/gQu5RSknwlyV+TfGGYywEAAAAAYAg1PsRO8v4k+yU5Nskzw1wLAAAAAABDqNEhdill6ySfTPLZWuuNw10PAAAAAABDq7EhdillZJJLk0xPcvIwlwMAAAAAwDAYOdwF9OLjSXZKsmet9dm+3lRKOTHJiUkyYcKEQSoNAAAAAICh0Mid2KWUXdPafX1OrfWW/txba/1SrXVSrXXS+uuvPzgFAgAAAAAwJBoXYi/SRuTeJP82zOUAAAAAADCMGhdiJ1kjyRZJtk7yXCmlLngkOaU954L22LnDViUAAAAAAIOuiT2xn0/y5R6u7ZxWn+yfJrknSb9ajQAAAAAAsGJpXIjdPsTx+E7XSimT0wqxL6m1XjiUdQEAAAAAMPSa2E4EAAAAAACSCLEBAAAAAGiwFSrErrVOrrUWrUQAAAAAAFYOK1SIDQAAAADAykWIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0FhCbAAAAAAAGkuIDQAAAABAYwmxAQAAAABoLCE2AAAAAACNJcQGAAAAAKCxhNgAAAAAADSWEBsAAAAAgMYSYgMAAAAA0Fgjl/XGUso+Sf5Xkp2TrN8efizJ7Um+UWudsrzFAQAAAACwcut3iF1KWS/JfyU5YMHQIpdfkWSXJP9USvlxkiNqrY8vd5UAAAAAAKyU+hVil1JWSfLjJNunFV7fkuQnSe5vTxmfZL8kf5fkwCQ/KqX8ba31hQGrGAAAAACAlUZ/d2K/N8kOSWYkeVut9ccd5vxbKeWgJF9rz31Pks8sV5UAAAAAAKyU+nuw4z8kqUlO7CHATpLUWn+U5MS0dmu/ddnLAwAAAABgZdbfEHvLJM8luaIPc69oz92qv0UBAAAAAEDS/xB7VJI5tda6tIm11vlJ5mQZDo8EAAAAAICk/yH29CRjSyk7L21iKeXVSca27wEAAAAAgH7rb4j9/bT6XH+5lLJ+T5NKKS9P8uW0+md/b9nLAwAAAABgZdbfVh9nJjk6yfZJ7i6lXJBkSpIHkoxOsmmSfZMck2RMkhlJzhqgWgEAAAAAWMn0K8SutT5aSnldkiuTbJDkI+1HdyXJQ0kOq7U+utxVAgAAAACwUupvO5HUWn+R5FVJTknym7RahpT2o7bHPp5km1rrLweuVAAAAAAAVjb9bSeSJKm1PpHk9CSnl1JGJVmnfWlGrXXOQBUHAAAAAMDKbZlC7EW1Q+tHBqAWAAAAAABYTL/biQyVUsqZpZTrSil/KaU8W0qZUUr5VSnllFLKusNdHwAAAAAAg6/HndillL3aX86utU7tNtYvtdYbl+G2Dya5PcmPkzyaZPUkf5tkcpITSyl/W2v9y7LUAwAAAADAiqG3diJT0jqo8Z60DnJcdKw/6lKepydr1lqf6z5YSvn3JCcn+Zck716GdQEAAAAAWEH0Fi5PTyuAfrDD2KDrFGC3fSOtEHvzoagDAAAAAIDh02OIXWud2JexYfD69p93DGsVAAAAAAAMumVp8zGkSikfTrJGkrWSTEqyZ1oB9ieHsy4AAAAAAAZfv0Ls9sGOL9Raf97H+bsmWXUZD3Zc4MNJXr7I99ckOabW+lgPz3likhOTZMKECcvxtAAAAAAADLcR/Zw/Jcnl/Zj/9SQ/6edzLKbWukGttSTZIMmbk2yW5FellJ17mP+lWuukWuuk9ddff3meGgAAAACAYdbfEDtJyiDP76jW+kit9YokByVZN8lXB2JdAAAAAACaa1lC7P4Ym+SFgVyw1vrnJHcm2aaUst5Arg0AAAAAQLMMWojd7oe9TpIHBmH5jdp/zhuEtQEAAAAAaIheD3YspRyd5Ohuw+uUUnrrc12SrJ3kVUlqkh/0t6hSylZJnqi1PtxtfESS05O8LMnNtdaZ/V0bAAAAAIAVR68hdpKJSfbpNrZKh7Ge3Jjk4/2qqOXgJJ8qpdyY5L4kf03y8iR7p3Ww48NJTliGdQEAAF5SfvTrv+Sc79yRJLnkfftmg7XHDHNFK6DfXpz88NjW18f/KVlr4nBWAwB0s7QQ+8ok09pflyQXJXkyyUm93DM/yVNJfldr/cMy1nVtki8l2SPJDmnt7H4myb1JLk3yn7XWGcu4NgAAAAAAK4heQ+xa66+T/HrB96WUi5I8W2u9ZDCLqrX+Nsl7BvM5AAAAVjS/mT4jq47qyuYbrtWn+Tfe+VC22WRc1h276iBXtgK5/6Zk1OrJy3fu2/x7vplsvGeyxoaDWxcA0KOl7cReTK110A6CBAAAoGfz5s/PuVffkQf++kz23XajHL3vlj22DvnN9Bm58Nq7cvcDT+TQV0/I+1+33RBX21Dz5yY/OiGZeW+y9duTPT7Rc+uQ+29KbvxI8tCtyQ7vTA74/JCWCgC8qF8hNgAAAMPjoZmz88Lc+alJfvLbB3PTXQ/n9btsmvUW2WX9l8efzhd+eGduufeRhWPTHp2VefNrukaUYai6YZ74YzL32SQ1ueu/knu/lez4nmSNjV+cM+Pu5PqTkvuuenHssd8k8+clI7qGvGQAICm11mW/uZQNkmyUZPW0emZ3VGu9cZmfZDlMmjSpTp06dTieGgAAYMC9MHdevn/79Pz3T+/LzGee73XupuuvkWP22TK7b7XBEFW3gpj7fHLHF5Nbz0hmP9L73HW3ae3W3vywoakNAFZipZTbaq2TOl7rb4hdShmR5INJ3p1kYh9uqbXWYdnxLcQGAABeip6bMy9X3vqnfPOWP+bp5+Ysdm3DcWNyxF6bZ7/tNs6IYvd1j+bMTm7/bDL1U8lzMxe/ttZmye6Tk63fkRRdNQFgKPQWYvcrXG4H2FcleV1aO6+fSLJ2kvlJHkyyXpIF/5btmSSPL2PNAAAA9KL0ElCPKKXnfyrLi3oKqEtJSld6+QfHAMAQ6tdO7FLKcUkuSPJQkv9Va/1ZKWV+kodrrRu1Q+49k3wiyaQk76y1fnUQ6u4TO7EBAICXkjnz5ucHt0/P1376h8x4uvd2Ipu9fM0cu++W2XXzlw1RdSuIeS8kd1yQ3PqJ5JmHe5+7/g7Jnmckm71uaGoDgJVYbzux+/vvoo5IUpN8pNb6s+4Xa63z2/2v901yQ5ILSyl/29+CAQAAWNz9f306x50/Jedd87vMePr5jOoakTft9oqceODWC+d84m27LAyt//jIU/m3//5lPnrpzzNv/rKfhfSSMuPe5KItk5+8txVgd62S7HxSsvc5L8558/eTzQ5tff3Yr5MrDk2+sV/rYEcAYFj0N8Terv3nFd3GFzuiudY6L62+2SOTfHjZSgMAAGCBDceNSdeIVnuL12y9YS54195550GvytjVRi2cs8l6a+T0t+6SM4/cLX+zwZpL3LfSW3uzZES7q+YWf58cc1ey72eSVdd5cc46Wydvujr5+58kL9u5fd8rkxFdS64HAAyJ/h64uEaSJ2utzy4y9lySsd0n1lrvLqU8lWT35agPAACAJF0jRuQDr9suo0d1Zevx43qdu+PE9fK54/fMtXc8kJ1esd4QVbgCGDEyOfCLycgxyUZL+UfDE/ZNjpia3HlpMmH/oakPAOiovyH2I0k2LKWMqLXOb489lmR8KWWjWuuDCya2+2OvlhcPegQAAGA57NiPQLqUkgN3GD+I1aygJuzX97mlJNscNXi1AAB90t92In9Oq3XIRouM3d7+803d5v5/SUalFXwDAAAAAEC/9Xcn9o+T7JHkwCRfaY/9V5I3JvlkKWVMkv9Jq3f2v6V1COR3B6ZUAAAAujtoh01y0A6bDHcZK7Ztj2k9AIBG6u9O7G8nmZnk0AUDtdZvJbkyyepJPpnkmiSfSrJWkvuSfHxAKgUAAAAAYKXTr53YtdbfJenUhO3vk5yY5PAk45M8mdau7bNrrTOXt0gAAAAAAFZO/W0n0lGtdV6Sz7cfAAAAAAAwIPrbTqTfSimvHuznAAAAAADgpWnQQuxSyu6llB8kuXWwngMAAAAAgJe2frUTKaWsnaSr1vrXXubsl+Rfk+ydpCSpy1UhAAAAAAArraXuxC6lrFpK+WQp5YEkf03yaCnlyVLK59qh9oJ525dSrkvrQMd90gqwb07ypsEpHQAAAACAl7ped2KXUrqS/CjJHmmF0guMTfKuJLuVUv4uyTFJ/m+S0WntvL4qyVm11lsGoWYAoOF+9Ou/5Jzv3JEkueR9+2aDtccMc0UAAACsqJbWTuSYJHu2v/5RWrusS5ID24+dk5yf5B/b45cm+fda672DUSwAAAAAACuXpbUT+Ye0dlZ/rtZ6cK31nFrr2bXW1yY5L63g+rgkM5LsVWs9WoANACuX30yfkd8/9GSf599450P566znBrEiAAAAXkqWthN7+/af/97h2ieSvKf99YdqrT8bsKoAgBXCvPnzc+7Vd+SBvz6TfbfdKEfvu2WPrUN+M31GLrz2rtz9wBM59NUT8v7XbTfE1QIAALAiWlqIPS7JrFrrI90v1FofKaXMSrJGkmsGozgAoNkemjk7L8ydn5rkJ799MDfd9XBev8umWW/sqgvn/OXxp/OFH96ZW+598a8T0x6dlXnza7pGlA6rAgAAwItKrbXni6XMT/JwrXWjHq4/lORltdauQapvuUyaNKlOnTp1uMsAgJe0F+bOy/dvn57//ul9mfnM873O3XT9NXLMPltm9602GKLqAAAAWBGUUm6rtU7qdG1pO7EBAHq1ysiuHLbrK3LwThNy5a1/yjdv+WOefm7OYnM2HDcmR+y1efbbbuOMKHZfAwAA0Hd9CbFXKaW8Jq1DHJe4liS9XE+S1FpvXLbyAIAVSekloB5RSs9/WQAAAIAe9KWdSM8T+qbWWodlx7d2IgAw+ObMm58f3D49X/vpHzLj6d7biWz28jVz7L5bZtfNXzZE1QEAALAi6K2dyIi+3D8ADwDgJej+vz6d486fkvOu+V1mPP18RnWNyJt2e0VOPHDrhXM+8bZdFobWf3zkqfzbf/8yH73055k3f3k/JwcAAGBlsLQd0q8YkioAgBXShuPGpGtE6/Pq12y9YY7bf6tsOG5MfvTrvyycs8l6a+T0t+6S/5n2eC748V35w8NPLXYfAAAA9KbXELvW+uehKgQAWPF0jRiRD7xuu4we1ZWtx4/rde6OE9fL547fM9fe8UB2esV6Q1QhAAAAK7ph6VUNALx07NiPQLqUkgN3GD+I1QAAAPBS05ee2AAAAAAAMCzsxAYABtxBO2ySg3bYZLjLAAAA4CXATmwAAAAAABpLiA0AAAAAQGMJsQEAAAAAaCwhNgAAAAAAjSXEBgAAAACgsYTYAAAAAAA0lhAbAAAAAIDGGtnThVLKTwboOWqtdf8BWgsAAAAAgJVIjyF2kn2Wcm9NUnq5lvb12sMcAAAAAADoVW8h9rE9jK+T5ONJ1kpyY5IbkjyQVmC9YZK9k+yV5MkkpyWZOVDFAgAAAACwcukxxK61XtJ9rJSyVpJfJnk+yV611p92ureUsnuSy5O8M8muA1MqAAAADIzJkyfn1FNP7fH6KaecksmTJw9dQQBAj0qtfe/2Ucr/396dh9lVlfkC/n1JgIBDEJAGQQUcEJUGEVBBJYwioILtjAN6FWek27aveh0KpXFox+vUaqs44DwrKF7FAAIOiOIAiIKAYFBmZAhT1v1jn4RKpSpJJZWqXcn7Ps9+9sle6+zz1SFZtfmdfdaqdyc5MskTW2vHL6fvgUm+k+TdrbXXrFKVK2nnnXduZ5555lS8NAAAANPE3LlzkyTz5s2b0joAYG1WVb9sre08WtuMcZ7r4CQ3Ly/AHjghyc1JDhnnawAAAAAAQJLxh9j3SrJwRTq27hbvOwbPAQAAAACAcRtviH1VkrtU1e7L6zjoc9ckV69MYQAAAAAAMN4Q+4QkleRTVXX/sTpV1f2SfCpJS7IiU48AAGuAoaGhVNWYmwWyAAAAGK/xLuy4eZKzk2yc5NYkX09ycpK/DrrcK8ljkzw5yewkf0+yY2vt8gmseYVZ2BEApo5FsgCYLvzOAoCpt6yFHWeN50SttflVtUeSrybZLskzBttSr5nknCRPnaoAGwAAAACA6W9cIXaStNbOraod0oXXT0myU5J7DpqvSHJWkq8k+VJr7faJKhQAAAAAgLXPuEPsJBmE058bbAAAAAAAsFqMa2HHqrqmqq6qqm1WV0EAAAAAALDIuELsJOsmmdlau3B1FAMAAAAAAMONN8S+JF2QDQAAAAAAq914Q+xvJ1mvqvZdHcUAAAAAAMBw4w2xj0lyUZKPV9V2E18OAAAAAADcadY4+z8pyUeSvCnJr6rqe0nOSHJFkjvGelJr7TMrXSEAAAAAAGut8YbYxyZpSWrw5ycOtuURYgMAAAAAMG7jDbFPSRdiAwAAAADAajeuELu1Nnc11QEAAAAAAEsZ78KOAAAAAAAwaYTYAAAAAAD0lhAbAAAAAIDeGu/CjkmSqtolyUuS7J7kXknusozurbW2Uq8DAAAAAMDabdzhclW9NsnRWfG7uGu8rwEAAAAAAMk4pxOpqj2THJOkJXlTkp0GTVckuX+6O7PfnOTKwfakJFtPVLEAAAAAAKxdxjsn9ivTBdhvbq0d3Vr79eD4Ha21C1trZ7TW3ppkhyTXJPlEktsnrlwAAAAAANYm4w2xHzHYf2xZ52mtzU/ysiSbJHn9ypUGAAAAAMDabrwh9iZJbmytXTns2O1JNhil70lJbk7y+JWsDQAAAACAtdx4Q+xrsvRikNckuUtVzRl+sLXWkixMsvnKlwcAAAAAwNpsvCH2pUnWq6p7Djt2zmA/d3jHqtohyV2S3LjS1QEAAAAAsFYbb4h92mC/87Bj305SSd5VVbtU1TpVtVOST6dbBPLkVS8TAAAAAIC10XhD7G+kC6yfN+zYR5L8Mcn9kvw0yYIkv0jyz+nmxB5a5SoBAAAAAFgrjTfEPiXJ9kneuOhAa21Bkj2SfCXJrelC7iQ5I8lerbXfTkCdAAAAAACshUYu0rhMrbWFSX4/yvHLkzy9qtZJskmS61tr5sIGAAAAAGCVjCvEXp7W2m1J5k/kOQEAAAAAWHuNK8SuqucOHp7eWvvTCvR/apL1W2ufWZniAAAAAABYu433Tuxjk7Qk11fVs1pr31tO//+b5J5JhNgAAAAAAIzbeBd2TLqFG+ck+XZVvWYF+wMAAAAAwLitTIj99yTvSDIzydur6nNVtd7ElgUAAAAAACsXYi9srb0uybOSLEjyzCSnVNXmE1oZAAAAAABrvZUJsZMkrbUvJnlMksuS7JLkzKp6xEQVBgAAAAAAKx1iJ0lr7awkD09yWpLNk8yrqudNRGEAAAAAALBKIXaStNauSLJnko8nWS/JJ6vqPVVlQUcAAAAAAFbJKofYSdJau7219uIkr0xyR5JXJTkxXagNAAAAAAArZUJC7EVaax9Ksm+Sq5PsnWTDiTw/AAAAAABrl/GG2Jck+cuyOrTWTk6yc5LfrmxRAAAAAACQJLPG07m1ttUK9ru4qnZNt9gjAAAAAACslHGF2OPRWrs1ycWr6/wAAAAAAKz5JnRObAAAAAAAmEgrdSd2Va2f5ClJdk9yryR3SVJjdG+ttb1XrjwAAAAAANZm4w6xq2qvJJ9Pcs90wXVb1DSs2/BjLeNUVRsnOSTJgUm2T7JFklvTLRb5qSSfaq0tHO95AQAAAACYXsYVYlfV/ZN8K92d1z9McnyS9ya5Lsmrk/xTkn2S7JnkyiRHJblhJep6apKPJJmf5MdJLhmc+8lJ/ifJ46vqqa21cQfkAAAAAABMH+O9E/s16QLsz7XWnpskVfXeJDe31j456PO2qtovyVeTPD/dlCPjdX6SJyY5fvgd11X1+iQ/T/Iv6QLtr63EuQEAAAAAmCbGu7DjXummBzl6WZ1aaz9IcmSSnZL8+3iLaq2d1Fr7zsgpQ1prlyf578Ef5473vAAAAAAATC/jDbG3SHJra+38YccWJpk9St/PJ7k9ydNWsrax3DbY3z7B5wUAAAAAoGfGG2LfMtiG+0eSOVW17vCDrbUFSW5MsvXKl7ekqpqV5LmDP35/jD6HV9WZVXXmFVdcMVEvDQAAAADAFBhviH1pkrtV1d2GHbtgsN95eMeq2izJnCS18uUt5e1JHprkhNbaiaN1aK19rLW2c2tt53ve854T+NIAAAAAAEy28YbYZw/2Dx527Efpguo3VdXsJBnclf3+QfuvVqnCgao6Ismrk5yX5DkTcU4AAAAAAPptvCH2t9IF1s8cduz/Jrkhyb5J/lJVp6W7Y/sp6RaBfPeqFllVL08Xip+TZM/W2tWrek4AAAAAAPpvvCH2CUlemeSniw601i5L8oQkf02ycZJHJdkkyc1JjmytfWtVCqyqI5N8MMnv0gXYl6/K+QAAAAAAmD5mjadza+3GJB8a5fjJVbV1ugB7yyTXJTmttXbdqhRXVf873TzYv06yb2vtylU5HwAAAAAA08u4Quxlaa3dnuTUiTpfVb0xyVuS/DLJfqYQAQAAAABY+0xYiD2Rqup56QLsO9IF40dU1chuF7XWjp3k0gAAAAAAmES9DLGTbD3Yz0xy5Bh9Tk5y7KRUAwAAAADAlFhmiF1VJ03Aa7TW2t7jfMJQkqEJeG0AAAAAAKax5d2JPTdJS7LUXB6D4xmjbbR+AAAAAAAwLssLsT+TsUPopydZL8mnJ7QiAAAAAAAYWGaI3Vo7bKy2qto/yaattedPdFEAAAAAAJAkM6a6AAAAAAAAGIsQGwAAAACA3lrenNgAAACw6obmTHUFY7voxm7f5xqXZei6qa4AAFYrd2IDAAAAANBbQmwAAAAAAHpLiA0AAAAAQG8JsQEAAAAA6K1lLuxYVScto3mjFeiTJK21tvd4CwMAAAAAgGWG2EnmJmlJajl9lqWNox4AAAAAAFhseSH2ZyKEBgAAAABgiiwzxG6tHTZJdQAAAAAAwFIs7AgAAAAAQG8JsQEAAAAA6C0hNgAAAAAAvSXEBgAAAACgt4TYAAAAAAD0lhAbAAAAAIDeEmIDAAAAANBbs6a6AABg2bZ67fFTXcJKufzCq5L0u/6L3n7gVJcAAADAcrgTGwAAAACA3hJiAwAAAADQW0Js1ho/OPsvedxbj8/j3np8Lr/2pqkuZ3r63bHJu6vbrrtoqqsBAAAAYC0gxAYAAAAAoLeE2KyRfnvJ1fnj/OtWuP8p58zPVf9YsBormoYuPTX521kr3v8PX0lumL/66gEAAABgrTRrqguAiXbHwoV533d/k8uuujF7PvReed6e22azDTcYte9vL7k6//PDc3PeZdfmwIffJ0ccsP0kV9tTC29PfvCi5Jrzk+2elex+dDJnq9H7Xnpqcsprkvk/S3Z4SbLPRya1VAAAAADWbEJs1jjzr7kpt96+MC3JSb/7a0499/I8YZf7ZpO7zV7c5y9X3pD/PvGcnHH+3xYfu+jv/8gdC1tmzqgpqLpnrr0wuf3mJC0597jk/K8mO748uesWd/a5+rzkx0cmF3zrzmNX/DZZeEcyY+aklwwAAADAmkmIzRpny43vmk+8bI+ccNYl+eJPLsg1N96Sr//0z0v0ecMXfrH48X3vedccNnfb7PagzSa71P7a6IHJC85PfvPR5GfHJDf9Lfnle5bs8/XH3/l444d0d2s/4ODJrRMAAACANZ4QmzXSurNm5uBdt87+D7tPvvmzP+crZ1yYGxbctkSfze+xQZ792Adkr+23yIxy9/VSZq2X7HREsv0Lk7Pen5z5X8mCa5bsM2ebZLehZLtDkzLFPgAAAAATT+rEGq+WEVDPqIr4egWMFVBXJTUz8S4CAAAAsJq4E5s10m13LMz3zrokX/jJn3L1DbeM2mf+NTflHd/8db5yxoV5/p7bZtcHbDrJVfbcHbcmv/l48rOjkxsvH73PtRckJxya/OKdyaOPSbY5YHJrBAAAAGCN505s1jiXXnVD/teH5+VD3/99rr7hlqwzc0YOecTWOXzf7Rb3OfqZuywOrS/82/V54xd/kf/47E9zx8I2VWX3y9XnJ5/cNjnpFV2Ag0otFQAAIABJREFUPXPdZKcjkz3efWefJ5+QbHNg9/iKs5NvHJh8ea9uYUcAAAAAmCBCbNY4m99jg8yc0U1v8ZjtNs/HX7pHXrLfg3O39ddZ3Ofem9w1b33GLnnHcx6R+29296Wet9bbcJtkxuCLGg98anLYucme701mb3Rnn422Sw75bvLUk5JNdxo8737JjJmTXy8AAAAAayzTibDGmTljRl51wPZZb52Z2W7Leyyz745bbZIPvvDR+eFvLsvDtt5kkiqcBmbMSvb9aDJrg+Rej1x23/vsmTz7zOSczyb32Xty6gMAAABgreFObNZIO269yXID7EWqKvvusGU2ufvs1VzVNHOfvZYfYC9SlTzkucndtli9NQEAsNjQ0FCqasxtaGhoqksEAJgQ7sQGAACYhoaGhhYH1XPnzk2SzJs3b8rqAQBYXYTYrDX22+He2W+He091GdPbQw/rNgAAAACYJKYTAQAAAACgt4TYAAAAAAD0lhCbNZ4FbwAAAABg+jInNms8C94AAAAAwPTlTmwAAAAAAHpLiA0sk+lYAAAAAJhKphMBlsl0LAAAAABMJXdiAwAAAADQW0JsAAAAAAB6S4gNAAAAAEBvCbEBAAAAAOgtITYAAAAAAL01a6oLAAAAgMk2NG9Bjjr51iWO1VHXL3785j3WzdDc2ZNdFtBjPzj7L3n3t3+TJPn0K/fMZhtuMMUVTUO/OzY58fnd4xf+OZmz1VRWwzQixAYAAGCtMzR3tpAaAKYJ04kAAAAAwDC/veTq/HH+dSvc/5Rz5ueqfyxYjRVNQ5eemvztrBXv/4evJDfMX331MK25ExsAAAAABu5YuDDv++5vctlVN2bPh94rz9tz2zGnDvntJVfnf354bs677Noc+PD75IgDtp/kantq4e3JD16UXHN+st2zkt2PHnvqkEtPTU55TTL/Z8kOL0n2+ciklsr0IMQGAAAY2Oq1x091CSvl8guvStLv+i8ycwcwTcy/5qbcevvCtCQn/e6vOfXcy/OEXe6bTe5250D2lytvyH+feE7OOP9vi49d9Pd/5I6FLTNn1BRU3TPXXpjcfnOSlpx7XHL+V5MdX57cdYs7+1x9XvLjI5MLvnXnsSt+myy8I5kxc9JLpt+E2AAAAAAwsOXGd80nXrZHTjjrknzxJxfkmhtvydd/+ucl+rzhC79Y/Pi+97xrDpu7bXZ70GaTXWp/bfTA5AXnJ7/5aPKzY5Kb/pb88j1L9vn64+98vPFDuru1H3Dw5NbJtCHEBgAAAIBh1p01MwfvunX2f9h98s2f/TlfOePC3LDgtiX6bH6PDfLsxz4ge22/RWaUu6+XMmu9ZKcjku1fmJz1/uTM/0oWXLNknznbJLsNJdsdmpSl+xibvx0AAAAAMIZaRkA9oyri6xUwVkBdldTMxLvIcrgTGwAAAACGue2OhfneWZfkCz/5U66+4ZZR+8y/5qa845u/zlfOuDDP33Pb7PqATSe5yp6749bkNx9PfnZ0cuPlo/e59oLkhEOTX7wzefQxyTYHTG6NTBvuxAYAAACAgUuvuiH/68Pz8qHv/z5X33BL1pk5I4c8Yuscvu92i/sc/cxdFofWF/7t+rzxi7/If3z2p7ljYZuqsvvl6vOTT26bnPSKLsCeuW6y05HJHu++s8+TT0i2ObB7fMXZyTcOTL68V7ewI4wgxAYAAACAgc3vsUFmzuimt3jMdpvn4y/dIy/Z78G52/rrLO5z703umrc+Y5e84zmPyP03u/tSz1vrbbhNMmMwAcQDn5ocdm6y53uT2Rvd2Wej7ZJDvps89aRk050Gz7tfMmPm5NdL75lOBAAAAAAGZs6YkVcdsH3WW2dmttvyHsvsu+NWm+SDL3x0fviby/KwrTeZpAqngRmzkn0/mszaILnXI5fd9z57Js8+Mznns8l99p6c+ph2hNgAAAAAMMyO4wikqyr77rDlaqxmmrrPXivetyp5yHNXXy1Me6YTAQAAAACgt9yJDQAAAADLsd8O985+O9x7qsuY3h56WLfBOLkTGwAAAACA3hJiAwAAAADQW6YTYaVs9drjp7qElXL5hVcl6Xf9F739wKkuAQAAAAB6w53YAAAAAAD0lhAbAAAAAIDeEmIDAAAAANBb5sQGAACYhq79yXG57rQvLHHs4ncctPjxnN2fmQ0ffehklwUAMOGE2AAAANPQho8+VEgNAKwVTCcCAAAAAEBvCbEBAHpiaGgoVTXmNjQ0NNUlAgAATDrTiQAA9MTQ0NDioHru3LlJknnz5k1ZPQAAAH3gTmwAAAAAAHrLndjQN0NzprqCsV10Y7fvc43LM3TdVFcAa7Rrf3JcrjvtC0scu/gdBy1+PGf3Z1qEDAAAgHERYgMAE2bDRx8qpAYAAGBCmU4EAAAAAIDeEmIDAAAAANBbQmwAAAAAAHpLiA0AAAAAQG8JsQEAAAAA6C0hNgAAAAAAvSXEBgAAAACgt4TYAAAAAAD0lhAbAAAAAIDeEmIDAAAAANBbQmwAAAAAAHpr1lQXAKvbtT85Lted9oUljl38joMWP56z+zOz4aMPneyyAAAAAIAVIMRmjbfhow8VUgMAAADANGU6EQAAAAAAequXIXZVPaWqPlBVp1bV9VXVqupzU10XAAAAAACTq6/TibwhyQ5JbkhyaZIHTW05AAAAAABMhb6G2P+aLrz+U5I9kvx4asuBtdfQvAU56uRblzhWR12/+PGb91g3Q3NnT3ZZAAAAAKwlehlit9YWh9ZVNZWlwFpvaO5sITWw5hqaM9UVjO2iG7t9n2tclqHrproCAABgDdHLEHvC/OEPydy5Sx572tOSl70suemm5IADln7OYYd125VXJk95ytLtL31p8vSnJ3/5S/Kc5yzd/upXJ094QvfaL37x0u1veEOyzz7Jr3+dHHnk0u3HHJPstlty+unJ61+/dPv73pfsuGPywx8mRx+9dPtHP5psu23yne8k73730u2f/Wxy73snX/pS8pGPLN3+1a8mm2ySHHtst410wgnJBhvk2Wcdn4POO3Wp5mc86+1Jkhf97OvZ+4KfL9G2YNZ6OexpRyVJXnnaF7L7xWcv0X7N+nfPSw/pfub/OPnY7HTZeUu0z7/bJvnXJ/x7kuRNP/xYHvz3C5dov3CjLfL6/V+ZJDnm+x/INldftkT7OZtuk7fsc3iS5L3feVc2/8eVS7SftcWD8s49DkuSfOQbx+QeN1+/RPtp990hH9j9mUmSY7/85sy+/ZYl2n90v13z8Uc8OUnyxc+/NiN990GPyed2OjCzb1uQY78ytFT7V7ffJ1/dfp/kpoXJl29eqj07r5s8dJ3kuoXJN0Zpf9S6ybbrJFfekXx3wdLtj10v2WZWcvkdyfdHad97veTes5K/3J786Jal2/efnWw2M7nw9uSUUdoPmp1sMjP5w23JGbcu3X7I+smcGcnvbkvOHKX9aesnG8xIfn1r8uvblm4/dINknUp+cWvy+1HaD7tLtz/9luT825dsWyfJoYP2t741+dGPlmzfeOPka1/rHr/udckZZyzZvuWWyecG0/IfeWT373e4Bz4w+djHuseHH56cf/6S7Tvu2P3bTZJnPzu59NIl2x/1qORtb+se/8u/JFddtWT73nsnb3xj9/jxj09uHvHf/6CDkn/v/m0sNeYlxr0JGvfy4Q8nX/7y0u3z5nX7d70r+e53l2xbf/3ke9/rHq/i3701edy7x03X5SPffNtS7Z972AH57naPzebXX5H3fnfp/7Yf3/WQ/Oj+j8g2V12aY0784FLtH9jtGTltqx3z4L9dmDf96GNLtb/zsc9L7p/ejnvrLWy5ZcYEjHsn35L8eUT7BpU8bYPu8Q8XJJfesWT73WckT16/e/z9Bd3vjuE2npE8YdD+nZuTqxYu2b7ZzGRo8Ni4t3S7ca973NffudkpyZo77p215XbZ6dJz8x+nfHqp9rfsfXjO+adtsvtFv84rT//iUu2vf9wrcuHGW2bvP/0sL/r5N5Zq/9eDXp35d79nDjr3lDz7Vycs1Z5nLJyc672pGvf2H9z48fWbk+tHtG85M9ln0P7lm5Kb2pLtW89K9live3zcjcnIH/+Bs5LdBu3H3pilbPph455xz+9cf/eWbPd3z9+96fp3bwxrXIhdVYcnOTxJ/nm99aa4GgCAFTd07cIcdd2SwUZdfGeQ8uY5laENe7kuNwAAwGpTrbXl95pCVTU33ZzYx7XWnj2e5+68887tzDPPXC11re22eu3xU13CGuui2c+a6hLWbL7ezjRkzF19jLmrkfGWacqYu/oYc1cjYy4Aa4Cq+mVrbefR2tzKAwAAAABAbwmxAQAAAADoLSE2AAAAAAC9JcQGAAAAAKC3hNgAAAAAAPTWrKkuYDRVdXCSgwd/3Gywf1RVHTt4fGVr7d8nvTAAAAAAACZVL0PsJDsmed6IY9sMtiS5OIkQGwAAAABgDdfL6URaa0OttVrGttVU1wgAAAAAwOrXyxAbAAAAAAASITYAAAAAAD0mxAYAAAAAoLeE2AAAAAAA9JYQGwAAAACA3hJiAwAAAADQW0JsAAAAAAB6S4gNAAAAAEBvCbEBAAAAAOgtITYAAAAAAL0lxAYAAAAAoLeE2AAAAAAA9JYQGwAAAACA3hJiAwAAAADQW0JsAAAAAAB6S4gNAAAAAEBvCbEBAAAAAOgtITYAAAAAAL0lxAYAAAAAoLeE2AAAAAAA9JYQGwAAAACA3hJiAwAAAADQW0JsAAAAAAB6S4gNAAAAAEBvCbEBAAAAAOgtITYAAAAAAL0lxAYAAAAAoLeE2AAAAAAA9JYQGwAAAACA3hJiAwAAAADQW0JsAAAAAAB6S4gNAAAAAEBvCbEBAAAAAOgtITYAAAAAAL0lxAYAAAAAoLeE2AAAAAAA9JYQGwAAAACA3hJiAwAAAADQW0JsAAAAAAB6S4gNAAAAAEBvCbEBAAAAYAxDQ0OpqjG3oaGhqS6x97yHrKpZU10AAAAAAPTV0NDQ4pB17ty5SZJ58+ZNWT3TkfeQVeVObAAAAAAAekuIDQAAAABAbwmxAQAAAADoLSE2AAAAAAC9JcQGAAAAAKC3hNgAAAAAAPSWEBsAAAAAgN4SYgMAAAAA0FtCbAAAAAAAekuIDQAAAABAbwmxAQAAAADoLSE2AAAAAAC9JcQGAAAAAKC3hNgAAAAAAPSWEBsAAAAAgN6aNdUFAAAAAAATaGjOVFcwtotu7PZ9rnFZhq6b6grWSu7EBgAAAACgt4TYAAAAAAD0lhAbAAAAAIDeEmIDAAAAANBbFnYEAAAAYFJt9drjp7qElXL5hVcl6X/9F82e6gpgYrkTGwAAAACA3hJiAwAAAADQW0JsAAAAAAB6S4gNAAAAAEBvCbEBAAAAAOgtITYAAAAAAL01a6oLAAAAAADWXEPzFuSok29d4lgddf3ix2/eY90MzZ092WUxjQixAQAAAIDVZmjubCE1q8R0IgAAAAAA9JYQGwAAAACA3hJiAwAAAADQW0JsAAAAAAB6y8KOAAAAADCGa39yXK477QtLHLv4HQctfjxn92dmw0cfOtllwVpFiA0AAAAAY9jw0YcKqWGKmU4EAAAAAIDeEmIDAAAAANBbQmwAAAAAAHpLiA0AAAAAQG8JsQEAAAAA6C0hNgAAAAAAvSXEBgAAAACgt4TYAAAAAAD0lhAbAAAAAIDeEmIDAAAAANBbQmwAAAAAAHpLiA0AAAAAQG8JsQEAAAAA6C0hNgAAAAAAvSXEBgAAAACgt4TYAAAAAAD0Vq9D7Krasqo+WVV/rapbquqiqnpfVd1jqmsDAAAAAGD1mzXVBYylqu6X5PQkmyb5VpLzkuya5FVJ9q+q3VtrV01hiQAAAAAArGZ9vhP7w+kC7CNaawe31l7bWtsryXuTbJvkP6e0OgAAAAAAVrtehthVtU2S/ZJclORDI5rfnOTGJM+pqrtMcmkAAAAAAEyiXobYSfYa7H/QWls4vKG19o8kpyXZIMkjJ7swAAAAAAAmT19D7G0H+/PHaP/jYP/ASagFAAAAAIAp0teFHecM9teN0b7o+IYjG6rq8CSHD/54Q1X9YYJrg9Wqkk2SXDnVdayxjqqprgDoEWPuamS8BUYw5q5GxlxgBGPuamTMXZ3uO1ZDX0Ps5Vn0t6WNbGitfSzJxya3HJg4VXVma23nqa4DYG1gzAWYPMZcgMljzGVN09fpRBbdaT1njPa7j+gHAAAAAMAaqK8h9qIpQMaa8/oBg/1Yc2YDAAAAALAG6GuI/ePBfr+qWqLGqrpbkt2T3Jzkp5NdGEwC0+EATB5jLsDkMeYCTB5jLmuUam2paaV7oapOTLJfkiNaax8Ydvw9Sf41yUdbay+ZqvoAAAAAAFj9+hxi3y/J6Uk2TfKtJOcmeUSSPdNNI7Jba+2qqasQAAAAAIDVrbchdpJU1b2TvCXJ/kk2TjI/yTeTHNVau3oqawMAAAAAYPXrdYgNa6Kqmpdkj9ZaTXUtAIxPVR2W5FNJnt9aO3ZqqwGYvqrqoiRprW01tZUAANNBXxd2BAAAAACAzJrqAmAt9NwkG0x1EQAAAAAwHbgTGyZZa+2S1tp5U10HAAAAMLqq2qqqWlUdW1UPqqpvVtXVVXVjVf2kqvYb0f+wQf/Dqmr/qppXVddVVRvWZ05Vva2q/lBVC6rqmqo6sar2GaOG9apqqKourKpbqurPVXX04HgbTFe6Mj/bitQ6q6peVlU/rarrq+qmqvpVVb2iqkbNE6tq16r6UlVdNqh3flX9oKqetrLvKywixIYJVFVPrKofDQbqW6rqr1V1clW9bFifecN/MQyOteVsQyP6bzT4xXduVd08+GXzI4M9sCaozquq6pzBxf1lVfXBwUX/RYvmUR30XZEL8IOr6nNVdf7g4viGqvplVR2xjAvw+1fVVwb/Y3FjVZ1eVQcup+4tB3Uu+p+Mq6rq21W1y4S9OQATZESIsFVVfbGqrhyMu2dW1UGjPGe9qnptVf1mEGZcX1WnDg8nRvSvQdjx+5Hj+XJqe2ZV/XgwBi8YXPO+oarWG6XvY6rqO1V16WDsvXwQuLx55d8dgCVsneSMJBsn+WiSryR5eJLvVdXTR+n/lCTfTfKPJP+d5MtJUlUbJjk9yWuTXJfkfUm+luRRSX5QVS8efpKqqkH7m5PcnuSDSb6T5LAkX5ygn22sWtcZHP9Qkg2TfD7Jx9LliB9I8umRJ6qqFw1+voMH+3cnOT7JpkleNrJ/xv++spazsCNMkKo6PN3Ae3m6XyxXphus/zndv7VdBv3mZcTCjiND6mGek2SbJP+7tfbOQd/7JpmXZKskpyb5ZZK7JDkoyWZJXtxa+/iE/nAAk6iqPpzkpUn+mu7C/dYkT0xybZItkty2aCGwunOhxeOT7J/ke0nOSbJVa+3pgz7nJVmYbry8LMmcJHsleWCSz7XWnjPi9R+QOy+ov5fk10nun+SQwZ+fkBELO1bVTkl+kGSjJCcm+X2STdJdxK+f5JDW2gkT8gYBTICq2irJn9NdVz4kyYXpxr6Nkjw9yTpJ9mmt/XjQf91049weSc5LF25skC4A2TTJ21prrx/xGu9PckSS+Um+muS2JE9Kck268fzWkQs7VtUnkrwgyaWD17s2ySOT7Daodd/W2u2DvvunG/+vT/LtdGP8Rkm2S/Kg1to/rdKbBKzVho2TSfKu1tprhrXtnG7MvCHJfVtr1w+7Lm1JDmitfX/E+T6a5PB0YfBL2iCQG1x7nplkdpJtW2sXDY4/J8ln0v1//z6ttVsHxzdM8tMk2yY5ubU2dyV+tuXVOpQuPP9gkiNba3cMjs8c1P+CJAe31r41OP7gJGenC8Mf01r7/Yjzbdlau3TweKuM430d78/GGqy1ZrPZJmBLF47ckmTTUdo2GfZ4XvdPb7nne366XyhnJJk94vkLkzxjRP8N0wUtNyf5p6l+P2w2m21ltiSPGYx9f0iy4bDj6yY5ZdB20bDjhw2OLUyy/xjnvN8ox2aku4OkJXnEiLYfDI6/asTxJw2OtySHDTs+K8mfkixI9yHl8OfcK12oMj/JelP9/tpsNtuiLd0NEYvGtDePaHvc4PgJw469btGxJLOGHd80yUWDtt2GHd9tcOxPSTYadnz24Pp2ifF80LZoTP96kvVHtA2NHJvTfdDZkuwwys+3yfLeA5vNZlvWNmycvDbJ3UZpP3bQ/rzBnxeNYd8Ype86SW5MF/JuNEr7WwfPfdOwYz8cHHvsKP0PHbTNW8mfbVm1zkh3U9784eP9sPYNB9feXx527AOD8/3rRL+vNtuizXQiMLFuT3eHyRJaa1eO5yRVtXe6u7ovTPLE1tqCwfEd0t398rXW2hJfH2qtXZvuk9LZSf5lpaoHmHrPG+z/czCuJUlad+fJ65bxvG+1EXeQDHvuBaMcW5jk/YM/Pm7R8araMsm+6e4O+eCI53wrycmjvMSBSe6X5AOttZNHPOevSd6Z7psyey+jfoCpcnGSo4cfaK2dmOSSJLsOO/yCdKHCv7XBndCDvn9PF74kyQuH9X/+YP+frbWrh/VfkLHH81elu55+QWvt5hFtb01yVbrgZqSRfcd9/Q2wDGe11v4xyvF5g/3DRhz/+Sh9H5Tu2ytnDx8ThzlplHM9LF1YfPoo/X8yZrXjM1qtD0z3jcR/JHlDdXNyL96SHJlu3N1u2HMeOdh/bxyvPd73lbXcrKkuANYgx6Wb8+n3VfWldEHHaa21K8ZzksHXcL6W7uszB4x4/qMG+zljTEFyz8F+u1HaAKaDRRero12Y/zRduDGa0S7AkyRVtXGS1yQ5IN0UTXcZ0WWL0V6/Db42OcK8dB8mDrdobL7vGGPzAwb77dLdwQjQJ78eY7z7SwbjW1XdLd20Spe10RcoHy182WmwH+3Dv1MzYjyvqg2S7JDu7r8ju6lgl3JLlrzOPS7Jk5P8bHD9/eN019+XjvZkgJX0tzGOXz7Yj5zn//KRHYf1mT/GuRYd33DEc64e/sHhCtQ0XqPVuvFg/4B0N8qN5a7DHi+q+7JxvPZ431fWckJsmCCttfdU1ZXpFiw4It2nk62qTk7ymtbamcs7R1Vtli7gWD/Jfq21P4zosuiXyb6DbSx3XUYbQJ8tulhd6qK2tXZHVV01xvNGuwBfNGfgL9ItHPPzdPMKXp0uPNkw3V1/wxcKG/P1l/E6i8bmp47xnEWMzUAfXTvG8duTxd/cXdnwJVnx8fweSSrdTRkrtChja+3rgwUoX53uTvEXJ0lV/TLJ61pr/29FzgOwHGPNr7/ZYH/diOOjLT63qM9mo7QlyeajnOv6JBtV1axRguyJmvN/WbV+o7X25BU8z6LfJVukWzdhRYz3fWUtZzoRmECttc+01h6ZLtA4MMknkjw2yYlVtemynju4++Q7Se6b7iuUo921smgQf1VrrZaxPX+U5wJMB4sWb1nqonawkMzGI48PjLVS9QvTBdhHtdYe0Vp7WWvtDa21oSRfGqX/onF2eRfVoz3nScsZm48a45wAfbcy4cuY4+kY4/mi/r9azli6xC3arbXjW2t7pQvB907y3nQLVX538A1HgFW10+AbKSPNHex/tQLn+EOSm5LsWFX3GKV9z8H+rGHHfpUut9ttlP6PXoHXXFnnZbCoblWts4LP+elg//hxvM5EvK+sRYTYsBq01q5trZ3QWntRukUJNkq3WNmoqmpGks8n2TndQg7HjdF10S+GMc8FMM0tulgd7cL8kRn/t8juP9h/bZS2kdOCLPH6g5BlpLmjHDM2A2u0wZylFyTZoqoeMEqX0cKXRY9HG2sfkxHjeWvthiS/T/KQqtpoJWq8sbV2Umvt35Ick25B4PGEKQBjmZPkTcMPVNXO6ebovy7JN5Z3gsH6Lsel+2beW0ac637pvs19W5LPDmv6zGB/dFWtO6z/nCRvHPdPsYIGd31/IN0HlP+3qtYf2aeqNh/xQeFH0n2D542jfYA4WHdmpFV+X1m7CLFhglTV/lU1Wriy6A7sm5bx9PckeVKST7fW3jpWp8GUJKcmeXJVvWCMOrZf3l3fAD226GL9/wwu0JMkgwv3Y1bifBcN9nOHH6yqh2WUhcUG86j+v3R3b79ixHOelNHDmG+lC3deXlUHjFZEVT1q8I0bgOnqk+mm+/iv4R/yVdUmuTNM+eSw/scO9v9neChdVbOTvG2M13hPuvD5k4PpoJZQVfeoqp2G/Xnv0cKV3Hn397KuvwFW1ClJXlhVp1TV26rq2HT/Xz4jyYtba9cv89l3em26u5xfUVU/HZzr4+k+9Lt7kiNba38e1v8zSb6f7oO/31XVu6rq/ek+8Fs0ZcfCVf3hxvDWJN9O8pIkf6yqzwzq/URVnZLk0iRPXNS5tXZOuqlV5yT5VVV9uar+s6r+u6rOzJLh/CIT9b6yljAnNkycLyZZUFU/SReaVLpfNrsk+WWSH472pKraNd2crAuSXDbGomDzWmvzBo+flW7xnE9U1RFJfpbuqz5bJvnnJA9NtwjP3yfihwKYTK21k6vqY0kOT7dQ7tfS3ZXyhHR3ZPw147tY/0y6RR3fV1V7JvljukVqDkry9SRPH+U5L09yxuA5+yU5O90d3Yekm/bpCSNqvq2qnpzkxCTHV9XpSX6dLjy5d7rfA9uku5tFoAJMV+9Kd2fzk5KcXVUnJNkg3XoAmyZ5Z2tt8aK8rbXTquoDSV6ZLnz5arrx/ElJrsko82u31j5ZVQ9PF4RcUFUnJrkk3bcat043Td+n0oUqSbeo+lZVNS/d9fetSR6eZK8kF6e7PgdYVX9ON+68fbBfL13w/JbW2okrepLW2tVV9ah0N1I8Ocm/Jbk53bot/9Va+8GI/q2qDkny+iTPSTeezk/y6SQfTjeerpagd3B9e3CSZyc5LN21812TXJHu/XhjujvLhz/n41X1uyT/nu4GkoPTLdb7myT/M8rLTMj7ytqjWhtrCklgPKpaX70GAAACSUlEQVTqJUkel25V9c3ShdIXJ/lCko8MvoaZwUX2Hovm86uquelWUl+Wowbzty56rbul+wX2L0m2TTIz3WJj56S7I/C41tqNE/SjAUyqwRRLr0q3QNfWSa5K93XC16e76+OC1tqOg76HpQs0nt9aO3aM8z043cXxI5PcJd2dKx9J9+Hin9N9C+awEc+5/+A5+yRZJ93F99HpFhwb9fUG34L5t3QX+dukC9vnpwvBv5nki2OsLg8w6apqq4wxBg7a52XYNevg2Ox049yzktwv3VfHz07yodbaF0Y5R6X7YPDl6cbF4eP52UnSWttqlOcdlC7Q2DXdYpFXpwuzf5Dkc6218wb9npbuA8ad031QuHDQ71tJ3tdau2IcbwnAEpY3Tk6lqto33Zj49tbaUt8u7LM+v6/0mxAbAJgWBvOwnp8uDH7mVNcDAMCaqw9ha1Xdq7X21xHHNk4XYO+U5BGttZ9PRW0rqw/vK9OT6UQAgF6pqs2S/L21tnDYsQ2SvG/wR4u8AACwNnhPVe2Q5PR0U3lsmW5qp42SfHS6BdiwKoTYAEDfHJnkmYOvss9PN0XT3uku2r+X5CtTVxoAAEyar6dbrPYJ6aZXWpBuYcdPZtg804NpSueuwPmuba29b/ndoH9MJwIA9EpV7Z1uQZgd091lcnu6aUQ+n26O09umsDwAAOiVqhpK8uYV6HrxaGsRwHQgxAYAAAAAoLdmTHUBAAAAAAAwFiE2AAAAAAC9JcQGAAAAAKC3hNgAAAAAAPSWEBsAAAAAgN76//filSRU3f5NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#append lists\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [25, 10]\n",
    "errorsDictSig = {}\n",
    "totalCoxList =  HRs_cont_all + list_HRs_all  \n",
    "mySummaries_reor = mySummaries[:1] + mySummaries[3:8] + mySummaries[1:3] \n",
    "#get the union of all sig covs\n",
    "all_sig_covs = [origCols[i] for i in range(len(origCols)) \n",
    "                    if ((totalCoxList[i][1] > 1 and totalCoxList[i][2]) > 1 \n",
    "                        or (totalCoxList[i][1] < 1 and totalCoxList[i][2] < 1)\n",
    "                       or (mySummaries_reor[i][1] > 1 and mySummaries_reor[i][2] > 1) \n",
    "                        or (mySummaries_reor[i][1] < 1 and mySummaries_reor[i][2] < 1))]\n",
    "\n",
    "# all_sig_covs_names = [tup[0] for tup in all_sig_covs]\n",
    "# all_sig_covs_numInd = [tup[1] for tup in all_sig_covs]\n",
    "xgb_sig_covs = [mySummaries_reor[i] for i in range(len(origCols)) \n",
    "                    if ((totalCoxList[i][1] > 1 and totalCoxList[i][2]) > 1 \n",
    "                        or (totalCoxList[i][1] < 1 and totalCoxList[i][2] < 1)\n",
    "                       or (mySummaries_reor[i][1] > 1 and mySummaries_reor[i][2] > 1) \n",
    "                        or (mySummaries_reor[i][1] < 1 and mySummaries_reor[i][2] < 1))]\n",
    "\n",
    "cox_sig_covs = [totalCoxList[i] for i in range(len(origCols)) \n",
    "                    if ((totalCoxList[i][1] > 1 and totalCoxList[i][2]) > 1 \n",
    "                        or (totalCoxList[i][1] < 1 and totalCoxList[i][2] < 1)\n",
    "                       or (mySummaries_reor[i][1] > 1 and mySummaries_reor[i][2] > 1) \n",
    "                        or (mySummaries_reor[i][1] < 1 and mySummaries_reor[i][2] < 1))]\n",
    "\n",
    "\n",
    "#rename (if needed)\n",
    "\n",
    "\n",
    "df_cox_sig_all = pd.DataFrame(cox_sig_covs, index = all_sig_covs, columns = [\"medianHR\", \"LB_HR\", \"UB_HR\"])\n",
    "# print(df_cox_conts_all)\n",
    "errorsCoxSig = np.array([list(df_cox_sig_all.medianHR - df_cox_sig_all.LB_HR),list(df_cox_sig_all.UB_HR - df_cox_sig_all.medianHR)])\n",
    "errorsDictSig[\"COX\"] = errorsCoxSig\n",
    "\n",
    "df_xgb_sig_all = pd.DataFrame(xgb_sig_covs, index = all_sig_covs, columns = [\"medianHR\", \"LB_HR\", \"UB_HR\"])\n",
    "errorsXGBSig = np.array([list(df_xgb_sig_all.medianHR - df_xgb_sig_all.LB_HR),list(df_xgb_sig_all.UB_HR - df_xgb_sig_all.medianHR)])\n",
    "errorsDictSig[\"XGB\"] = errorsXGBSig\n",
    "\n",
    "#All Sig Variables\n",
    "total_plot_sig_all = pd.DataFrame({\"COX\":list(df_cox_sig_all.medianHR), \n",
    "                          \"XGB\":list(df_xgb_sig_all.medianHR)},\n",
    "                         index = all_sig_covs)\n",
    "\n",
    "cats = all_sig_covs\n",
    "x1 = np.arange(len(cats)) + 0.115 #offset \n",
    "x2 = np.arange(len(cats)) - 0.115 #offset\n",
    "ax_sig = total_plot_sig_all.plot.bar(rot=0)\n",
    "ax_sig.set_title(\"Breast Cancer\", fontsize = 30, weight = \"heavy\")\n",
    "ax_sig.axhline(y=1 , color='r', linestyle='--')\n",
    "ax_sig.set_ylabel(\"Hazard Ratio\", fontsize = 24)\n",
    "ax_sig.set_ylim((0, 5))\n",
    "for label in (ax_sig.get_xticklabels() + ax_sig.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "plt.legend(loc = 1,fontsize = 20)\n",
    "plt.errorbar(x1, df_xgb_sig_all.medianHR, yerr = errorsDictSig[\"XGB\"], ecolor = 'black', linestyle = 'None', capsize = 4)\n",
    "plt.errorbar(x2, df_cox_sig_all.medianHR, yerr = errorsDictSig[\"COX\"], ecolor = 'black', linestyle = 'None', capsize = 4)\n",
    "\n",
    "\n",
    "plt.text(0-.140, 1.5, \"*\", fontsize= 30,weight=\"heavy\", color = \"SteelBlue\")\n",
    "plt.text(0+.092, 1.5, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "plt.text(1-.140, 2.55, \"*\", fontsize= 30, weight=\"heavy\", color = \"SteelBlue\")\n",
    "plt.text(2-.14, 2.75, \"*\", fontsize= 30, weight=\"heavy\", color = \"SteelBlue\")\n",
    "plt.text(2+.092, 2.75, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "plt.text(3-.14, 1.25, \"*\", fontsize= 30, weight=\"heavy\", color = \"SteelBlue\")\n",
    "plt.text(3+.092, 1.25, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "\n",
    "plt.savefig(save_to + 'bcd_sigonly_allcov_XGB_COX.png',  bbox_inches = \"tight\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medianHR</th>\n",
       "      <th>LB_HR</th>\n",
       "      <th>UB_HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>1.156242</td>\n",
       "      <td>1.010027</td>\n",
       "      <td>1.484406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>1.006834</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>1.200703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>1.684592</td>\n",
       "      <td>1.203189</td>\n",
       "      <td>2.393775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prog_recp</th>\n",
       "      <td>0.351927</td>\n",
       "      <td>0.231629</td>\n",
       "      <td>0.532820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           medianHR     LB_HR     UB_HR\n",
       "size       1.156242  1.010027  1.484406\n",
       "grade      1.006834  0.999434  1.200703\n",
       "nodes      1.684592  1.203189  2.393775\n",
       "prog_recp  0.351927  0.231629  0.532820"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb_sig_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#append lists\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [25, 10]\n",
    "errorsDictAll = {}\n",
    "# totalCoxList =  HRs_cont_all + list_HRs_all  \n",
    "# mySummaries_reor = mySummaries[:1] + mySummaries[2:3] + mySummaries[6:9] + mySummaries[1:2] + mySummaries[3:6] + mySummaries[9:]\n",
    "#get the union of all sig covs\n",
    "all_covs = [origCols[i] for i in range(len(origCols))]\n",
    "\n",
    "# all_sig_covs_names = [tup[0] for tup in all_sig_covs]\n",
    "# all_sig_covs_numInd = [tup[1] for tup in all_sig_covs]\n",
    "xgb_all_covs = [mySummaries_reor[i] for i in range(len(origCols))]\n",
    "\n",
    "cox_all_covs = [totalCoxList[i] for i in range(len(origCols))]\n",
    "\n",
    "#rename (if needed)\n",
    "\n",
    "\n",
    "df_cox_all = pd.DataFrame(cox_all_covs, index = all_covs, columns = [\"medianHR\", \"LB_HR\", \"UB_HR\"])\n",
    "# print(df_cox_conts_all)\n",
    "errorsCoxAll = np.array([list(df_cox_all.medianHR - df_cox_all.LB_HR),list(df_cox_all.UB_HR - df_cox_all.medianHR)])\n",
    "errorsDictAll[\"COX\"] = errorsCoxAll\n",
    "\n",
    "df_xgb_all = pd.DataFrame(xgb_all_covs, index = all_covs, columns = [\"medianHR\", \"LB_HR\", \"UB_HR\"])\n",
    "errorsXGBSig = np.array([list(df_xgb_all.medianHR - df_xgb_all.LB_HR),list(df_xgb_all.UB_HR - df_xgb_all.medianHR)])\n",
    "errorsDictAll[\"XGB\"] = errorsXGBSig\n",
    "\n",
    "#All Sig Variables\n",
    "total_plot_all = pd.DataFrame({\"COX\":list(df_cox_all.medianHR), \n",
    "                          \"XGB\":list(df_xgb_all.medianHR)},\n",
    "                         index = all_covs)\n",
    "\n",
    "cats = all_covs\n",
    "x1 = np.arange(len(cats)) + 0.115 #offset \n",
    "x2 = np.arange(len(cats)) - 0.115 #offset\n",
    "ax = total_plot_all.plot.bar(rot=0)\n",
    "ax.set_title(\"Breast Cancer CoxPH / XGBoost Comparison: All Covariates\", fontsize = 30, weight = \"heavy\")\n",
    "ax.axhline(y=1 , color='r', linestyle='--')\n",
    "ax.set_ylabel(\"Hazard Ratio\", fontsize = 24)\n",
    "ax.set_ylim((0, 5))\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "plt.legend(loc = 1,fontsize = 20)\n",
    "plt.errorbar(x1, df_xgb_all.medianHR, yerr = errorsDictAll[\"XGB\"], ecolor = 'black', linestyle = 'None', capsize = 4)\n",
    "plt.errorbar(x2, df_cox_all.medianHR, yerr = errorsDictAll[\"COX\"], ecolor = 'black', linestyle = 'None', capsize = 4)\n",
    "\n",
    "# plt.text(0-.15, 1.5, \"*\", fontsize= 30,weight=\"heavy\", color = \"Navy\")\n",
    "# # plt.text(0+.092, 2, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "# plt.text(1+.092, 2, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "# plt.text(2-.15, 2.75, \"*\", fontsize= 30, weight=\"heavy\", color = \"Navy\")\n",
    "# plt.text(2+.092, 2.75, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "# plt.text(3-.15, 2.5, \"*\", fontsize= 30, weight=\"heavy\", color = \"Navy\")\n",
    "# plt.text(3+.092, 2.5, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "# plt.text(4-.15, 2, \"*\", fontsize= 30, weight=\"heavy\", color = \"Navy\")\n",
    "# plt.text(4+.092, 2, \"*\", fontsize= 30, weight=\"heavy\", color = \"DarkOrange\")\n",
    "plt.savefig(save_to + 'bcd_allcov_XGB_COX.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coxCs = [0.7331452, 0.715131, 0.7260905, 0.7266426, 0.782861]\n",
    "xgbCs = [0.7839305103148752,\n",
    " 0.6783340717766947,\n",
    " 0.7650669642857143,\n",
    " 0.7093124456048738,\n",
    " 0.8002033553634977]\n",
    "\n",
    "\n",
    "box_data = [coxCs, xgbCs]\n",
    "# print(box_data)\n",
    "fig = plt.figure(figsize =(10, 7)) \n",
    "  \n",
    "# Set the font dictionaries (for plot title and axis titles)\n",
    "title_font = {'size':'24', 'color':'black', 'weight':'heavy'} # Bottom vertical alignment for more space\n",
    "axis_font = {'size':'20'}\n",
    "# Creating axes instance \n",
    "ax = fig.add_axes([0, 0, 1, 1]) \n",
    "ax.set_xticklabels(['Cox_AllCovs', 'XGB_AllCovs'])\n",
    "ax.set_title(\"Breast Model Cross Validation C-Index Comparison\", **title_font)\n",
    "ax.set_ylabel(\"Concordance Index\", **axis_font)\n",
    "ax.set_ylim(0.55, 0.90)\n",
    "\n",
    "\n",
    "\n",
    "# for item in [ax.title]:\n",
    "#     item.set_fontsize(20)\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(18)\n",
    "\n",
    "# Creating plot \n",
    "bp = ax.boxplot(box_data, patch_artist=True) \n",
    "\n",
    "for median in bp['medians']:\n",
    "    median.set(linewidth=3)\n",
    "\n",
    "for box in bp['boxes']:\n",
    "# change outline color\n",
    "    box.set(linewidth=3)\n",
    "\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(linewidth =3)\n",
    "\n",
    "for cap in bp['caps']:\n",
    "    cap.set(linewidth=3)\n",
    "\n",
    "# show plot \n",
    "plt.show()\n",
    "plt.savefig(save_to + 'bcd_box_plot_cindex.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model trained, using for SHAP analysis\n",
    "X_train = full_xy.sample(n = full_xy.shape[0], random_state = i, replace = True) #sample w/ replacement num rows\n",
    "y_train = X_train['y'] #y train are X_trains y column\n",
    "X_train = X_train.drop(columns = ['y']) #X_train then needs to drop the y column\n",
    "X_test = full_xy.drop(X_train.index) #test features are the full - X_train\n",
    "y_test = X_test['y'] #y test are X_tests y column\n",
    "X_test = X_test.drop(columns = ['y']) #X_test then needs to drop they column\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "model_train_SHAP = xgboost.train(xgb_best_hyperparams, xgb_train, 1000, evals = [(xgb_test, \"test\")], verbose_eval=False)\n",
    "    \n",
    "#   let's get the SHAP vals and a HR from these based on our model\n",
    "shap_values= shap.TreeExplainer(model_train_SHAP).shap_values(X_bcd)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x338.4 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values, X_bcd, show = False)\n",
    "plt.title(\"Breast Cancer XGBoost Feature Importance\", fontsize = 14, weight = 'bold')\n",
    "plt.savefig(save_to + \"importance_plot_all_XGBoost_BCD.png\",  bbox_inches = \"tight\", dpi = 400) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
